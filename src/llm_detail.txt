# LLM Summary Detail File

This file is a concatenation of all individual *llm.txt files found in the directory tree. Each section below corresponds to a specific directory's summary file.

================================================================================

## Section 1: agent/adk/adk_llm.txt

**Source file:** `agent/adk/adk_llm.txt`

# DEVELOPER GUIDE: adk

## Quick Summary
The `adk` directory serves as the core integration layer between the Solace AI Connector framework and Google's Agent Development Kit (ADK). It provides the essential components for building, configuring, and running sophisticated AI agents within a Solace messaging environment.

The architecture is designed for modularity and extensibility. The `setup.py` module acts as the main configuration hub, using factory functions from `services.py` to initialize pluggable services (like `FilesystemArtifactService` for artifact storage) and loading tools (Python functions, MCP tools) via the `ADKToolWrapper`.

Once initialized, the `AppLlmAgent` (a custom agent class) is managed by the `runner.py` module, which handles the asynchronous task execution loop. The agent's behavior is dynamically augmented at runtime by a rich set of callbacks from `callbacks.py`. These callbacks inject dynamic instructions, manage large tool responses, log events to Solace, and handle advanced features like streaming artifact creation and auto-continuation of conversations. The `models/` subdirectory provides the concrete LLM clients, with `LiteLlm` offering broad compatibility with various model providers.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Standard Python package initializer.
  - `app_llm_agent.py`: Defines a custom `LlmAgent` subclass that holds a reference to its host component.
  - `callbacks.py`: Provides a rich set of ADK callback functions for dynamic instructions, metadata injection, and Solace integration.
  - `filesystem_artifact_service.py`: A local filesystem-based implementation of ADK's `BaseArtifactService`.
  - `invocation_monitor.py`: A utility for monitoring and logging agent invocations to YAML files for debugging.
  - `runner.py`: Manages the asynchronous execution of ADK agent tasks, including cancellation support.
  - `services.py`: Contains factory functions for initializing ADK services (session, artifact, memory) based on configuration.
  - `setup.py`: Handles the high-level initialization of the ADK agent, tools, and runner.
  - `stream_parser.py`: An internal utility for parsing fenced artifact blocks from an LLM's streaming response.
  - `tool_wrapper.py`: A wrapper for Python functions to make them compatible with ADK, handling embed resolution and config injection.
- **Subdirectories:**
  - `models/`: Contains concrete `BaseLlm` implementations for interfacing with various LLM providers.

## Developer API Reference

### Direct Files

#### app_llm_agent.py
**Purpose:** A custom `LlmAgent` subclass that includes a reference to its hosting component, allowing callbacks and tools to access host-level configurations and services.
**Import:** `from agent.adk.app_llm_agent import AppLlmAgent`

**Classes/Functions/Constants:**
- `AppLlmAgent(host_component: Any = None, **kwargs)`: A custom `LlmAgent` that can be linked to a host component. The `host_component` is set post-initialization and is excluded from serialization.

#### callbacks.py
**Purpose:** Provides a suite of ADK callback functions that hook into the agent's lifecycle to inject custom logic. These are typically not called directly but are assigned to the agent during setup.
**Import:** `from agent.adk import callbacks`

**Classes/Functions/Constants:**
- `inject_dynamic_instructions_callback(...)`: Injects instructions into the prompt based on host configuration, active tools, and peer agents.
- `manage_large_mcp_tool_responses_callback(...)`: Intercepts large tool responses, saves them as artifacts, and returns a truncated summary to the LLM.
- `after_tool_callback_inject_metadata(...)`: After a tool creates an artifact, this loads its metadata and injects it into the tool response.
- `process_artifact_blocks_callback(...)`: Processes streaming text to identify and save fenced artifact blocks (e.g., `«««save_artifact:...»»»`).
- `auto_continue_on_max_tokens_callback(...)`: Automatically continues a conversation if the LLM response was interrupted due to token limits.
- `notify_tool_invocation_start_callback(...)`: Sends a status update over Solace when a tool is about to be invoked.
- `solace_llm_invocation_callback(...)`: Sends a status update over Solace when the agent calls the LLM.

#### filesystem_artifact_service.py
**Purpose:** An implementation of `BaseArtifactService` that stores artifacts on the local filesystem, organized by scope, user, and session.
**Import:** `from agent.adk.filesystem_artifact_service import FilesystemArtifactService`

**Classes/Functions/Constants:**
- `FilesystemArtifactService(base_path: str, scope_identifier: str)`: A service for managing artifacts on the local disk.
  - `async save_artifact(...) -> int`: Saves an artifact and returns its version number.
  - `async load_artifact(...) -> Optional[adk_types.Part]`: Loads a specific version of an artifact, or the latest if unspecified.
  - `async list_artifact_keys(...) -> List[str]`: Lists the names of all artifacts for a given user/session.
  - `async delete_artifact(...)`: Deletes an artifact and all its versions.

#### invocation_monitor.py
**Purpose:** A debugging utility that logs the entire lifecycle of an agent invocation, from the initial request to the final response, into a structured YAML file.
**Import:** `from agent.adk.invocation_monitor import InvocationMonitor`

**Classes/Functions/Constants:**
- `InvocationMonitor()`: A class that monitors and logs agent message flows.
  - `log_message_event(direction: str, topic: str, payload: any, ...)`: Logs a single message event. The monitor automatically starts and stops logging based on topic patterns.
  - `cleanup()`: Finalizes any active logging sessions.

#### runner.py
**Purpose:** Provides the core asynchronous task execution logic for the ADK agent, including robust cancellation handling.
**Import:** `from agent.adk.runner import run_adk_async_task_thread_wrapper, TaskCancelledError`

**Classes/Functions/Constants:**
- `run_adk_async_task_thread_wrapper(component, adk_session, adk_content, ...)`: A high-level wrapper that runs an ADK task in a separate thread and handles all cleanup and error finalization.
- `TaskCancelledError(Exception)`: Custom exception raised when an agent task is cancelled externally.

#### services.py
**Purpose:** Provides factory functions to initialize the various ADK services based on the agent's configuration file.
**Import:** `from agent.adk.services import initialize_session_service, initialize_artifact_service, initialize_memory_service`

**Classes/Functions/Constants:**
- `initialize_session_service(component) -> BaseSessionService`: Creates a session service (e.g., `InMemorySessionService`).
- `initialize_artifact_service(component) -> BaseArtifactService`: Creates an artifact service (e.g., `FilesystemArtifactService`, `GcsArtifactService`).
- `initialize_memory_service(component) -> BaseMemoryService`: Creates a memory service (e.g., `InMemoryMemoryService`).

#### setup.py
**Purpose:** The main entry point for configuring and instantiating the ADK agent and its dependencies. These functions tie all the other modules together.
**Import:** `from agent.adk.setup import load_adk_tools, initialize_adk_agent, initialize_adk_runner`

**Classes/Functions/Constants:**
- `async load_adk_tools(component) -> Tuple[...]`: Loads all configured tools, including Python functions, MCP tools, and built-ins, wrapping them with `ADKToolWrapper`.
- `initialize_adk_agent(component, loaded_explicit_tools, ...)`: Creates an `AppLlmAgent` instance, assigns all the necessary callbacks from `callbacks.py`, and attaches the tools.
- `initialize_adk_runner(component)`: Creates an ADK `Runner` instance that orchestrates the agent execution.

#### stream_parser.py
**Purpose:** A stateful parser for extracting fenced artifact blocks from streaming LLM responses.
**Import:** `from agent.adk.stream_parser import FencedBlockStreamParser, BlockStartedEvent, BlockCompletedEvent`

**Classes/Functions/Constants:**
- `FencedBlockStreamParser(progress_update_interval_bytes: int = 4096)`: Parses streaming text to identify artifact blocks.
  - `process_chunk(text_chunk: str) -> ParserResult`: Processes a chunk of streaming text.
  - `finalize() -> ParserResult`: Finalizes parsing at the end of a stream.
- `BlockStartedEvent`, `BlockCompletedEvent`, `BlockInvalidatedEvent`: Events emitted during parsing.

#### tool_wrapper.py
**Purpose:** A wrapper that makes Python functions compatible with ADK by handling embed resolution and configuration injection.
**Import:** `from agent.adk.tool_wrapper import ADKToolWrapper`

**Classes/Functions/Constants:**
- `ADKToolWrapper(original_func, tool_config, tool_name, raw_string_args=None)`: Wraps a Python function for ADK compatibility.
  - `async __call__(*args, **kwargs)`: Executes the wrapped function with embed resolution and error handling.

### Subdirectory APIs

#### models/
**Purpose:** Contains concrete LLM client implementations that interface with various model providers.
**Key Exports:** `LiteLlm` class for accessing hundreds of models through the `litellm` library.
**Import Examples:**
```python
from agent.adk.models.lite_llm import LiteLlm
```

## Complete Usage Guide

### 1. Basic Agent Setup

```python
from agent.adk.setup import load_adk_tools, initialize_adk_agent, initialize_adk_runner
from agent.adk.services import initialize_session_service, initialize_artifact_service, initialize_memory_service
from agent.adk.models.lite_llm import LiteLlm

# Initialize services
session_service = initialize_session_service(component)
artifact_service = initialize_artifact_service(component)
memory_service = initialize_memory_service(component)

# Load tools
loaded_tools, builtin_tools = await load_adk_tools(component)

# Initialize agent
agent = initialize_adk_agent(component, loaded_tools, builtin_tools)

# Initialize runner
runner = initialize_adk_runner(component)
```

### 2. Custom LLM Configuration

```python
from agent.adk.models.lite_llm import LiteLlm

# Configure LiteLlm for different providers
openai_model = LiteLlm(
    model="gpt-4-turbo",
    temperature=0.7,
    max_tokens=2048
)

anthropic_model = LiteLlm(
    model="claude-3-opus-20240229",
    temperature=0.5
)

vertex_model = LiteLlm(
    model="vertex_ai/gemini-pro",
    temperature=0.3
)
```

### 3. Artifact Service Usage

```python
from agent.adk.filesystem_artifact_service import FilesystemArtifactService
from google.genai import types as adk_types

# Initialize filesystem artifact service
artifact_service = FilesystemArtifactService(
    base_path="/path/to/artifacts",
    scope_identifier="my_agent"
)

# Save an artifact
content = b"Hello, world!"
artifact = adk_types.Part.from_bytes(content, "text/plain")
version = await artifact_service.save_artifact(
    app_name="my_app",
    user_id="user123",
    session_id="session456",
    filename="greeting.txt",
    artifact=artifact
)

# Load an artifact
loaded_artifact = await artifact_service.load_artifact(
    app_name="my_app",
    user_id="user123", 
    session_id="session456",
    filename="greeting.txt",
    version=version
)
```

### 4. Tool Wrapper Usage

```python
from agent.adk.tool_wrapper import ADKToolWrapper

def my_custom_tool(query: str, tool_config: dict = None):
    """A custom tool that processes queries."""
    return {"result": f"Processed: {query}"}

# Wrap the tool for ADK compatibility
wrapped_tool = ADKToolWrapper(
    original_func=my_custom_tool,
    tool_config={"setting": "value"},
    tool_name="my_custom_tool"
)

# The wrapper handles embed resolution and error handling automatically
```

### 5. Running Agent Tasks

```python
from agent.adk.runner import run_adk_async_task_thread_wrapper
from google.genai import types as adk_types
from google.adk.agents import RunConfig

# Create input content
content = adk_types.Content(
    role="user",
    parts=[adk_types.Part.from_text("Hello, how can you help me?")]
)

# Configure run parameters
run_config = RunConfig(
    max_llm_calls=10,
    max_tool_calls=20
)

# Execute the task
await run_adk_async_task_thread_wrapper(
    component=component,
    adk_session=session,
    adk_content=content,
    run_config=run_config,
    a2a_context={"logical_task_id": "task123"}
)
```

### 6. Monitoring and Debugging

```python
from agent.adk.invocation_monitor import InvocationMonitor

# Initialize monitor
monitor = InvocationMonitor()

# Log message events
monitor.log_message_event(
    direction="inbound",
    topic="a2a/v1/agent/request/MyAgent",
    payload={"method": "tasks/sendSubscribe", "params": {...}},
    component_identifier="MyAgent"
)

# Cleanup when done
monitor.cleanup()
```

### 7. Custom Callbacks

```python
from agent.adk import callbacks
import functools

# Use built-in callbacks with component reference
dynamic_instructions_callback = functools.partial(
    callbacks.inject_dynamic_instructions_callback,
    host_component=component,
    active_builtin_tools=builtin_tools
)

# Assign to agent
agent.before_model_callback = dynamic_instructions_callback
```

### 8. Working with Streaming Responses

```python
from agent.adk.stream_parser import FencedBlockStreamParser

# Initialize parser for artifact blocks
parser = FencedBlockStreamParser(progress_update_interval_bytes=1024)

# Process streaming chunks
for chunk in llm_stream:
    result = parser.process_chunk(chunk)
    
    # Handle user-facing text
    if result.user_facing_text:
        print(result.user_facing_text, end="")
    
    # Handle parser events
    for event in result.events:
        if isinstance(event, BlockStartedEvent):
            print(f"Artifact started: {event.params}")
        elif isinstance(event, BlockCompletedEvent):
            print(f"Artifact completed: {event.params}")

# Finalize at end of stream
final_result = parser.finalize()
```

This comprehensive guide shows how the various components of the `adk` directory work together to create a powerful, extensible AI agent framework that integrates seamlessly with Solace messaging and supports a wide variety of LLM providers and tools.

# content_hash: 17e0a9a7d0e60610a97ba81b7966cec2ac26232a286206c3269727499500d4ba

================================================================================

## Section 2: agent/adk/models/models_llm.txt

**Source file:** `agent/adk/models/models_llm.txt`

# DEVELOPER GUIDE: models

## Quick Summary
The `models` directory contains concrete implementations of Large Language Model (LLM) clients that wrap various LLM APIs. These classes provide a standardized interface for interacting with different LLM providers by translating ADK's `LlmRequest` format to provider-specific formats and parsing responses back to standardized `LlmResponse` objects.

## Files Overview
- `lite_llm.py` - LLM client wrapper using the `litellm` library to support hundreds of models from various providers (OpenAI, Anthropic, Vertex AI, etc.)

## Developer API Reference

### lite_llm.py
**Purpose:** Provides the `LiteLlm` class, a `BaseLlm` implementation that interfaces with hundreds of LLM models through the `litellm` library. Supports models from OpenAI, Anthropic, Vertex AI, and many other providers by simply changing the model string.

**Import:** `from google.adk.models.lite_llm import LiteLlm`

**Classes:**
- `LiteLlm(model: str, **kwargs)` - Wrapper around `litellm` for accessing various LLM providers
  - `generate_content_async(llm_request: LlmRequest, stream: bool = False) -> AsyncGenerator[LlmResponse, None]` - Generates content asynchronously with optional streaming
  - `supported_models() -> list[str]` - Returns list of supported models (empty for LiteLlm as it supports dynamic model list)
  - `model: str` - The name of the LiteLlm model
  - `llm_client: LiteLLMClient` - The LLM client instance used for API calls

- `LiteLLMClient()` - Internal client for making API calls (used for testability)
  - `acompletion(model, messages, tools, **kwargs) -> Union[ModelResponse, CustomStreamWrapper]` - Asynchronous completion call
  - `completion(model, messages, tools, stream=False, **kwargs) -> Union[ModelResponse, CustomStreamWrapper]` - Synchronous completion call

- `FunctionChunk(BaseModel)` - Represents a function call chunk in streaming responses
  - `id: Optional[str]` - Function call ID
  - `name: Optional[str]` - Function name
  - `args: Optional[str]` - Function arguments as JSON string
  - `index: Optional[int]` - Index of the function call

- `TextChunk(BaseModel)` - Represents a text chunk in streaming responses
  - `text: str` - The text content

- `UsageMetadataChunk(BaseModel)` - Represents usage metadata in streaming responses
  - `prompt_tokens: int` - Number of prompt tokens
  - `completion_tokens: int` - Number of completion tokens
  - `total_tokens: int` - Total number of tokens

**Functions:**
- `supported_models() -> list[str]` - Static method that returns supported models list

**Usage Examples:**
```python
import asyncio
import os
from google.adk.models.lite_llm import LiteLlm
from google.adk.models.llm_request import LlmRequest, LlmConfig
from google.genai import types

# Set up environment variables for your chosen provider
# For OpenAI:
# os.environ["OPENAI_API_KEY"] = "your-api-key"
# For Vertex AI:
# os.environ["VERTEXAI_PROJECT"] = "your-project-id"
# os.environ["VERTEXAI_LOCATION"] = "your-location"

async def basic_usage():
    # Initialize LiteLlm with a specific model
    llm = LiteLlm(
        model="gpt-4-turbo",
        temperature=0.7,
        max_tokens=150
    )
    
    # Create a request
    request = LlmRequest(
        contents=[
            types.Content(
                role="user",
                parts=[types.Part.from_text("Explain quantum computing in simple terms.")]
            )
        ],
        config=LlmConfig(temperature=0.5)
    )
    
    # Non-streaming response
    async for response in llm.generate_content_async(request, stream=False):
        print(f"Response: {response.text}")
        if response.usage_metadata:
            print(f"Tokens used: {response.usage_metadata.total_token_count}")

async def streaming_usage():
    llm = LiteLlm(model="claude-3-opus-20240229")
    
    request = LlmRequest(
        contents=[
            types.Content(
                role="user", 
                parts=[types.Part.from_text("Write a short story about AI.")]
            )
        ]
    )
    
    # Streaming response
    print("Streaming response:")
    async for response in llm.generate_content_async(request, stream=True):
        if response.text:
            print(response.text, end="", flush=True)
        if response.usage_metadata:
            print(f"\nTotal tokens: {response.usage_metadata.total_token_count}")

async def function_calling_usage():
    # Define a function for the LLM to call
    weather_function = types.FunctionDeclaration(
        name="get_weather",
        description="Get current weather for a location",
        parameters=types.Schema(
            type=types.Type.OBJECT,
            properties={
                "location": types.Schema(
                    type=types.Type.STRING,
                    description="City name"
                )
            },
            required=["location"]
        )
    )
    
    llm = LiteLlm(model="gpt-4-turbo")
    
    request = LlmRequest(
        contents=[
            types.Content(
                role="user",
                parts=[types.Part.from_text("What's the weather like in Tokyo?")]
            )
        ],
        config=LlmConfig(
            tools=[types.Tool(function_declarations=[weather_function])]
        )
    )
    
    async for response in llm.generate_content_async(request):
        if response.function_calls:
            for func_call in response.function_calls:
                print(f"Function called: {func_call.name}")
                print(f"Arguments: {func_call.args}")

async def vertex_ai_usage():
    # Using Vertex AI models through LiteLlm
    os.environ["VERTEXAI_PROJECT"] = "your-gcp-project-id"
    os.environ["VERTEXAI_LOCATION"] = "your-gcp-location"
    
    llm = LiteLlm(model="vertex_ai/claude-3-7-sonnet@20250219")
    
    request = LlmRequest(
        contents=[
            types.Content(
                role="user",
                parts=[types.Part.from_text("Summarize the benefits of cloud computing.")]
            )
        ],
        config=LlmConfig(
            temperature=0.3,
            max_output_tokens=200
        )
    )
    
    async for response in llm.generate_content_async(request):
        print(f"Vertex AI Response: {response.text}")

# Run examples
if __name__ == "__main__":
    # Uncomment to run examples (ensure environment variables are set)
    # asyncio.run(basic_usage())
    # asyncio.run(streaming_usage())
    # asyncio.run(function_calling_usage())
    # asyncio.run(vertex_ai_usage())
    pass
```

# content_hash: 53b50802d5729266fa0ba5df7d713dd050a91a629ab528e7567ed8780b35413e

================================================================================

## Section 3: agent/agent_llm.txt

**Source file:** `agent/agent_llm.txt`

# DEVELOPER GUIDE: agent

## Quick Summary
The `agent` directory provides a comprehensive framework for hosting Google ADK (Agent Development Kit) agents within the Solace AI Connector ecosystem. It bridges ADK agents with the A2A (Agent-to-Agent) protocol over Solace messaging, enabling distributed agent communication, task delegation, and rich tool functionality.

The architecture is modular, consisting of several key components:
- **`sac/` (Solace AI Connector):** The main entry point, providing the `SamAgentApp` and `SamAgentComponent` to host the agent and manage its lifecycle and communication over the Solace event mesh.
- **`adk/` (Agent Development Kit):** The core integration layer with Google's ADK. It defines the custom `AppLlmAgent`, manages asynchronous task execution, and provides a rich set of callbacks to augment agent behavior.
- **`tools/`:** A comprehensive and extensible library of tools available to the agent, covering data analysis, artifact management, web requests, multimedia processing, and inter-agent communication.
- **`protocol/`:** The underlying implementation of the A2A (Agent-to-Agent) communication protocol, handling message routing and event processing.
- **`utils/`:** A collection of helper modules for common tasks like artifact management, configuration parsing, and context handling.
- **`testing/`:** Utilities to aid in debugging and testing custom agent implementations.

These components work together to create a robust environment where an ADK agent can be configured with specific instructions and tools, communicate with other agents, and execute complex tasks in a distributed, event-driven manner.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: An empty file that marks the `agent` directory as a Python package.
- **Subdirectories:**
  - `adk/`: Provides the core integration layer with Google's ADK, including custom agents, services, and callbacks.
  - `protocol/`: Implements the A2A protocol event handlers for message routing and agent communication.
  - `sac/`: Contains the Solace AI Connector app and component implementations for hosting ADK agents.
  - `testing/`: Provides utilities for testing the A2A framework and debugging agent behavior.
  - `tools/`: A comprehensive, registry-based tool library for AI agents.
  - `utils/`: Contains helper utilities for configuration, context handling, and artifact management.

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Standard Python package initializer. It allows the `agent` directory to be treated as a package.
**Import:** `import agent`

**Classes/Functions/Constants:** [None]

### Subdirectory APIs

#### adk/
**Purpose:** Provides the core integration layer between the Solace AI Connector and Google's ADK.
**Key Exports:** `AppLlmAgent`, `initialize_adk_agent`, `initialize_adk_runner`, `load_adk_tools`, `FilesystemArtifactService`, `LiteLlm`
**Import Examples:**
```python
from agent.adk.app_llm_agent import AppLlmAgent
from agent.adk.setup import load_adk_tools, initialize_adk_agent, initialize_adk_runner
from agent.adk.filesystem_artifact_service import FilesystemArtifactService
from agent.adk.models.lite_llm import LiteLlm
from agent.adk.runner import run_adk_async_task_thread_wrapper
```

#### protocol/
**Purpose:** Implements the core A2A protocol event handling and message routing.
**Key Exports:** `process_event`, `handle_a2a_request`, `handle_agent_card_message`, `publish_agent_card`
**Import Examples:**
```python
from agent.protocol.event_handlers import process_event, handle_a2a_request, publish_agent_card
```

#### sac/
**Purpose:** Provides the Solace AI Connector app and component for hosting ADK agents.
**Key Exports:** `SamAgentApp`, `SamAgentComponent`, `TaskExecutionContext`
**Import Examples:**
```python
from agent.sac.app import SamAgentApp
from agent.sac.component import SamAgentComponent
from agent.sac.task_execution_context import TaskExecutionContext
```

#### testing/
**Purpose:** Provides debugging utilities for testing agent implementations.
**Key Exports:** `pretty_print_event_history`
**Import Examples:**
```python
from agent.testing.debug_utils import pretty_print_event_history
```

#### tools/
**Purpose:** Comprehensive registry-based tool library for AI agents.
**Key Exports:** `tool_registry`, `BuiltinTool`, `PeerAgentTool`, and various tool functions
**Import Examples:**
```python
from agent.tools.registry import tool_registry
from agent.tools.tool_definition import BuiltinTool
from agent.tools.peer_agent_tool import PeerAgentTool
from agent.tools.builtin_artifact_tools import list_artifacts, load_artifact
from agent.tools.audio_tools import text_to_speech
from agent.tools.image_tools import create_image_from_description
```

#### utils/
**Purpose:** Helper utilities for artifact management, configuration, and context handling.
**Key Exports:** Artifact helpers, config parsers, and context utilities
**Import Examples:**
```python
from agent.utils.artifact_helpers import save_artifact_with_metadata, load_artifact_content_or_metadata
from agent.utils.config_parser import resolve_instruction_provider
from agent.utils.context_helpers import get_session_from_callback_context
```

## Complete Usage Guide

### 1. Setting Up a Complete Agent

```python
from agent.sac.app import SamAgentApp
from agent.sac.component import SamAgentComponent
from agent.adk.setup import load_adk_tools, initialize_adk_agent, initialize_adk_runner
from agent.adk.services import initialize_session_service, initialize_artifact_service, initialize_memory_service
from agent.adk.models.lite_llm import LiteLlm

# Create the SAC app (typically done via YAML config)
app = SamAgentApp({
    "namespace": "my-org/production",
    "agent_name": "customer-support-agent",
    "model": "gpt-4-turbo",
    "tools": [
        {"tool_type": "builtin", "tool_name": "list_artifacts"},
        {"tool_type": "builtin", "tool_name": "text_to_speech"}
    ]
})

# Initialize component
component = SamAgentComponent()

# Initialize services
session_service = initialize_session_service(component)
artifact_service = initialize_artifact_service(component)
memory_service = initialize_memory_service(component)

# Load tools and initialize agent
loaded_tools, builtin_tools = await load_adk_tools(component)
agent = initialize_adk_agent(component, loaded_tools, builtin_tools)
runner = initialize_adk_runner(component)
```

### 2. Creating Custom Tools

```python
from agent.tools.tool_definition import BuiltinTool
from agent.tools.registry import tool_registry
from google.genai import types as adk_types

# Define a custom tool function
async def my_custom_tool(query: str, tool_context=None, tool_config=None):
    """Processes a custom query and returns results."""
    # Access host component if needed
    host_component = tool_context.host_component if tool_context else None
    
    # Your custom logic here
    result = f"Processed: {query}"
    
    return {"result": result, "status": "success"}

# Create tool definition
custom_tool = BuiltinTool(
    name="my_custom_tool",
    implementation=my_custom_tool,
    description="A custom tool that processes queries",
    parameters=adk_types.Schema(
        type=adk_types.Type.OBJECT,
        properties={
            "query": adk_types.Schema(
                type=adk_types.Type.STRING,
                description="The query to process"
            )
        },
        required=["query"]
    ),
    category="custom"
)

# Register the tool
tool_registry.register(custom_tool)
```

### 3. Working with Artifacts

```python
from agent.utils.artifact_helpers import save_artifact_with_metadata, load_artifact_content_or_metadata
from agent.tools.builtin_artifact_tools import list_artifacts, load_artifact
import datetime

# Save an artifact with metadata
csv_data = b"name,age\nAlice,30\nBob,25"
result = await save_artifact_with_metadata(
    artifact_service=artifact_service,
    app_name="my_app",
    user_id="user123",
    session_id="session456",
    filename="employee_data.csv",
    content_bytes=csv_data,
    mime_type="text/csv",
    metadata_dict={
        "source": "hr_system",
        "description": "Employee demographics",
        "created_by": "data_import_tool"
    },
    timestamp=datetime.datetime.now(datetime.timezone.utc)
)

# List all artifacts using the tool
artifacts_list = await list_artifacts(tool_context=tool_context)

# Load specific artifact
loaded_artifact = await load_artifact(
    filename="employee_data.csv",
    version=1,
    tool_context=tool_context
)
```

### 4. Agent-to-Agent Communication

```python
from agent.tools.peer_agent_tool import PeerAgentTool
from common.types import A2AMessage, TextPart

# Create a peer agent tool for delegation
peer_tool = PeerAgentTool(
    target_agent_name="data_analyst_agent",
    host_component=component
)

# Submit a task to another agent (typically done by the LLM)
async def delegate_analysis_task(component, data_description):
    message = A2AMessage(
        role="user",
        parts=[TextPart(text=f"Please analyze this data: {data_description}")]
    )
    
    sub_task_id = component.submit_a2a_task(
        target_agent_name="data_analyst_agent",
        a2a_message=message,
        original_session_id="session123",
        main_logical_task_id="task456",
        user_id="user789",
        user_config={},
        sub_task_id="analysis_001"
    )
    return sub_task_id
```

### 5. Multimedia Processing

```python
from agent.tools.audio_tools import text_to_speech, multi_speaker_text_to_speech
from agent.tools.image_tools import create_image_from_description, describe_image

# Generate audio from text
audio_result = await text_to_speech(
    text="Welcome to our customer service. How can I help you today?",
    output_filename="greeting.mp3",
    gender="female",
    tone="friendly",
    language="en-US",
    tool_context=tool_context
)

# Create multi-speaker conversation
conversation_result = await multi_speaker_text_to_speech(
    conversation_text="Agent: How can I help?\nCustomer: I need account information.",
    speaker_configs=[
        {"name": "Agent", "gender": "female", "tone": "professional"},
        {"name": "Customer", "gender": "male", "tone": "neutral"}
    ],
    tool_context=tool_context
)

# Generate image
image_result = await create_image_from_description(
    image_description="A professional customer service representative at a modern desk",
    output_filename="service_rep.png",
    tool_context=tool_context
)

# Analyze existing image
description = await describe_image(
    image_filename="uploaded_document.jpg",
    prompt="Extract all text and identify the document type",
    tool_context=tool_context
)
```

### 6. Event Processing and Protocol Handling

```python
from agent.protocol.event_handlers import process_event, publish_agent_card
from solace_ai_connector.common.event import Event, EventType

# Process incoming events (typically handled by the framework)
async def handle_incoming_event(component, event):
    await process_event(component, event)

# Publish agent capabilities
publish_agent_card(component)
```

### 7. Testing and Debugging

```python
from agent.testing.debug_utils import pretty_print_event_history
from agent.adk.invocation_monitor import InvocationMonitor

# Set up monitoring for debugging
monitor = InvocationMonitor()

# Log events during testing
monitor.log_message_event(
    direction="inbound",
    topic="a2a/v1/agent/request/MyAgent",
    payload={"method": "tasks/sendSubscribe", "params": {...}},
    component_identifier="MyAgent"
)

# Debug test failures
def test_agent_behavior():
    event_history = []
    try:
        # Your test code here
        pass
    except AssertionError:
        pretty_print_event_history(event_history)
        raise
    finally:
        monitor.cleanup()
```

### 8. Custom Configuration and Initialization

```python
from agent.utils.config_parser import resolve_instruction_provider
from agent.utils.context_helpers import get_session_from_callback_context

# Custom initialization function
def initialize_my_agent(host_component, config):
    """Custom agent initialization."""
    # Set up database connection
    db_config = config.get('database', {})
    db_connection = create_database_connection(db_config)
    host_component.set_agent_specific_state('db_connection', db_connection)
    
    # Configure dynamic instructions
    def dynamic_instructions(context):
        user_id = context.get('user_id', 'unknown')
        return f"You are a customer service agent helping user {user_id}."
    
    host_component.set_agent_system_instruction_callback(dynamic_instructions)

# Use in tool functions
async def database_query_tool(query: str, tool_context=None):
    """Tool that queries the database."""
    if tool_context and tool_context.host_component:
        db_connection = tool_context.host_component.get_agent_specific_state('db_connection')
        if db_connection:
            return db_connection.execute(query)
    return {"error": "Database not available"}
```

This comprehensive guide demonstrates how all components of the `agent` directory work together to create a powerful, distributed AI agent system that can handle complex tasks, communicate with other agents, process multimedia content, and maintain rich state and artifact management.

# content_hash: b3bf3006eccb057ecef51660d32a4e3a95efd6c563dff669b4151baa89cb70e4

================================================================================

## Section 4: agent/protocol/protocol_llm.txt

**Source file:** `agent/protocol/protocol_llm.txt`

## Quick Summary
The `protocol` directory implements the core logic for Agent-to-Agent (A2A) communication. It handles receiving and processing requests, responses, and discovery messages (Agent Cards) over the Solace event mesh. It acts as the bridge between the A2A protocol and the underlying Google ADK execution environment.

## Files Overview
- `__init__.py` - An empty file that marks the directory as a Python package.
- `event_handlers.py` - Contains the primary logic for handling all A2A protocol events, including routing incoming messages to the correct processors, managing task execution, and handling agent discovery.

## Developer API Reference

### __init__.py
**Purpose:** Standard Python package initialization file.
**Import:** `from agent.protocol import *`

This is an empty package initialization file and has no public interfaces.

### event_handlers.py
**Purpose:** This file is the central hub for processing all events related to the A2A protocol. It receives events from the Solace AI Connector framework, determines their type (e.g., new task request, peer agent response, discovery message, timer), and routes them to the appropriate handler function. It manages the lifecycle of tasks, from initiation and cancellation to handling responses from peer agents.
**Import:** `from agent.protocol.event_handlers import process_event, handle_a2a_request, handle_agent_card_message, handle_a2a_response, publish_agent_card`

**Functions:**
- `process_event(component: "SamAgentComponent", event: Event) -> None` - Main event router that processes all incoming events (messages, timers, cache expiry) and delegates to appropriate handlers
- `handle_a2a_request(component: "SamAgentComponent", message: SolaceMessage) -> None` - Handles incoming A2A task requests (SendTask, SendTaskStreaming, CancelTask) and initiates ADK execution
- `handle_agent_card_message(component: "SamAgentComponent", message: SolaceMessage) -> None` - Processes agent discovery messages and updates the peer agent registry
- `handle_a2a_response(component: "SamAgentComponent", message: SolaceMessage) -> None` - Handles responses from peer agents and manages parallel task completion
- `publish_agent_card(component: "SamAgentComponent") -> None` - Publishes the agent's capabilities and information to the discovery topic

**Private Functions:**
- `_format_artifact_summary_from_manifest(component: "SamAgentComponent", produced_artifacts: List[Dict[str, Any]], peer_agent_name: str, correlation_data: Dict[str, Any]) -> str` - Formats artifact metadata into human-readable YAML summary
- `_register_peer_artifacts_in_parent_context(parent_task_context: "TaskExecutionContext", peer_task_object: Task, log_identifier: str) -> None` - Registers artifacts from peer agents in the parent task context

**Usage Examples:**
```python
# Main event processing (typically called by the SAC framework)
from agent.protocol.event_handlers import process_event
from solace_ai_connector.common.event import Event, EventType

# Process an incoming message event
await process_event(component, event)

# Manually publish agent card (typically done on timer)
from agent.protocol.event_handlers import publish_agent_card
publish_agent_card(component)

# Handle specific message types (usually called internally by process_event)
from agent.protocol.event_handlers import handle_a2a_request, handle_agent_card_message
await handle_a2a_request(component, solace_message)
handle_agent_card_message(component, solace_message)
```

**Key Integration Points:**
- Integrates with `SamAgentComponent` for task management and configuration
- Uses `TaskExecutionContext` for tracking active tasks and parallel execution
- Leverages the ADK runner for actual agent execution
- Manages artifact handling and peer agent communication
- Handles session management for both persistent and run-based sessions

# content_hash: be0edddbc86e00baa0e1602247dc7305a2b84e37c0a2be13906f4c8aea60f6ac

================================================================================

## Section 5: agent/sac/sac_llm.txt

**Source file:** `agent/sac/sac_llm.txt`

# DEVELOPER GUIDE for sac

## Quick Summary
The `sac` (Solace AI Connector) directory provides the core implementation for hosting a Google ADK (Agent Development Kit) agent within the Solace AI Connector framework. It acts as a bridge, enabling ADK agents to communicate using the A2A (Agent-to-Agent) protocol over Solace messaging. This allows for the creation of distributed, collaborative agent systems where agents can delegate tasks, share information, and work together to solve complex problems.

## Files Overview
- `__init__.py` - Empty package marker file
- `app.py` - Custom SAC App class that automatically configures Solace subscriptions and broker settings for A2A communication
- `component.py` - Main SAC Component that hosts the ADK agent, manages its lifecycle, and handles all A2A protocol messaging
- `patch_adk.py` - Runtime patches for the Google ADK library to enhance or correct its behavior
- `task_execution_context.py` - State management class that encapsulates all runtime information for a single, in-flight A2A task

## Developer API Reference

### app.py
**Purpose:** Provides a custom SAC App class that simplifies the configuration of an A2A agent
**Import:** `from agent.sac.app import SamAgentApp`

**Classes:**
- `SamAgentApp(app_info: Dict[str, Any], **kwargs)` - Custom App class for SAM Agent Host with automatic subscription generation and namespace prefixing
  - `app_schema: Dict` - Class attribute defining comprehensive configuration schema for agent validation

**Constants/Variables:**
- `info: Dict[str, str]` - Metadata dictionary about the SamAgentApp class

**Usage Examples:**
```python
# SamAgentApp is typically instantiated by the SAC framework from YAML config
# Example agent-config.yaml:
app:
  class_name: agent.sac.app.SamAgentApp
  app_config:
    namespace: "my-org/production"
    agent_name: "customer-support-agent"
    model: "gemini-1.5-pro-latest"
    tools:
      - tool_type: "builtin"
        tool_name: "file_search"
    agent_card:
      description: "An agent that can answer questions about customer accounts."
    agent_card_publishing:
      interval_seconds: 60
    session_service:
      type: "memory"
```

### component.py
**Purpose:** Core component that hosts a Google ADK agent and bridges communication to A2A protocol
**Import:** `from agent.sac.component import SamAgentComponent`

**Classes:**
- `SamAgentComponent(**kwargs)` - Solace AI Connector component that hosts a Google ADK agent
  - `process_event(self, event: Event) -> None` - Main entry point for all SAC framework events
  - `handle_timer_event(self, timer_data: Dict[str, Any]) -> None` - Handles scheduled timer events
  - `handle_cache_expiry_event(self, cache_data: Dict[str, Any]) -> None` - Handles cache expiry events for peer timeouts
  - `finalize_task_success(self, a2a_context: Dict) -> None` - Async method to finalize successful tasks
  - `finalize_task_canceled(self, a2a_context: Dict) -> None` - Finalizes cancelled tasks
  - `finalize_task_error(self, exception: Exception, a2a_context: Dict) -> None` - Async method to finalize failed tasks
  - `cleanup(self) -> None` - Cleans up resources on component shutdown
  - `set_agent_specific_state(self, key: str, value: Any) -> None` - Sets agent-specific state for custom init functions
  - `get_agent_specific_state(self, key: str, default: Optional[Any] = None) -> Any` - Retrieves agent-specific state
  - `get_async_loop(self) -> Optional[asyncio.AbstractEventLoop]` - Returns the component's dedicated async event loop
  - `set_agent_system_instruction_string(self, instruction_string: str) -> None` - Sets static system prompt injection
  - `set_agent_system_instruction_callback(self, callback_function: Callable) -> None` - Sets dynamic system prompt callback
  - `get_gateway_id(self) -> str` - Returns unique identifier for this agent host instance
  - `submit_a2a_task(self, target_agent_name: str, a2a_message: A2AMessage, original_session_id: str, main_logical_task_id: str, user_id: str, user_config: Dict[str, Any], sub_task_id: str, function_call_id: Optional[str] = None) -> str` - Submits task to peer agent
  - `get_agent_context(self) -> Dict[str, Any]` - Returns agent context for middleware interactions

**Constants/Variables:**
- `info: Dict` - Metadata about the SamAgentComponent class
- `CORRELATION_DATA_PREFIX: str` - Prefix for cache keys when tracking peer requests
- `HOST_COMPONENT_VERSION: str` - Version string of the host component

**Usage Examples:**
```python
# Custom initialization function example
from agent.sac.component import SamAgentComponent

def initialize_my_agent(host_component: SamAgentComponent, config: dict):
    """Custom initialization function for the agent."""
    # Store database connection in agent state
    db_connection = create_database_connection(config.get('db_url'))
    host_component.set_agent_specific_state('db_connection', db_connection)
    
    # Set custom system instruction
    host_component.set_agent_system_instruction_string(
        "You are a specialized customer service agent with access to our database."
    )

# Tool accessing agent state
def my_custom_tool(host_component: SamAgentComponent, query: str) -> str:
    """Tool that uses stored database connection."""
    db_connection = host_component.get_agent_specific_state('db_connection')
    if db_connection:
        return db_connection.execute_query(query)
    return "Database not available"

# Submitting task to peer agent
async def delegate_to_specialist(host_component: SamAgentComponent, task_description: str):
    from common.types import A2AMessage, TextPart
    
    message = A2AMessage(
        role="user",
        parts=[TextPart(text=task_description)]
    )
    
    sub_task_id = host_component.submit_a2a_task(
        target_agent_name="specialist-agent",
        a2a_message=message,
        original_session_id="session123",
        main_logical_task_id="task456",
        user_id="user789",
        user_config={},
        sub_task_id="subtask001"
    )
    return sub_task_id
```

### patch_adk.py
**Purpose:** Contains runtime patches for the Google ADK library to enhance behavior
**Import:** `from agent.sac.patch_adk import patch_adk`

**Functions:**
- `patch_adk() -> None` - Applies all necessary patches to the ADK library

**Usage Examples:**
```python
from agent.sac.patch_adk import patch_adk

# Apply patches before using ADK
patch_adk()
```

### task_execution_context.py
**Purpose:** Encapsulates runtime state for a single, in-flight agent task
**Import:** `from agent.sac.task_execution_context import TaskExecutionContext`

**Classes:**
- `TaskExecutionContext(task_id: str, a2a_context: Dict[str, Any])` - Runtime state container for agent tasks
  - `cancel(self) -> None` - Signals that the task should be cancelled
  - `is_cancelled(self) -> bool` - Checks if cancellation event has been set
  - `append_to_streaming_buffer(self, text: str) -> None` - Appends text to streaming buffer
  - `flush_streaming_buffer(self) -> str` - Returns and clears streaming buffer content
  - `get_streaming_buffer_content(self) -> str` - Returns buffer content without clearing
  - `append_to_run_based_buffer(self, text: str) -> None` - Appends text to run-based response buffer
  - `register_peer_sub_task(self, sub_task_id: str, peer_agent_name: str) -> None` - Tracks peer sub-tasks
  - `register_parallel_call_sent(self, invocation_id: str) -> None` - Registers parallel tool calls
  - `handle_peer_timeout(self, sub_task_id: str, correlation_data: Dict, timeout_sec: int, invocation_id: str) -> bool` - Handles peer timeouts
  - `record_parallel_result(self, result: Dict, invocation_id: str) -> bool` - Records parallel call results
  - `clear_parallel_invocation_state(self, invocation_id: str) -> None` - Cleans up invocation state
  - `register_produced_artifact(self, filename: str, version: int) -> None` - Tracks created artifacts
  - `add_artifact_signal(self, signal: Dict[str, Any]) -> None` - Adds artifact return signals
  - `get_and_clear_artifact_signals(self) -> List[Dict[str, Any]]` - Retrieves and clears artifact signals
  - `set_event_loop(self, loop: asyncio.AbstractEventLoop) -> None` - Stores event loop reference
  - `get_event_loop(self) -> Optional[asyncio.AbstractEventLoop]` - Retrieves stored event loop

**Usage Examples:**
```python
from agent.sac.task_execution_context import TaskExecutionContext

# Create task context
context = TaskExecutionContext("task123", {"user_id": "user456"})

# Use streaming buffer
context.append_to_streaming_buffer("Hello ")
context.append_to_streaming_buffer("world!")
content = context.flush_streaming_buffer()  # Returns "Hello world!"

# Track parallel calls
context.register_parallel_call_sent("invocation1")
context.register_parallel_call_sent("invocation1")  # Second call for same invocation

# Record results
result1 = {"adk_function_call_id": "call1", "peer_tool_name": "tool1", "payload": {"result": "success"}}
all_complete = context.record_parallel_result(result1, "invocation1")  # Returns False

result2 = {"adk_function_call_id": "call2", "peer_tool_name": "tool2", "payload": {"result": "success"}}
all_complete = context.record_parallel_result(result2, "invocation1")  # Returns True

# Cancel task
context.cancel()
if context.is_cancelled():
    print("Task was cancelled")
```

# content_hash: 986b09a08268f49a006b6e8435b9988b92585e71967fa71febe9f466f3e715a6

================================================================================

## Section 6: agent/testing/testing_llm.txt

**Source file:** `agent/testing/testing_llm.txt`

## Quick Summary

The `testing` directory provides utilities for testing the A2A (Agent-to-Agent) framework. It contains debugging tools that help developers understand test failures by providing human-readable representations of agent event histories and interactions.

## Files Overview

- `__init__.py` - Package initialization file marking the directory as a Python module
- `debug_utils.py` - Debugging utilities including pretty-printing for A2A event history
- `testing_llm.txt` - Documentation file (not a code module)

## Developer API Reference

### debug_utils.py
**Purpose:** Provides debugging utilities for the declarative test framework, including a pretty-printer for A2A event history
**Import:** `from agent.testing.debug_utils import pretty_print_event_history`

**Functions:**
- `pretty_print_event_history(event_history: List[Dict[str, Any]], max_string_length: int = 200) -> None` - Formats and prints a list of A2A event payloads for debugging. Intelligently parses different event types (status updates, final responses, errors, artifacts) and displays them in a structured, readable format with string truncation for concise output.

**Usage Examples:**
```python
# Import the debugging utility
from agent.testing.debug_utils import pretty_print_event_history
from typing import List, Dict, Any

# Example: Debug a failed test by printing event history
def test_agent_task():
    event_history = []
    try:
        # Your test code here that populates event_history
        # ... test execution ...
        pass
    except AssertionError:
        # Print event history when test fails
        pretty_print_event_history(event_history)
        raise

# Example: Print event history with custom string length limit
sample_events = [
    {
        "result": {
            "status": {
                "state": "EXECUTING",
                "message": {
                    "parts": [
                        {"type": "text", "text": "Processing your request..."}
                    ]
                }
            },
            "final": False
        }
    },
    {
        "error": {
            "code": "TIMEOUT",
            "message": "Request timed out after 30 seconds"
        }
    }
]

# Print with shorter string truncation
pretty_print_event_history(sample_events, max_string_length=50)

# Handle empty event history (no events recorded)
pretty_print_event_history([])
```

# content_hash: d9352844683547bf3473ba718b29c8a10641f0100d334388ebe9c6e1be58cf9b

================================================================================

## Section 7: agent/tools/tools_llm.txt

**Source file:** `agent/tools/tools_llm.txt`

# DEVELOPER GUIDE: tools

## Quick Summary
The `tools` directory contains the complete set of built-in tools available to the agent. It follows a declarative, registry-based pattern where each tool module defines its functions and registers them with a central `tool_registry`. This allows for automatic discovery and dynamic availability of tools based on configuration and agent capabilities. The tools cover a wide range of functionalities including artifact management, audio/image processing, data analysis, web requests, and inter-agent communication.

## Files Overview
- `__init__.py` - Imports all tool modules, triggering their registration with the central registry
- `audio_tools.py` - Provides tools for text-to-speech (TTS), multi-speaker TTS, audio concatenation, and transcription
- `builtin_artifact_tools.py` - Contains core tools for creating, listing, loading, modifying, and deleting artifacts
- `builtin_data_analysis_tools.py` - Offers tools for generating charts from Plotly configurations
- `general_agent_tools.py` - Includes general-purpose utilities like file-to-markdown conversion and Mermaid diagram generation
- `image_tools.py` - Provides tools for image generation, editing, and vision-based description of images and audio
- `peer_agent_tool.py` - Defines the `PeerAgentTool` class for delegating tasks to other agents
- `registry.py` - Implements the singleton `tool_registry` for managing all tool definitions
- `test_tools.py` - Contains tools specifically for testing agent behavior, such as delays and failures
- `tool_definition.py` - Defines the `BuiltinTool` Pydantic model used for declaring tools
- `web_tools.py` - Contains tools for making HTTP requests to external web resources with content processing

## Developer API Reference

### __init__.py
**Purpose:** Ensures all built-in tool modules are imported when the tools package is loaded, triggering tool registration
**Import:** `import src.agent.tools`

**Usage Examples:**
```python
# Importing the tools package registers all built-in tools
import src.agent.tools

# Access the registry to see all registered tools
from src.agent.tools.registry import tool_registry
all_tools = tool_registry.get_all_tools()
print(f"Registered {len(all_tools)} tools.")
```

### audio_tools.py
**Purpose:** Collection of tools for audio processing including TTS, concatenation, and transcription
**Import:** `from src.agent.tools.audio_tools import select_voice, text_to_speech, multi_speaker_text_to_speech, concatenate_audio, transcribe_audio`

**Functions:**
- `select_voice(gender: Optional[str] = None, tone: Optional[str] = None, exclude_voices: Optional[List[str]] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Selects a suitable voice name based on criteria like gender and tone
- `text_to_speech(text: str, output_filename: Optional[str] = None, voice_name: Optional[str] = None, gender: Optional[str] = None, tone: Optional[str] = None, language: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Converts text to speech using Gemini TTS API and saves as MP3 artifact
- `multi_speaker_text_to_speech(conversation_text: str, output_filename: Optional[str] = None, speaker_configs: Optional[List[Dict[str, str]]] = None, language: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Converts conversation text with speaker labels to speech using multiple voices
- `concatenate_audio(clips_to_join: List[Dict[str, Any]], output_filename: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Combines multiple audio artifacts in specified order with optional pauses
- `transcribe_audio(audio_filename: str, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Transcribes audio using OpenAI-compatible transcription API

**Constants/Variables:**
- `ALL_AVAILABLE_VOICES: List[str]` - List of all available voice names for TTS
- `SUPPORTED_LANGUAGES: Dict[str, str]` - Mapping of language names to BCP-47 codes
- `VOICE_TONE_MAPPING: Dict[str, List[str]]` - Maps descriptive tones to voice names
- `GENDER_TO_VOICE_MAPPING: Dict[str, List[str]]` - Maps genders to voice names

**Usage Examples:**
```python
# Generate simple audio file
tts_result = await text_to_speech(
    text="Welcome to the developer guide.",
    output_filename="welcome.mp3",
    gender="female",
    tone="friendly",
    language="en-US",
    tool_context=tool_context
)

# Generate multi-speaker conversation
convo_result = await multi_speaker_text_to_speech(
    conversation_text="SpeakerA: How are you?\nSpeakerB: I am fine, thank you.",
    speaker_configs=[
        {"name": "SpeakerA", "gender": "male", "tone": "warm"},
        {"name": "SpeakerB", "gender": "female", "tone": "bright"}
    ],
    tool_context=tool_context
)
```

### builtin_artifact_tools.py
**Purpose:** Core tools for artifact management - create, read, list, update, and delete data artifacts
**Import:** `from src.agent.tools.builtin_artifact_tools import list_artifacts, load_artifact, signal_artifact_for_return, append_to_artifact, apply_embed_and_create_artifact, extract_content_from_artifact, delete_artifact`

**Functions:**
- `list_artifacts(tool_context: ToolContext = None) -> Dict[str, Any]` - Lists all available data artifact filenames and versions for current session
- `load_artifact(filename: str, version: int, load_metadata_only: bool = False, max_content_length: Optional[int] = None, tool_context: ToolContext = None) -> Dict[str, Any]` - Loads content or metadata of specific artifact version
- `signal_artifact_for_return(filename: str, version: int, tool_context: ToolContext = None) -> Dict[str, Any]` - Signals that artifact should be returned to original caller
- `append_to_artifact(filename: str, content_chunk: str, mime_type: str, tool_context: ToolContext = None) -> Dict[str, Any]` - Appends content chunk to existing artifact
- `apply_embed_and_create_artifact(output_filename: str, embed_directive: str, output_metadata: Optional[Dict[str, Any]] = None, tool_context: ToolContext = None) -> Dict[str, Any]` - Resolves embed directive and saves as new artifact
- `extract_content_from_artifact(filename: str, extraction_goal: str, version: Optional[str] = "latest", output_filename_base: Optional[str] = None, tool_context: ToolContext = None) -> Dict[str, Any]` - Uses LLM to extract/transform content from artifact
- `delete_artifact(filename: str, version: Optional[int] = None, tool_context: ToolContext = None) -> Dict[str, Any]` - Deletes specific version or all versions of artifact

**Usage Examples:**
```python
# List all artifacts
artifacts = await list_artifacts(tool_context=tool_context)
print(artifacts)

# Load specific artifact
content = await load_artifact(
    filename="data.csv",
    version=1,
    tool_context=tool_context
)

# Extract content using LLM
extracted = await extract_content_from_artifact(
    filename="report.pdf",
    extraction_goal="Extract all financial figures and create a summary table",
    tool_context=tool_context
)
```

### builtin_data_analysis_tools.py
**Purpose:** Tools for data analysis and visualization, particularly chart generation
**Import:** `from src.agent.tools.builtin_data_analysis_tools import create_chart_from_plotly_config`

**Functions:**
- `create_chart_from_plotly_config(config_content: str, config_format: Literal["json", "yaml"], output_filename: str, output_format: Optional[str] = "png", tool_context: ToolContext = None) -> Dict[str, Any]` - Generates static chart image from Plotly configuration

**Usage Examples:**
```python
# Create chart from JSON config
chart_result = await create_chart_from_plotly_config(
    config_content='{"data": [{"x": [1,2,3], "y": [4,5,6], "type": "scatter"}], "layout": {"title": "Sample Chart"}}',
    config_format="json",
    output_filename="my_chart.png",
    output_format="png",
    tool_context=tool_context
)
```

### general_agent_tools.py
**Purpose:** General-purpose utility tools for file conversion and diagram generation
**Import:** `from src.agent.tools.general_agent_tools import convert_file_to_markdown, mermaid_diagram_generator`

**Functions:**
- `convert_file_to_markdown(input_filename: str, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Converts input file artifact to Markdown using MarkItDown library
- `mermaid_diagram_generator(mermaid_syntax: str, output_filename: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Generates PNG image from Mermaid diagram syntax

**Usage Examples:**
```python
# Convert PDF to Markdown
md_result = await convert_file_to_markdown(
    input_filename="document.pdf",
    tool_context=tool_context
)

# Generate Mermaid diagram
diagram_result = await mermaid_diagram_generator(
    mermaid_syntax="graph TD; A-->B; B-->C;",
    output_filename="flowchart.png",
    tool_context=tool_context
)
```

### image_tools.py
**Purpose:** Tools for image generation, editing, and multimodal content analysis
**Import:** `from src.agent.tools.image_tools import create_image_from_description, describe_image, describe_audio, edit_image_with_gemini`

**Functions:**
- `create_image_from_description(image_description: str, output_filename: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Generates image from text description using configured model
- `describe_image(image_filename: str, prompt: str = "What is in this image?", tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Describes image using OpenAI-compatible vision API
- `describe_audio(audio_filename: str, prompt: str = "What is in this recording?", tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Describes audio using multimodal API
- `edit_image_with_gemini(image_filename: str, edit_prompt: str, output_filename: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Edits existing image using Gemini 2.0 Flash Preview

**Usage Examples:**
```python
# Generate image from description
image_result = await create_image_from_description(
    image_description="A sunset over mountains with a lake in the foreground",
    output_filename="sunset.png",
    tool_context=tool_context
)

# Describe existing image
description = await describe_image(
    image_filename="photo.jpg",
    prompt="Describe the objects and people in this image",
    tool_context=tool_context
)
```

### peer_agent_tool.py
**Purpose:** Defines PeerAgentTool class for delegating tasks to other agents
**Import:** `from src.agent.tools.peer_agent_tool import PeerAgentTool`

**Classes:**
- `PeerAgentTool(target_agent_name: str, host_component)` - ADK Tool for delegating tasks to peer agents
  - `run_async(args: Dict[str, Any], tool_context: ToolContext) -> Any` - Handles task delegation to peer agent
  - `_get_declaration() -> Optional[adk_types.FunctionDeclaration]` - Dynamically generates function declaration

**Usage Examples:**
```python
# Create peer agent tool
peer_tool = PeerAgentTool(
    target_agent_name="data_analyst",
    host_component=host_component
)

# The tool is typically used by the LLM, not directly by developers
```

### registry.py
**Purpose:** Singleton registry for discovering and managing all BuiltinTool definitions
**Import:** `from src.agent.tools.registry import tool_registry`

**Classes:**
- `_ToolRegistry()` - Singleton registry for tool management
  - `register(tool: BuiltinTool)` - Registers a tool in the registry
  - `get_tool_by_name(name: str) -> Optional[BuiltinTool]` - Returns tool by name
  - `get_tools_by_category(category_name: str) -> List[BuiltinTool]` - Returns tools by category
  - `get_all_tools() -> List[BuiltinTool]` - Returns all registered tools
  - `clear()` - Clears all registered tools (testing only)

**Constants/Variables:**
- `tool_registry: _ToolRegistry` - The singleton registry instance

**Usage Examples:**
```python
from src.agent.tools.registry import tool_registry
from src.agent.tools.tool_definition import BuiltinTool

# Get all tools
all_tools = tool_registry.get_all_tools()

# Get specific tool
artifact_tool = tool_registry.get_tool_by_name("list_artifacts")

# Get tools by category
audio_tools = tool_registry.get_tools_by_category("audio")
```

### test_tools.py
**Purpose:** Tools specifically for testing agent behavior and error handling
**Import:** `from src.agent.tools.test_tools import time_delay, always_fail_tool, dangling_tool_call_test_tool`

**Functions:**
- `time_delay(seconds: float, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Pauses execution for specified seconds
- `always_fail_tool() -> dict` - Always raises exception for testing error handling
- `dangling_tool_call_test_tool() -> None` - Returns None to create dangling tool call for testing

**Usage Examples:**
```python
# Add delay for testing
delay_result = await time_delay(
    seconds=2.5,
    tool_context=tool_context
)

# These tools are primarily for internal testing
```

### tool_definition.py
**Purpose:** Defines the Pydantic model for self-contained BuiltinTool definitions
**Import:** `from src.agent.tools.tool_definition import BuiltinTool`

**Classes:**
- `BuiltinTool(BaseModel)` - Pydantic model for tool definitions
  - `name: str` - Function name the LLM will call
  - `implementation: Callable` - Async Python function implementing the tool
  - `description: str` - High-level description for LLM understanding
  - `parameters: adk_types.Schema` - OpenAPI-like

# content_hash: da5077941d1f5801bc093583679cfc9c959fa8c70cf3e7ba8ab3ad6d7f2b8a3a

================================================================================

## Section 8: agent/utils/utils_llm.txt

**Source file:** `agent/utils/utils_llm.txt`

# DEVELOPER GUIDE for the directory: utils

## Quick Summary
The `utils` directory provides a collection of helper modules designed to support the core functionality of the agent. These utilities encapsulate common, reusable logic for tasks such as artifact management (saving, loading, schema inference), configuration parsing, and safe interaction with the ADK's invocation context.

## Files Overview
- `__init__.py` - Empty package marker file
- `artifact_helpers.py` - Comprehensive artifact management functions for saving, loading, and metadata handling
- `config_parser.py` - Configuration parsing utilities for agent instruction resolution
- `context_helpers.py` - Safe utilities for extracting data from ADK contexts

## Developer API Reference

### artifact_helpers.py
**Purpose:** Comprehensive artifact management with automatic metadata generation, schema inference, and async operations
**Import:** `from agent.utils.artifact_helpers import save_artifact_with_metadata, load_artifact_content_or_metadata, get_artifact_info_list, is_filename_safe, ensure_correct_extension, format_metadata_for_llm, decode_and_get_bytes, get_latest_artifact_version`

**Functions:**
- `is_filename_safe(filename: str) -> bool` - Validates filename safety (no path traversal, separators, or reserved names)
- `ensure_correct_extension(filename_from_llm: str, desired_extension: str) -> str` - Ensures filename has correct extension, handling LLM inconsistencies
- `save_artifact_with_metadata(artifact_service: BaseArtifactService, app_name: str, user_id: str, session_id: str, filename: str, content_bytes: bytes, mime_type: str, metadata_dict: Dict[str, Any], timestamp: datetime.datetime, explicit_schema: Optional[Dict] = None, schema_inference_depth: int = 2, schema_max_keys: int = 20, tool_context: Optional["ToolContext"] = None) -> Dict[str, Any]` - Saves artifact with auto-generated metadata and schema inference
- `load_artifact_content_or_metadata(artifact_service: BaseArtifactService, app_name: str, user_id: str, session_id: str, filename: str, version: Union[int, str], load_metadata_only: bool = False, return_raw_bytes: bool = False, max_content_length: Optional[int] = None, component: Optional[Any] = None, log_identifier_prefix: str = "[ArtifactHelper:load]", encoding: str = "utf-8", error_handling: str = "strict") -> Dict[str, Any]` - Loads artifact content or metadata with flexible options
- `get_artifact_info_list(artifact_service: BaseArtifactService, app_name: str, user_id: str, session_id: str) -> List[ArtifactInfo]` - Retrieves detailed info for all artifacts
- `get_latest_artifact_version(artifact_service: BaseArtifactService, app_name: str, user_id: str, session_id: str, filename: str) -> Optional[int]` - Gets latest version number for an artifact
- `format_metadata_for_llm(metadata: Dict[str, Any]) -> str` - Formats metadata into LLM-friendly text
- `decode_and_get_bytes(content_str: str, mime_type: str, log_identifier: str) -> Tuple[bytes, str]` - Decodes content based on MIME type (base64 for binary, UTF-8 for text)

**Constants/Variables:**
- `METADATA_SUFFIX: str` - Metadata file suffix: ".metadata.json"
- `DEFAULT_SCHEMA_MAX_KEYS: int` - Default max keys for schema inference: 20

**Usage Examples:**
```python
import asyncio
import datetime
from google.adk.artifacts import BaseArtifactService
from agent.utils.artifact_helpers import (
    save_artifact_with_metadata,
    load_artifact_content_or_metadata,
    get_artifact_info_list,
    ensure_correct_extension,
    is_filename_safe
)

async def artifact_example():
    # Validate and fix filename
    filename = ensure_correct_extension("data_export", "csv")  # -> "data_export.csv"
    if not is_filename_safe(filename):
        raise ValueError("Unsafe filename")
    
    # Save artifact with metadata
    csv_data = b"name,age\nAlice,30\nBob,25"
    result = await save_artifact_with_metadata(
        artifact_service=service,
        app_name="my_app",
        user_id="user123",
        session_id="session456",
        filename=filename,
        content_bytes=csv_data,
        mime_type="text/csv",
        metadata_dict={"source": "user_upload", "description": "Employee data"},
        timestamp=datetime.datetime.now(datetime.timezone.utc)
    )
    
    # Load artifact content
    loaded = await load_artifact_content_or_metadata(
        artifact_service=service,
        app_name="my_app",
        user_id="user123", 
        session_id="session456",
        filename=filename,
        version="latest"
    )
    
    # List all artifacts
    artifacts = await get_artifact_info_list(
        artifact_service=service,
        app_name="my_app",
        user_id="user123",
        session_id="session456"
    )
```

### config_parser.py
**Purpose:** Parses and validates agent configuration, especially instruction providers
**Import:** `from agent.utils.config_parser import resolve_instruction_provider`

**Functions:**
- `resolve_instruction_provider(component, config_value: Any) -> Union[str, InstructionProvider]` - Resolves instruction config from string or callable invoke block

**Usage Examples:**
```python
from agent.utils.config_parser import resolve_instruction_provider

# String instruction
instruction = resolve_instruction_provider(component, "You are a helpful assistant.")
# Returns: "You are a helpful assistant."

# Callable instruction provider
def dynamic_instruction(context):
    return f"Assistant for {context.user_id}"

instruction_func = resolve_instruction_provider(component, dynamic_instruction)
# Returns: the dynamic_instruction function
```

### context_helpers.py
**Purpose:** Safe utilities for extracting data from ADK callback and invocation contexts
**Import:** `from agent.utils.context_helpers import get_session_from_callback_context, get_original_session_id`

**Functions:**
- `get_session_from_callback_context(callback_context: CallbackContext) -> Session` - Safely extracts Session object from CallbackContext
- `get_original_session_id(invocation_context: Any) -> str` - Extracts base session ID, removing colon-separated suffixes

**Usage Examples:**
```python
from agent.utils.context_helpers import get_session_from_callback_context, get_original_session_id

# In a tool callback
def my_tool_callback(callback_context):
    # Get full session object
    session = get_session_from_callback_context(callback_context)
    print(f"Session ID: {session.id}")
    
    # Get original session ID (strips suffixes)
    original_id = get_original_session_id(callback_context._invocation_context)
    # "session123:tool456" -> "session123"
    print(f"Original ID: {original_id}")
```

# content_hash: 65eafb66a61e6fbe9a29b46227c048051a1f97bff26293985cb5e20bf5e5dd52

================================================================================

## Section 9: common/client/client_llm.txt

**Source file:** `common/client/client_llm.txt`

## Quick Summary
The `client` directory provides a Python-based client library for Agent-to-Agent (A2A) communication. It allows developers to discover remote agent capabilities via an "Agent Card" and then interact with that agent by sending tasks, receiving streaming responses, and managing the task lifecycle (getting status, cancelling, setting callbacks).

## Files Overview
- `__init__.py`: Exposes the primary `A2AClient` and `A2ACardResolver` classes for easy importing.
- `card_resolver.py`: Contains the `A2ACardResolver` class, used to discover and fetch an agent's capabilities from a well-known endpoint.
- `client.py`: Contains the main `A2AClient` class for all communication with a remote agent, including sending tasks and managing them.

## Developer API Reference

### __init__.py
**Purpose:** This file makes the main client classes available directly under the `client` package, simplifying imports for developers.
**Import:** `from common.client import A2AClient, A2ACardResolver`

**Constants/Variables:**
- `__all__: list[str]` - A list of the public objects that are exported from this module: `["A2AClient", "A2ACardResolver"]`.

### card_resolver.py
**Purpose:** This file provides a utility to resolve and fetch an agent's "Agent Card". The Agent Card is a JSON file that describes the agent's capabilities, its endpoint URL, and other metadata.
**Import:** `from common.client import A2ACardResolver`

**Classes:**
- `A2ACardResolver(base_url: str, agent_card_path: str = "/.well-known/agent.json")` - A client to discover and fetch an agent's capability card.
  - `get_agent_card() -> AgentCard` - Makes an HTTP GET request to the constructed agent card URL, parses the JSON response, and returns it as an `AgentCard` object. Raises `A2AClientHTTPError` on network/status errors and `A2AClientJSONError` on parsing errors.

**Usage Examples:**
```python
from common.client import A2ACardResolver
from common.types import AgentCard, A2AClientHTTPError

# Create a resolver for an agent hosted at a specific domain
resolver = A2ACardResolver(base_url="https://some-agent.ai")

try:
    # Fetch the agent's capability card from the default path
    agent_card: AgentCard = resolver.get_agent_card()
    print(f"Agent API URL: {agent_card.url}")
except A2AClientHTTPError as e:
    print(f"Error fetching agent card: {e}")

# Using a custom path for the agent card
custom_resolver = A2ACardResolver(
    base_url="https://another-agent.com",
    agent_card_path="/api/v1/agent-info.json"
)
custom_agent_card = custom_resolver.get_agent_card()
```

### client.py
**Purpose:** This file contains the core `A2AClient`, which is used to communicate with a remote agent's API endpoint. It handles sending various types of JSON-RPC requests for task management. All methods are asynchronous.
**Import:** `from common.client import A2AClient`

**Classes:**
- `A2AClient(agent_card: AgentCard = None, url: str = None)` - The main client for interacting with a remote agent. You must provide either an `AgentCard` object (from `A2ACardResolver`) or a direct `url` string to its API endpoint.
  - `async send_task(payload: dict[str, Any]) -> SendTaskResponse` - Sends a task to the agent for processing. The `payload` should contain the action and its parameters. Returns a response typically containing a `task_id`.
  - `async send_task_streaming(payload: dict[str, Any]) -> AsyncIterable[SendTaskStreamingResponse]` - Sends a task that is expected to return a stream of events (Server-Sent Events). The `payload` is the same as `send_task`. Returns an async iterator that yields response chunks as they arrive.
  - `async get_task(payload: dict[str, Any]) -> GetTaskResponse` - Retrieves the current status and/or result of a previously submitted task. The `payload` must contain the `task_id`.
  - `async cancel_task(payload: dict[str, Any]) -> CancelTaskResponse` - Requests the cancellation of a running task. The `payload` must contain the `task_id`.
  - `async set_task_callback(payload: dict[str, Any]) -> SetTaskPushNotificationResponse` - Sets a callback URL for a specific task. The agent will send a notification to this URL upon task completion. The `payload` must contain the `task_id` and `callback_url`.
  - `async get_task_callback(payload: dict[str, Any]) -> GetTaskPushNotificationResponse` - Retrieves the currently configured callback URL for a task. The `payload` must contain the `task_id`.

**Usage Examples:**
```python
import asyncio
from common.client import A2AClient, A2ACardResolver

async def main():
    # First, discover the agent's capabilities and endpoint URL
    resolver = A2ACardResolver(base_url="https://some-agent.ai")
    agent_card = resolver.get_agent_card()

    # Initialize client using the discovered AgentCard
    client = A2AClient(agent_card=agent_card)
    
    # Or initialize client with a direct URL (if known)
    # client = A2AClient(url="https://some-agent.ai/api/v1/a2a")

    # Send a simple task
    task_payload = {"action": "summarize_text", "text": "A long article..."}
    send_response = await client.send_task(payload=task_payload)
    task_id = send_response.result.task_id
    print(f"Task created with ID: {task_id}")

    # Get task status
    status_response = await client.get_task(payload={"task_id": task_id})
    print(f"Task status: {status_response.result.status}")
    
    # Send a streaming task
    stream_payload = {"action": "generate_story", "prompt": "A robot who discovers music"}
    async for chunk in client.send_task_streaming(payload=stream_payload):
        print(f"Received stream chunk: {chunk.result.content_chunk}")

    # Set a callback URL for the task
    await client.set_task_callback(
        payload={"task_id": task_id, "callback_url": "https://my-app.com/webhook"}
    )

    # Cancel a task
    cancel_response = await client.cancel_task(payload={"task_id": task_id})
    print(f"Task cancelled: {cancel_response.result.cancelled}")

# Run the async function
asyncio.run(main())
```

# content_hash: 6de8c484ba235f4037b8750d3e47fa6c7e9276c28a69d9fe40f85541ae1d62e8

================================================================================

## Section 10: common/common_llm.txt

**Source file:** `common/common_llm.txt`

# DEVELOPER GUIDE: common

## Quick Summary
The `common` directory provides the foundational infrastructure for Agent-to-Agent (A2A) communication within the Solace AI Connector. It establishes the core protocol, data types, and message translation logic that underpins all interactions between AI agents and gateways.

The architecture is designed for clarity and extensibility. Core, low-level definitions are located in **direct files**:
- `types.py` defines the canonical data structures (e.g., `Message`, `Task`, `AgentCard`).
- `a2a_protocol.py` handles the construction of Solace topics and the translation between A2A and Google ADK message formats.
- `agent_registry.py` provides a simple, thread-safe mechanism for discovering and tracking available agents.

This foundation is then leveraged by specialized **subdirectories**, which provide higher-level, ready-to-use components:
- `client/`: A complete client library for discovering and interacting with remote agents.
- `server/`: A stand-alone server implementation for building A2A-compliant agents.
- `middleware/`: A pluggable framework for customizing configuration and feature access.
- `services/`: A factory-based system for integrating identity and other external data sources.
- `utils/`: A collection of cross-cutting utilities for caching, logging, and dynamic content processing.

Together, these components form a cohesive ecosystem, enabling developers to either build new agents from scratch using the `server` components or interact with existing agents using the `client` library, all while relying on the same underlying protocol and types.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Package initialization file.
  - `a2a_protocol.py`: Handles A2A topic construction and translation between A2A and ADK message formats.
  - `agent_registry.py`: A thread-safe registry for managing discovered agent cards.
  - `constants.py`: Common constants used across the A2A system.
  - `types.py`: Contains all Pydantic models for A2A protocol messages, tasks, and data structures.
- **Subdirectories:**
  - `client/`: Provides a high-level client for discovering and communicating with remote A2A agents.
  - `middleware/`: A pluggable framework for configuration resolution and system extensibility.
  - `server/`: A complete A2A server implementation with JSON-RPC support and task management.
  - `services/`: Provides shared services like identity management using a factory pattern.
  - `utils/`: Contains common utility functions and an embedded expression processing system.

## Developer API Reference

### Direct Files

#### a2a_protocol.py
**Purpose:** Provides the core functions for constructing Solace topics according to the A2A specification and for translating messages between the A2A format and the Google ADK format.
**Import:** `from common.a2a_protocol import get_agent_request_topic, translate_a2a_to_adk_content`

**Classes/Functions/Constants:**
- **Constants**:
  - `A2A_VERSION: str`: The current version of the A2A protocol (e.g., "v1").
  - `A2A_BASE_PATH: str`: The base path used in all A2A topics (e.g., "a2a/v1").
- **Topic Construction Functions**:
  - `get_a2a_base_topic(namespace: str) -> str`: Returns the base topic prefix for all A2A communication.
  - `get_discovery_topic(namespace: str) -> str`: Returns the topic for agent card discovery.
  - `get_agent_request_topic(namespace: str, agent_name: str) -> str`: Returns the topic for sending requests to a specific agent.
  - `get_gateway_status_topic(namespace: str, gateway_id: str, task_id: str) -> str`: Returns the topic for an agent to publish status updates to a gateway.
  - `get_gateway_response_topic(namespace: str, gateway_id: str, task_id: str) -> str`: Returns the topic for an agent to publish final responses to a gateway.
  - `get_client_response_topic(namespace: str, client_id: str) -> str`: Returns the topic for publishing final responses to a specific client.
  - `get_client_status_topic(namespace: str, client_id: str, task_id: str) -> str`: Returns the topic for publishing status updates to a specific client.
  - ... and various functions for subscription topics (e.g., `get_gateway_status_subscription_topic`).
- **Message Translation Functions**:
  - `translate_a2a_to_adk_content(a2a_message: A2AMessage, log_identifier: str) -> adk_types.Content`: Translates an A2A `Message` object into the Google ADK `Content` format.
  - `format_adk_event_as_a2a(...) -> Tuple[Optional[JSONRPCResponse], ...]`: Translates an ADK `Event` into an A2A `JSONRPCResponse` containing a `TaskStatusUpdateEvent`.
  - `format_and_route_adk_event(...) -> Tuple[Optional[Dict], Optional[str], ...]`: A higher-level wrapper that formats an ADK event and determines the correct Solace topic to publish it to.

#### agent_registry.py
**Purpose:** Provides a simple, thread-safe, in-memory store for discovered `AgentCard` objects. This is useful for components that need to keep track of available agents in the network.
**Import:** `from common.agent_registry import AgentRegistry`

**Classes/Functions/Constants:**
- **`AgentRegistry`**: A thread-safe class for storing and managing agent cards.
  - `add_or_update_agent(self, agent_card: AgentCard)`: Adds a new agent or updates an existing one.
  - `get_agent(self, agent_name: str) -> Optional[AgentCard]`: Retrieves an agent card by its unique name.
  - `get_agent_names(self) -> List[str]`: Returns a sorted list of all discovered agent names.
  - `clear(self)`: Clears all agents from the registry.

#### constants.py
**Purpose:** Defines common constants used throughout the A2A system.
**Import:** `from common.constants import DEFAULT_COMMUNICATION_TIMEOUT`

**Classes/Functions/Constants:**
- `DEFAULT_COMMUNICATION_TIMEOUT: int`: Default timeout for A2A communications (600 seconds / 10 minutes).

#### types.py
**Purpose:** Defines all the Pydantic data models that constitute the A2A protocol. These types ensure data consistency and provide validation across all components.
**Import:** `from common.types import Message, Task, AgentCard, JSONRPCRequest, TaskState`

**Classes/Functions/Constants:**
- **Core Data Structures**:
  - `Message`: Represents a message from a user or agent, containing a list of `Part` objects.
  - `Part`: A discriminated union of `TextPart`, `FilePart`, and `DataPart`.
  - `Task`: The central object representing a complete task, including its ID, status, history, and artifacts.
  - `TaskStatus`: Describes the current state of a task (e.g., `WORKING`, `COMPLETED`).
  - `TaskState(Enum)`: An enumeration of all possible task states.
  - `AgentCard`: A comprehensive description of an agent's identity, capabilities, and skills.
  - `Artifact`: Represents a task output, such as a generated file or structured data.
- **JSON-RPC Structures**:
  - `JSONRPCRequest`: The base model for all JSON-RPC requests.
  - `JSONRPCResponse`: The base model for all JSON-RPC responses.
  - `SendTaskRequest`, `GetTaskRequest`, etc.: Specific request types inheriting from `JSONRPCRequest`.
- **Error Structures**:
  - `JSONRPCError`: The base model for errors.
  - `InternalError`, `TaskNotFoundError`, etc.: Specific error types inheriting from `JSONRPCError`.

### Subdirectory APIs

#### client/
**Purpose:** Provides a high-level, asynchronous client library for discovering and interacting with remote A2A agents.
**Key Exports:** `A2AClient`, `A2ACardResolver`
**Import Examples:**
```python
from common.client import A2AClient, A2ACardResolver
```

#### middleware/
**Purpose:** A pluggable middleware framework for customizing system behavior, such as resolving user-specific configurations and feature flags.
**Key Exports:** `ConfigResolver`, `MiddlewareRegistry`
**Import Examples:**
```python
from common.middleware import ConfigResolver, MiddlewareRegistry
```

#### server/
**Purpose:** A complete, stand-alone server for building A2A-compliant agents, handling HTTP requests, JSON-RPC, and task lifecycle management.
**Key Exports:** `A2AServer`, `TaskManager`, `InMemoryTaskManager`
**Import Examples:**
```python
from common.server import A2AServer, TaskManager, InMemoryTaskManager
```

#### services/
**Purpose:** A factory-based system for integrating external data sources for identity, employee information, and more.
**Key Exports:** `BaseIdentityService`, `create_identity_service`
**Import Examples:**
```python
from common.services.identity_service import create_identity_service, BaseIdentityService
```

#### utils/
**Purpose:** A collection of cross-cutting utilities for caching, logging, MIME type handling, and dynamic content processing.
**Key Exports:** `InMemoryCache`, `is_text_based_mime_type`, `resolve_embeds_in_string`
**Import Examples:**
```python
from common.utils.in_memory_cache import InMemoryCache
from common.utils import is_text_based_mime_type
from common.utils.embeds import resolve_embeds_recursively_in_string
```

## Complete Usage Guide

### 1. How to import and use classes from direct files
This example shows basic usage of the protocol, types, and agent registry, which form the foundation of any A2A component.

```python
import uuid
from common.a2a_protocol import get_agent_request_topic, get_gateway_status_topic
from common.types import AgentCard, Message, TextPart, Task, TaskStatus, TaskState
from common.agent_registry import AgentRegistry
from common.constants import DEFAULT_COMMUNICATION_TIMEOUT

# Create an agent card
agent_card = AgentCard(
    name="my-agent",
    display_name="My AI Agent",
    description="A helpful AI assistant",
    url="https://my-agent.example.com/api",
    version="1.0.0",
    capabilities={
        "streaming": True,
        "pushNotifications": False,
        "stateTransitionHistory": True
    },
    defaultInputModes=["text"],
    defaultOutputModes=["text"],
    skills=[
        {
            "id": "text-analysis",
            "name": "Text Analysis",
            "description": "Analyze and summarize text content"
        }
    ],
    peer_agents={}
)

# Use the agent registry
registry = AgentRegistry()
registry.add_or_update_agent(agent_card)

# Get agent names
available_agents = registry.get_agent_names()
print(f"Available agents: {available_agents}")

# Create A2A message
message = Message(
    role="user",
    parts=[TextPart(text="Please analyze this document")]
)

# Create task
task = Task(
    id=str(uuid.uuid4()),
    status=TaskStatus(state=TaskState.SUBMITTED, message=message),
    history=[message]
)

# Generate topic names for communication
namespace = "my-company/ai-agents"
request_topic = get_agent_request_topic(namespace, "my-agent")
status_topic = get_gateway_status_topic(namespace, "gateway-1", task.id)

print(f"Request topic: {request_topic}")
print(f"Status topic: {status_topic}")
print(f"Default timeout: {DEFAULT_COMMUNICATION_TIMEOUT} seconds")
```

### 2. How to import and use functionality from subdirectories
This example demonstrates using the higher-level components from subdirectories.

```python
import asyncio
from common.client import A2AClient, A2ACardResolver
from common.server import A2AServer, InMemoryTaskManager
from common.middleware import ConfigResolver, MiddlewareRegistry
from common.services.identity_service import create_identity_service
from common.utils.in_memory_cache import InMemoryCache
from common.utils import is_text_based_mime_type

async def client_example():
    """Example of using the A2A client to interact with remote agents."""
    
    # Discover agent capabilities
    resolver = A2ACardResolver(base_url="https://remote-agent.example.com")
    agent_card = resolver.get_agent_card()
    
    # Create client
    client = A2AClient(agent_card=agent_card)
    
    # Send a task
    task_payload = {
        "id": str(uuid.uuid4()),
        "message": {
            "role": "user",
            "parts": [{"type": "text", "text": "Summarize this document"}]
        }
    }
    
    response = await client.send_task(payload=task_payload)
    print(f"Task submitted: {response.result.id}")
    
    # Get task status
    status_response = await client.get_task(payload={"id": response.result.id})
    print(f"Task status: {status_response.result.status.state}")

def server_example():
    """Example of creating an A2A server."""
    
    # Create custom task manager
    class MyTaskManager(InMemoryTaskManager):
        async def on_send_task(self, request):
            # Custom task processing logic
            task = await self.upsert_task(request.params)
            
            # Simulate processing
            import time
            time.sleep(1)
            
            # Update task as completed
            from common.types import TaskStatus, TaskState
            completed_status = TaskStatus(state=TaskState.COMPLETED)
            await self.update_store(task.id, completed_status, [])
            
            return {"id": request.id, "result": task}
    
    # Create server
    server = A2AServer(
        host="0.0.0.0",
        port=8080,
        agent_card=agent_card,  # From previous example
        task_manager=MyTaskManager()
    )
    
    # Start server (this blocks)
    # server.start()

async def services_example():
    """Example of using services for identity and caching."""
    
    # Set up identity service
    identity_config = {
        "type": "local_file",
        "file_path": "users.json",
        "lookup_key": "email"
    }
    identity_service = create_identity_service(identity_config)
    
    if identity_service:
        # Look up user profile
        auth_claims = {"email": "user@example.com"}
        profile = await identity_service.get_user_profile(auth_claims)
        print(f"User profile: {profile}")
    
    # Use caching
    cache = InMemoryCache()
    cache.set("user_session", {"user_id": "123"}, ttl=3600)
    session = cache.get("user_session")
    print(f"Cached session: {session}")
    
    # Check MIME types
    if is_text_based_mime_type("application/json"):
        print("JSON is text-based")

# Run examples
asyncio.run(client_example())
# server_example()  # Uncomment to run server
asyncio.run(services_example())
```

### 3. How different parts work together
This example shows a complete workflow using multiple components together.

```python
import asyncio
import json
from common.types import *
from common.a2a_protocol import *
from common.client import A2AClient
from common.server import A2AServer, InMemoryTaskManager
from common.middleware import ConfigResolver
from common.utils.embeds import resolve_embeds_recursively_in_string, evaluate_embed
from common.utils.in_memory_cache import InMemoryCache

class Integr

# content_hash: 9dd1a4f0293c17f2a8dfb97d394d603a46e56ee0c0dec1c67af478028e95f525

================================================================================

## Section 11: common/middleware/middleware_llm.txt

**Source file:** `common/middleware/middleware_llm.txt`

# DEVELOPER GUIDE: middleware

## Quick Summary
The `middleware` directory provides a pluggable framework for system components that can be extended or replaced at runtime. It offers a registry system to dynamically bind custom implementations for core functionalities like configuration resolution. The default implementations provide permissive behavior, making them suitable for development and testing environments where all features are enabled by default.

## Files Overview
- `__init__.py` - Exposes the main public classes of the middleware package for easy importing
- `config_resolver.py` - Defines the default, permissive configuration resolution middleware
- `registry.py` - Provides the MiddlewareRegistry for dynamically binding custom middleware implementations

## Developer API Reference

### __init__.py
**Purpose:** Entry point to the middleware package, exporting the primary public interfaces

**Import:** `from solace_ai_connector.common.middleware import ConfigResolver, MiddlewareRegistry`

**Usage Examples:**
```python
# Import the main classes directly from the middleware package
from solace_ai_connector.common.middleware import ConfigResolver, MiddlewareRegistry

# Now you can use ConfigResolver and MiddlewareRegistry
resolver = ConfigResolver()
registry = MiddlewareRegistry()
```

### config_resolver.py
**Purpose:** Provides a pluggable interface for resolving user-specific configuration and determining feature availability. The default implementation is permissive, allowing all operations.

**Import:** `from solace_ai_connector.common.middleware import ConfigResolver`

**Classes:**
- `ConfigResolver()` - Resolves user-specific configuration and determines feature availability with permissive defaults
  - `resolve_user_config(user_identity: Any, gateway_context: Dict[str, Any], base_config: Dict[str, Any]) -> Dict[str, Any]` - (async static) Resolves user-specific configuration settings
  - `is_feature_enabled(user_config: Dict[str, Any], feature_descriptor: Dict[str, Any], context: Dict[str, Any]) -> bool` - (static) Checks if a feature is enabled for the user
  - `validate_operation_config(user_config: Dict[str, Any], operation_spec: Dict[str, Any], validation_context: Dict[str, Any]) -> Dict[str, Any]` - (static) Validates operation against user configuration
  - `filter_available_options(user_config: Dict[str, Any], available_options: List[Dict[str, Any]], filter_context: Dict[str, Any]) -> List[Dict[str, Any]]` - (static) Filters available options based on user configuration

**Usage Examples:**
```python
import asyncio
from solace_ai_connector.common.middleware import ConfigResolver

async def main():
    # Resolve user configuration
    user_config = await ConfigResolver.resolve_user_config(
        user_identity="user@example.com",
        gateway_context={"gateway_id": "gw-1"},
        base_config={"api_key": "default_key"}
    )
    
    # Check if feature is enabled
    feature_enabled = ConfigResolver.is_feature_enabled(
        user_config=user_config,
        feature_descriptor={"feature_type": "ai_tool", "function_name": "code_interpreter"},
        context={}
    )
    
    # Validate operation
    validation_result = ConfigResolver.validate_operation_config(
        user_config=user_config,
        operation_spec={"operation_type": "model_inference", "model": "gpt-4"},
        validation_context={}
    )
    
    # Filter available options
    filtered_options = ConfigResolver.filter_available_options(
        user_config=user_config,
        available_options=[{"name": "gpt-3.5"}, {"name": "gpt-4"}],
        filter_context={"type": "language_model"}
    )

asyncio.run(main())
```

### registry.py
**Purpose:** Provides a registry system for dynamically binding custom middleware implementations at runtime

**Import:** `from solace_ai_connector.common.middleware import MiddlewareRegistry`

**Classes:**
- `MiddlewareRegistry()` - Registry for managing middleware implementations with class methods
  - `bind_config_resolver(resolver_class: Type)` - (classmethod) Binds a custom config resolver implementation
  - `get_config_resolver() -> Type` - (classmethod) Gets the current config resolver implementation
  - `register_initialization_callback(callback: callable)` - (classmethod) Registers a callback for system initialization
  - `initialize_middleware()` - (classmethod) Initializes all registered middleware components
  - `reset_bindings()` - (classmethod) Resets all bindings to defaults
  - `get_registry_status() -> Dict[str, Any]` - (classmethod) Gets current status of the middleware registry

**Usage Examples:**
```python
from solace_ai_connector.common.middleware import MiddlewareRegistry, ConfigResolver
from typing import Any, Dict

# Define custom config resolver
class CustomConfigResolver:
    @staticmethod
    async def resolve_user_config(user_identity: Any, gateway_context: Dict[str, Any], base_config: Dict[str, Any]) -> Dict[str, Any]:
        # Custom logic here
        return {"custom": True, **base_config}
    
    # Inherit other methods from default
    is_feature_enabled = ConfigResolver.is_feature_enabled
    validate_operation_config = ConfigResolver.validate_operation_config
    filter_available_options = ConfigResolver.filter_available_options

# Define initialization callback
def setup_custom_middleware():
    print("Setting up custom middleware...")

# Bind custom implementations
MiddlewareRegistry.bind_config_resolver(CustomConfigResolver)
MiddlewareRegistry.register_initialization_callback(setup_custom_middleware)

# Initialize middleware (call during app startup)
MiddlewareRegistry.initialize_middleware()

# Get current resolver
current_resolver = MiddlewareRegistry.get_config_resolver()

# Check registry status
status = MiddlewareRegistry.get_registry_status()
print(f"Registry status: {status}")

# Reset for testing
MiddlewareRegistry.reset_bindings()
```

# content_hash: 62bfccb5a13cdb8430b367f663dfdc10c4ee0a494d5d781f51e4ebbeac6a5ab8

================================================================================

## Section 12: common/server/server_llm.txt

**Source file:** `common/server/server_llm.txt`

# DEVELOPER GUIDE for server

## Quick Summary
The `server` directory provides a complete Agent-to-Agent (A2A) communication server built on Starlette that implements JSON-RPC 2.0 protocol. It handles task management, streaming responses via Server-Sent Events (SSE), push notifications, and agent discovery through standardized endpoints.

## Files Overview
- `__init__.py` - Exposes main public classes for easy importing
- `server.py` - Core A2A HTTP server implementation with JSON-RPC request routing
- `task_manager.py` - Abstract task management interface and in-memory implementation
- `utils.py` - Utility functions for error responses and modality compatibility checks

## Developer API Reference

### __init__.py
**Purpose:** Provides convenient access to the main server components
**Import:** `from solace_ai_connector.common.server import A2AServer, TaskManager, InMemoryTaskManager`

### server.py
**Purpose:** Main HTTP server that handles A2A communication via JSON-RPC 2.0 protocol
**Import:** `from solace_ai_connector.common.server import A2AServer`

**Classes:**
- `A2AServer(host: str = "0.0.0.0", port: int = 5000, endpoint: str = "/", agent_card: AgentCard = None, task_manager: TaskManager = None)` - Starlette-based web server for A2A communication
  - `start() -> None` - Starts the uvicorn server (raises ValueError if agent_card or task_manager not set)
  - `host: str` - Server bind address
  - `port: int` - Server port number
  - `endpoint: str` - Main API endpoint path
  - `agent_card: AgentCard` - Agent metadata served at `/.well-known/agent.json`
  - `task_manager: TaskManager` - Handler for task operations

**Usage Examples:**
```python
from solace_ai_connector.common.server import A2AServer, InMemoryTaskManager
from solace_ai_connector.common.types import AgentCard

# Create agent metadata
agent_card = AgentCard(
    id="my-agent-v1",
    name="My Agent",
    version="1.0.0",
    description="A sample agent",
    supported_tasks=["summarize"],
    input_modalities=["text/plain"],
    output_modalities=["text/plain"]
)

# Create custom task manager
class MyTaskManager(InMemoryTaskManager):
    async def on_send_task(self, request):
        # Your agent logic here
        task = await self.upsert_task(request.params)
        # Process task...
        return SendTaskResponse(id=request.id, result=task)

# Start server
server = A2AServer(
    host="127.0.0.1",
    port=8080,
    agent_card=agent_card,
    task_manager=MyTaskManager()
)
server.start()
```

### task_manager.py
**Purpose:** Defines task management interface and provides in-memory implementation
**Import:** `from solace_ai_connector.common.server import TaskManager, InMemoryTaskManager`

**Classes:**
- `TaskManager()` - Abstract base class defining task management interface
  - `on_get_task(request: GetTaskRequest) -> GetTaskResponse` - Retrieve task status and details
  - `on_cancel_task(request: CancelTaskRequest) -> CancelTaskResponse` - Cancel an ongoing task
  - `on_send_task(request: SendTaskRequest) -> SendTaskResponse` - Handle standard task submission
  - `on_send_task_subscribe(request: SendTaskStreamingRequest) -> Union[AsyncIterable[SendTaskStreamingResponse], JSONRPCResponse]` - Handle streaming task submission
  - `on_set_task_push_notification(request: SetTaskPushNotificationRequest) -> SetTaskPushNotificationResponse` - Configure push notifications
  - `on_get_task_push_notification(request: GetTaskPushNotificationRequest) -> GetTaskPushNotificationResponse` - Get push notification config
  - `on_resubscribe_to_task(request: TaskResubscriptionRequest) -> Union[AsyncIterable[SendTaskResponse], JSONRPCResponse]` - Resubscribe to streaming task

- `InMemoryTaskManager()` - Concrete implementation with in-memory storage and SSE support
  - `upsert_task(task_send_params: TaskSendParams) -> Task` - Create or update task with new message
  - `update_store(task_id: str, status: TaskStatus, artifacts: list[Artifact]) -> Task` - Update task status and artifacts
  - `set_push_notification_info(task_id: str, notification_config: PushNotificationConfig) -> None` - Store push notification config
  - `get_push_notification_info(task_id: str) -> PushNotificationConfig` - Retrieve push notification config
  - `has_push_notification_info(task_id: str) -> bool` - Check if push notification config exists
  - `setup_sse_consumer(task_id: str, is_resubscribe: bool = False) -> asyncio.Queue` - Create SSE subscriber queue
  - `enqueue_events_for_sse(task_id: str, task_update_event: Any) -> None` - Send event to all SSE subscribers
  - `dequeue_events_for_sse(request_id: str, task_id: str, sse_event_queue: asyncio.Queue) -> AsyncIterable[SendTaskStreamingResponse]` - Async generator for SSE events

**Usage Examples:**
```python
import asyncio
from solace_ai_connector.common.server import InMemoryTaskManager
from solace_ai_connector.common.types import (
    SendTaskRequest, SendTaskResponse, TaskStatus, TaskState,
    SendTaskStreamingRequest, TaskStatusUpdateEvent
)

class MyTaskManager(InMemoryTaskManager):
    async def on_send_task(self, request: SendTaskRequest) -> SendTaskResponse:
        # Create/update task
        task = await self.upsert_task(request.params)
        
        # Process task (your logic here)
        result = f"Processed: {request.params.message.content}"
        
        # Update task as completed
        status = TaskStatus(state=TaskState.COMPLETED)
        await self.update_store(task.id, status, [])
        
        return SendTaskResponse(id=request.id, result=task)

    async def on_send_task_subscribe(self, request: SendTaskStreamingRequest):
        await self.upsert_task(request.params)
        sse_queue = await self.setup_sse_consumer(request.params.id)
        
        # Start background processing
        asyncio.create_task(self._process_streaming(request.params.id))
        
        # Return SSE generator
        return self.dequeue_events_for_sse(request.id, request.params.id, sse_queue)
    
    async def _process_streaming(self, task_id: str):
        for i in range(3):
            await asyncio.sleep(1)
            event = TaskStatusUpdateEvent(
                status=TaskStatus(state=TaskState.IN_PROGRESS),
                message={"content": f"Step {i+1} complete"}
            )
            await self.enqueue_events_for_sse(task_id, event)
        
        # Final event
        final_event = TaskStatusUpdateEvent(
            status=TaskStatus(state=TaskState.COMPLETED),
            final=True
        )
        await self.enqueue_events_for_sse(task_id, final_event)
```

### utils.py
**Purpose:** Utility functions for error handling and compatibility checks
**Import:** `from solace_ai_connector.common.server.utils import are_modalities_compatible, new_incompatible_types_error, new_not_implemented_error`

**Functions:**
- `are_modalities_compatible(server_output_modes: List[str], client_output_modes: List[str]) -> bool` - Check if modality lists have common elements
- `new_incompatible_types_error(request_id) -> JSONRPCResponse` - Create content type not supported error response
- `new_not_implemented_error(request_id) -> JSONRPCResponse` - Create unsupported operation error response

**Usage Examples:**
```python
from solace_ai_connector.common.server.utils import are_modalities_compatible, new_not_implemented_error

# Check modality compatibility
server_modes = ["text/plain", "application/json"]
client_modes = ["text/plain"]
if are_modalities_compatible(server_modes, client_modes):
    print("Compatible modalities")

# Return error for unimplemented feature
def some_handler(request):
    return new_not_implemented_error(request.id)
```

# content_hash: eeddd5631483c2e4f109b8b4d2f9ab222c69bcee6b37e72a8ea0eace0b03a946

================================================================================

## Section 13: common/services/providers/providers_llm.txt

**Source file:** `common/services/providers/providers_llm.txt`

## Quick Summary
This directory contains concrete implementations (providers) for the abstract services defined in the parent `services` package. These providers offer specific ways to fulfill service contracts, such as sourcing user identity information from a local file.

## Files Overview
- `__init__.py` - Package initialization file marking the directory as a Python package
- `local_file_identity_service.py` - File-based identity service implementation that reads user data from local JSON files

## Developer API Reference

### __init__.py
**Purpose:** Initializes the `providers` package
**Import:** `from solace_ai_connector.common.services import providers`

This file contains no public classes or functions - it only serves as package documentation.

### local_file_identity_service.py
**Purpose:** Provides a file-based identity service that reads user profiles from a local JSON file, ideal for development, testing, or small-scale deployments
**Import:** `from solace_ai_connector.common.services.providers.local_file_identity_service import LocalFileIdentityService`

**Classes:**
- `LocalFileIdentityService(config: Dict[str, Any])` - Identity service that sources user data from a local JSON file
  - `async get_user_profile(auth_claims: Dict[str, Any]) -> Optional[Dict[str, Any]]` - Looks up a user profile using the lookup key from auth claims
  - `async search_users(query: str, limit: int = 10) -> List[Dict[str, Any]]` - Performs case-insensitive search on user names and emails
  - `file_path: str` - Path to the JSON file containing user data
  - `lookup_key: str` - Key used to identify users (defaults to "id")
  - `all_users: List[Dict[str, Any]]` - Complete list of user profiles loaded from file
  - `user_index: Dict[str, Dict[str, Any]]` - In-memory index mapping lookup keys to user profiles

**Usage Examples:**
```python
import asyncio
import json
from typing import Dict, Any
from solace_ai_connector.common.services.providers.local_file_identity_service import LocalFileIdentityService

# Create sample users.json file
users_data = [
    {
        "id": "jdoe",
        "email": "jane.doe@example.com", 
        "name": "Jane Doe",
        "title": "Senior Engineer",
        "manager_id": "ssmith"
    },
    {
        "id": "ssmith",
        "email": "sam.smith@example.com",
        "name": "Sam Smith", 
        "title": "Engineering Manager"
    }
]

with open("users.json", "w") as f:
    json.dump(users_data, f)

async def main():
    # Initialize the service
    config = {
        "file_path": "users.json",
        "lookup_key": "id"  # Optional, defaults to "id"
    }
    
    identity_service = LocalFileIdentityService(config)
    
    # Get user profile by ID
    auth_claims = {"id": "jdoe"}
    profile = await identity_service.get_user_profile(auth_claims)
    print(f"User profile: {profile}")
    
    # Search for users
    results = await identity_service.search_users("jane", limit=5)
    print(f"Search results: {results}")

# Run the example
asyncio.run(main())
```

# content_hash: 44499ff8f5983a37d14b0eae8a58c6870ad84fd71f2e883568fc90aeab393db3

================================================================================

## Section 14: common/services/services_llm.txt

**Source file:** `common/services/services_llm.txt`

## Quick Summary
The `services` directory provides a modular and extensible framework for integrating external data sources related to identity and employee information into the Solace AI Connector. It is built on a provider pattern, defining abstract base classes (`BaseIdentityService`, `BaseEmployeeService`) that establish a clear contract for what data and functionality a service must provide.

The core architecture revolves around factory functions (`create_identity_service`, `create_employee_service`) that instantiate specific service providers based on a configuration dictionary. This allows the application to remain decoupled from the concrete implementations. Providers can be either built-in (like the file-based identity service located in the `providers/` subdirectory) or dynamically loaded as external plugins, making the system highly flexible and easy to extend.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Marks the directory as a Python package.
  - `employee_service.py`: Defines the abstract contract and factory for employee data services.
  - `identity_service.py`: Defines the abstract contract and factory for user identity services.
- **Subdirectories:**
  - `providers/`: Contains concrete implementations of the service contracts, such as a file-based identity provider.

## Developer API Reference

### Direct Files

#### employee_service.py
**Purpose:** Defines the abstract base class (`BaseEmployeeService`) that all employee service providers must implement, and a factory function (`create_employee_service`) to instantiate them. It enforces a canonical schema for employee data to ensure consistency across different providers.
**Import:** `from solace_ai_connector.common.services.employee_service import BaseEmployeeService, create_employee_service`

**Classes/Functions/Constants:**
- **`class BaseEmployeeService(ABC)`**: The abstract base class for employee service providers.
    - **`__init__(self, config: Dict[str, Any])`**: Initializes the service, setting up configuration and an optional in-memory cache.
    - **`async def get_employee_dataframe(self) -> pd.DataFrame`**: (Abstract) Returns the entire employee directory as a pandas DataFrame.
    - **`async def get_employee_profile(self, employee_id: str) -> Optional[Dict[str, Any]]`**: (Abstract) Fetches the profile for a single employee, conforming to the canonical schema.
    - **`async def get_time_off_data(self, employee_id: str) -> List[Dict[str, Any]]`**: (Abstract) Retrieves a list of time-off entries for an employee.
    - **`async def get_employee_profile_picture(self, employee_id: str) -> Optional[str]`**: (Abstract) Fetches an employee's profile picture as a data URI string.
- **`def create_employee_service(config: Optional[Dict[str, Any]]) -> Optional[BaseEmployeeService]`**: A factory function that dynamically loads and instantiates an employee service provider based on the `type` specified in the configuration. It primarily uses Python's entry points to find and load external plugins.

#### identity_service.py
**Purpose:** Defines the abstract base class (`BaseIdentityService`) for identity providers and a factory function (`create_identity_service`) to create instances of them. This service is used for user lookups and profile enrichment.
**Import:** `from solace_ai_connector.common.services.identity_service import BaseIdentityService, create_identity_service`

**Classes/Functions/Constants:**
- **`class BaseIdentityService(ABC)`**: The abstract base class for identity service providers.
    - **`__init__(self, config: Dict[str, Any])`**: Initializes the service, setting up configuration and an optional in-memory cache.
    - **`async def get_user_profile(self, auth_claims: Dict[str, Any]) -> Optional[Dict[str, Any]]`**: (Abstract) Fetches additional profile details for an authenticated user based on claims.
    - **`async def search_users(self, query: str, limit: int = 10) -> List[Dict[str, Any]]`**: (Abstract) Searches for users based on a query string (e.g., for autocomplete).
- **`def create_identity_service(config: Optional[Dict[str, Any]]) -> Optional[BaseIdentityService]`**: A factory function that instantiates an identity service provider. It has special handling for the built-in `local_file` provider and uses Python entry points for all other provider types.

### Subdirectory APIs

#### providers/
**Purpose:** Contains concrete implementations of the abstract service classes. It ships with a built-in provider for the `IdentityService` that is useful for development and testing.
**Key Exports:** `LocalFileIdentityService`
**Import Examples:**
```python
# Direct import of the concrete implementation
from solace_ai_connector.common.services.providers.local_file_identity_service import LocalFileIdentityService

# Or import the entire providers module
from solace_ai_connector.common.services import providers
```

## Complete Usage Guide

### 1. Using the Service Factories (Recommended Approach)
The factories are the primary way to create and use services. They abstract away the specific implementation details and handle plugin loading.

**Example: Creating Identity and Employee Services**

```python
import asyncio
from solace_ai_connector.common.services.identity_service import create_identity_service
from solace_ai_connector.common.services.employee_service import create_employee_service

async def main():
    # --- Identity Service Example (using built-in provider) ---
    identity_config = {
        "type": "local_file",
        "file_path": "path/to/your/users.json",
        "lookup_key": "email",  # Key to use for lookups from auth_claims
        "cache_ttl_seconds": 3600
    }
    identity_service = create_identity_service(identity_config)

    if identity_service:
        print("Identity Service created.")
        # Fetch a user profile
        auth_claims = {"email": "jane.doe@example.com"}
        user_profile = await identity_service.get_user_profile(auth_claims)
        print(f"User Profile: {user_profile}")

        # Search for users
        search_results = await identity_service.search_users("Jane")
        print(f"Search Results: {search_results}")

    # --- Employee Service Example (using external plugin) ---
    employee_config = {
        "type": "bamboohr_plugin",  # Must match plugin entry point name
        "api_key": "your-secret-api-key",
        "subdomain": "your-company",
        "cache_ttl_seconds": 7200
    }
    employee_service = create_employee_service(employee_config)

    if employee_service:
        print("\nEmployee Service created.")
        # Get employee profile
        employee_profile = await employee_service.get_employee_profile("jane.doe@example.com")
        print(f"Employee Profile: {employee_profile}")

        # Get time off data
        time_off = await employee_service.get_time_off_data("jane.doe@example.com")
        print(f"Time Off Data: {time_off}")

        # Get entire employee directory
        df = await employee_service.get_employee_dataframe()
        print(f"Employee Directory shape: {df.shape}")

asyncio.run(main())
```

### 2. Direct Instantiation of Built-in Providers
For testing or when you know you'll always use a specific built-in provider, you can instantiate directly.

**Example: Using LocalFileIdentityService Directly**

```python
import asyncio
import json
from solace_ai_connector.common.services.providers.local_file_identity_service import LocalFileIdentityService

async def setup_and_use_local_identity():
    # Create sample users.json file
    users_data = [
        {
            "id": "jdoe",
            "email": "jane.doe@example.com", 
            "name": "Jane Doe",
            "title": "Senior Engineer",
            "manager_id": "ssmith"
        },
        {
            "id": "ssmith",
            "email": "sam.smith@example.com",
            "name": "Sam Smith", 
            "title": "Engineering Manager"
        }
    ]

    with open("users.json", "w") as f:
        json.dump(users_data, f)

    # Configuration without 'type' key for direct instantiation
    config = {
        "file_path": "users.json",
        "lookup_key": "id",
        "cache_ttl_seconds": 1800
    }

    # Instantiate directly
    local_service = LocalFileIdentityService(config)
    
    # Use the service
    auth_claims = {"id": "jdoe"}
    profile = await local_service.get_user_profile(auth_claims)
    print(f"User profile: {profile}")
    
    # Search functionality
    results = await local_service.search_users("jane", limit=5)
    print(f"Search results: {results}")

asyncio.run(setup_and_use_local_identity())
```

### 3. Creating Custom Service Providers
To create your own service provider, inherit from the appropriate base class and implement all abstract methods.

**Example: Custom Employee Service Provider**

```python
import pandas as pd
from typing import Any, Dict, List, Optional
from solace_ai_connector.common.services.employee_service import BaseEmployeeService

class CustomEmployeeService(BaseEmployeeService):
    """Custom employee service that connects to your HR system."""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.api_endpoint = config.get("api_endpoint")
        self.api_key = config.get("api_key")
    
    async def get_employee_dataframe(self) -> pd.DataFrame:
        """Fetch all employees and return as DataFrame."""
        # Your implementation here
        # This should return a DataFrame with canonical schema columns
        employees_data = await self._fetch_all_employees()
        return pd.DataFrame(employees_data)
    
    async def get_employee_profile(self, employee_id: str) -> Optional[Dict[str, Any]]:
        """Fetch single employee profile."""
        # Your implementation here
        return await self._fetch_employee_by_id(employee_id)
    
    async def get_time_off_data(self, employee_id: str) -> List[Dict[str, Any]]:
        """Fetch time off data for employee."""
        # Must return list of dicts with 'start', 'end', 'type', 'amount' keys
        return await self._fetch_time_off(employee_id)
    
    async def get_employee_profile_picture(self, employee_id: str) -> Optional[str]:
        """Fetch profile picture as data URI."""
        return await self._fetch_profile_picture(employee_id)
    
    # Your private helper methods
    async def _fetch_all_employees(self):
        # Implementation details
        pass
    
    async def _fetch_employee_by_id(self, employee_id: str):
        # Implementation details
        pass
    
    async def _fetch_time_off(self, employee_id: str):
        # Implementation details
        pass
    
    async def _fetch_profile_picture(self, employee_id: str):
        # Implementation details
        pass

# Usage
config = {
    "api_endpoint": "https://your-hr-system.com/api",
    "api_key": "your-api-key",
    "cache_ttl_seconds": 3600
}

custom_service = CustomEmployeeService(config)
```

### 4. Working with Both Services Together
Often you'll want to use both identity and employee services together for comprehensive user information.

**Example: Combined Service Usage**

```python
import asyncio
from solace_ai_connector.common.services.identity_service import create_identity_service
from solace_ai_connector.common.services.employee_service import create_employee_service

async def comprehensive_user_lookup(user_identifier: str):
    # Setup both services
    identity_config = {
        "type": "local_file",
        "file_path": "users.json",
        "lookup_key": "email"
    }
    
    employee_config = {
        "type": "your_hr_plugin",
        "api_key": "your-key"
    }
    
    identity_service = create_identity_service(identity_config)
    employee_service = create_employee_service(employee_config)
    
    # Get comprehensive user information
    auth_claims = {"email": user_identifier}
    
    # Get identity information
    identity_profile = None
    if identity_service:
        identity_profile = await identity_service.get_user_profile(auth_claims)
    
    # Get employee information
    employee_profile = None
    time_off_data = None
    profile_picture = None
    
    if employee_service:
        employee_profile = await employee_service.get_employee_profile(user_identifier)
        time_off_data = await employee_service.get_time_off_data(user_identifier)
        profile_picture = await employee_service.get_employee_profile_picture(user_identifier)
    
    # Combine all information
    comprehensive_profile = {
        "identity": identity_profile,
        "employee": employee_profile,
        "time_off": time_off_data,
        "profile_picture": profile_picture
    }
    
    return comprehensive_profile

# Usage
user_info = asyncio.run(comprehensive_user_lookup("jane.doe@example.com"))
print(f"Complete user information: {user_info}")
```

This guide demonstrates the flexibility of the services framework, from simple factory usage to creating custom providers and combining multiple services for comprehensive functionality.

# content_hash: 82b39425a596ce17f7d767465a57a6393931091b51fbc6d4996ae7f953daf269

================================================================================

## Section 15: common/utils/embeds/embeds_llm.txt

**Source file:** `common/utils/embeds/embeds_llm.txt`

# DEVELOPER GUIDE: embeds

## Quick Summary
The `embeds` directory provides a comprehensive system for finding, parsing, and resolving embedded expressions within strings. These expressions use `«...»` syntax and can represent dynamic values like mathematical calculations, datetimes, UUIDs, or content from stored artifacts. The system supports multi-step data transformation pipelines, recursive embed resolution, and includes safety features like depth and size limits. It's designed as a core component for dynamic content generation and data processing in AI applications.

## Files Overview
- `__init__.py` - Main public entry point exporting key functions and constants
- `constants.py` - Defines embed syntax (delimiters, separators), regex patterns, and type classifications
- `converter.py` - Data format conversion and serialization functions
- `evaluators.py` - Specific evaluation logic for simple embed types (math, datetime, uuid, etc.)
- `modifiers.py` - Data transformation functions that can be chained together (jsonpath, slice, grep, etc.)
- `resolver.py` - Core orchestration engine handling embed resolution, modifier chains, and recursion
- `types.py` - DataFormat enum for tracking data types during transformations

## Developer API Reference

### __init__.py
**Purpose:** Main public entry point that exports the most commonly used functions and constants from other modules.

**Import:** `from common.utils.embeds import resolve_embeds_recursively_in_string, evaluate_embed, EMBED_REGEX`

**Functions:**
- `evaluate_embed(...)` - Evaluates a single, parsed embed expression
- `resolve_embeds_in_string(...)` - Resolves embeds in a string for a single pass (non-recursive)
- `resolve_embeds_recursively_in_string(...)` - Recursively resolves all embeds in a string with safety limits

**Constants/Variables:**
- `EMBED_DELIMITER_OPEN: str` - Opening delimiter (`«`)
- `EMBED_DELIMITER_CLOSE: str` - Closing delimiter (`»`)
- `EMBED_TYPE_SEPARATOR: str` - Type/expression separator (`:`)
- `EMBED_FORMAT_SEPARATOR: str` - Format specifier separator (`|`)
- `EMBED_CHAIN_DELIMITER: str` - Modifier chain separator (`>>>`)
- `EMBED_REGEX: re.Pattern` - Compiled regex for finding embeds
- `EARLY_EMBED_TYPES: Set[str]` - Types resolved in initial pass
- `LATE_EMBED_TYPES: Set[str]` - Types resolved in subsequent pass

### constants.py
**Purpose:** Defines all static constants governing embed syntax and classification.

**Import:** `from common.utils.embeds.constants import EMBED_REGEX, EARLY_EMBED_TYPES`

**Constants/Variables:**
- `EMBED_DELIMITER_OPEN: str` - Opening delimiter (`«`)
- `EMBED_DELIMITER_CLOSE: str` - Closing delimiter (`»`)
- `EMBED_TYPE_SEPARATOR: str` - Type/expression separator (`:`)
- `EMBED_FORMAT_SEPARATOR: str` - Format specifier separator (`|`)
- `EMBED_CHAIN_DELIMITER: str` - Modifier chain separator (`>>>`)
- `EMBED_REGEX: re.Pattern` - Compiled regex with capture groups for type, expression, and format
- `EARLY_EMBED_TYPES: Set[str]` - Simple types resolved first: `{'math', 'datetime', 'uuid', 'artifact_meta', 'status_update'}`
- `LATE_EMBED_TYPES: Set[str]` - Complex types resolved later: `{'artifact_content'}`
- `TEXT_CONTAINER_MIME_TYPES: Set[str]` - MIME types considered text-based

**Usage Examples:**
```python
import re
from common.utils.embeds.constants import EMBED_REGEX

text = "The price is «math:10 * 1.15 | .2f» and the ID is «uuid:new»."

for match in EMBED_REGEX.finditer(text):
    embed_type = match.group(1)
    expression = match.group(2)
    format_spec = match.group(3)  # None if not present
    print(f"Type: {embed_type}, Expression: '{expression}', Format: '{format_spec}'")
```

### converter.py
**Purpose:** Provides core data conversion between different formats and serialization to final string representations.

**Import:** `from common.utils.embeds.converter import convert_data, serialize_data`

**Functions:**
- `convert_data(current_data: Any, current_format: Optional[DataFormat], target_format: DataFormat, log_id: str = "[Converter]", original_mime_type: Optional[str] = None) -> Tuple[Any, DataFormat, Optional[str]]` - Converts data between DataFormat types using MIME type hints for parsing
- `serialize_data(data: Any, data_format: Optional[DataFormat], target_string_format: Optional[str], original_mime_type: Optional[str], log_id: str = "[Serializer]") -> Tuple[str, Optional[str]]` - Serializes data to final string format (supports "json", "csv", "datauri", Python format specs)

**Usage Examples:**
```python
from common.utils.embeds.converter import convert_data, serialize_data
from common.utils.embeds.types import DataFormat

# Convert CSV bytes to list of dictionaries
csv_bytes = b"id,name\n1,Alice\n2,Bob"
list_of_dicts, new_format, err = convert_data(
    current_data=csv_bytes,
    current_format=DataFormat.BYTES,
    target_format=DataFormat.LIST_OF_DICTS,
    original_mime_type="text/csv"
)

# Serialize to pretty JSON
if not err:
    json_string, err = serialize_data(
        data=list_of_dicts,
        data_format=DataFormat.LIST_OF_DICTS,
        target_string_format="json_pretty",
        original_mime_type=None
    )
```

### evaluators.py
**Purpose:** Contains evaluation logic for simple embed types and the evaluator registry.

**Import:** `from common.utils.embeds.evaluators import EMBED_EVALUATORS`

**Constants/Variables:**
- `EMBED_EVALUATORS: Dict[str, Callable]` - Registry mapping embed types to evaluator functions
- `MATH_SAFE_SYMBOLS: Dict[str, Any]` - Safe mathematical functions and constants for math embeds

**Functions:**
- Individual evaluator functions (private, accessed via registry)

**Usage Examples:**
```python
# Math embed with format specifier
# «math:sqrt(16) + 2 | .2f» → "6.00"

# Datetime embed
# «datetime:now» → "2024-01-15T10:30:00.123456"
# «datetime:%Y-%m-%d» → "2024-01-15"

# UUID embed
# «uuid:new» → "550e8400-e29b-41d4-a716-446655440000"
```

### modifiers.py
**Purpose:** Implements data transformation functions that can be chained together in artifact_content embeds.

**Import:** `from common.utils.embeds.modifiers import MODIFIER_DEFINITIONS`

**Constants/Variables:**
- `MODIFIER_DEFINITIONS: Dict[str, Dict[str, Any]]` - Registry of available modifiers with their input/output formats

**Functions:**
- Individual modifier functions (private, accessed via registry)

**Usage Examples:**
```python
# Chain example in an embed:
# «artifact_content:data.json >>> jsonpath:$.users[*] >>> select_fields:name,email >>> format:json»

# Available modifiers:
# - jsonpath: Extract data using JSONPath expressions
# - select_cols/select_fields: Select specific columns/fields
# - filter_rows_eq: Filter rows by column value equality
# - slice_rows/slice_lines: Slice data by index range
# - grep: Filter text lines by regex pattern
# - head/tail: Get first/last N lines
# - apply_to_template: Apply Mustache template from artifact
```

### resolver.py
**Purpose:** Core orchestration engine that handles the complete embed resolution process.

**Import:** `from common.utils.embeds.resolver import resolve_embeds_recursively_in_string, evaluate_embed`

**Functions:**
- `resolve_embeds_in_string(text: str, context: Any, resolver_func: Callable, types_to_resolve: Set[str], log_identifier: str = "[EmbedUtil]", config: Optional[Dict[str, Any]] = None) -> Tuple[str, int, List[Tuple[int, Any]]]` - Single-pass embed resolution with buffering support
- `resolve_embeds_recursively_in_string(text: str, context: Any, resolver_func: Callable, types_to_resolve: Set[str], log_identifier: str, config: Optional[Dict], max_depth: int, current_depth: int = 0, visited_artifacts: Optional[Set[Tuple[str, int]]] = None, accumulated_size: int = 0, max_total_size: int = -1) -> str` - Recursive embed resolution with safety limits
- `evaluate_embed(embed_type: str, expression: str, format_spec: Optional[str], context: Dict[str, Any], log_identifier: str, config: Optional[Dict] = None, current_depth: int = 0, visited_artifacts: Optional[Set[Tuple[str, int]]] = None) -> Union[Tuple[str, Optional[str], int], Tuple[None, str, Any]]` - Evaluates individual embeds, handling both simple types and complex artifact_content chains

**Usage Examples:**
```python
from common.utils.embeds.resolver import resolve_embeds_recursively_in_string, evaluate_embed
from common.utils.embeds.constants import EARLY_EMBED_TYPES, LATE_EMBED_TYPES

# Context setup
context = {
    "artifact_service": artifact_service_instance,
    "session_context": {
        "app_name": "my_app",
        "user_id": "user123",
        "session_id": "session456"
    },
    "config": {
        "gateway_recursive_embed_depth": 12,
        "gateway_max_artifact_resolve_size_bytes": 10485760
    }
}

# Resolve all embeds recursively
text = "Price: «math:10 * 1.15 | .2f», Data: «artifact_content:report.csv >>> head:5 >>> format:text»"
resolved = await resolve_embeds_recursively_in_string(
    text=text,
    context=context,
    resolver_func=evaluate_embed,
    types_to_resolve=EARLY_EMBED_TYPES.union(LATE_EMBED_TYPES),
    log_identifier="[MyApp]",
    config=context["config"],
    max_depth=12
)
```

### types.py
**Purpose:** Defines the DataFormat enum used to track data types during transformations.

**Import:** `from common.utils.embeds.types import DataFormat`

**Classes:**
- `DataFormat(Enum)` - Enumeration of internal data formats
  - `BYTES` - Raw binary data
  - `STRING` - Text data
  - `JSON_OBJECT` - Parsed JSON (dict/list)
  - `LIST_OF_DICTS` - Structured tabular data

**Usage Examples:**
```python
from common.utils.embeds.types import DataFormat

# Check data format
if current_format == DataFormat.JSON_OBJECT:
    # Handle JSON data
    pass
elif current_format == DataFormat.LIST_OF_DICTS:
    # Handle tabular data
    pass
```

# content_hash: e432576d9997c97db12a4e1c4031b2c6a8f3208a54091c20cf46b7bad4b4fbd2

================================================================================

## Section 16: common/utils/utils_llm.txt

**Source file:** `common/utils/utils_llm.txt`

# DEVELOPER GUIDE: utils

## Quick Summary
The `utils` directory provides a comprehensive collection of essential, cross-cutting utilities for the Solace AI Connector. Its purpose is to offer robust, reusable solutions for common application needs including caching, platform compatibility, secure communication, logging, MIME type handling, and dynamic content generation.

The architecture consists of standalone utility files for specific tasks and a sophisticated `embeds` subdirectory for advanced dynamic expression processing. Direct files provide services like thread-safe in-memory caching, JWT-based push notification authentication, custom logging formatters, asyncio platform fixes, and MIME type classification. The `embeds` subdirectory provides a powerful system for finding, parsing, and resolving dynamic expressions embedded within strings using `«...»` syntax.

These utilities are designed to work together seamlessly - for instance, a request handler might use `mime_helpers` to validate content type, use the `embeds` system to process dynamic content, and then store results in the `InMemoryCache` for optimization.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py` - Exposes key utility functions from the package for convenient access
  - `asyncio_macos_fix.py` - Automatically applies a patch to fix asyncio subprocess issues on macOS
  - `in_memory_cache.py` - Thread-safe, singleton in-memory cache with TTL support
  - `log_formatters.py` - Custom logging formatters including Datadog-compatible JSON formatter
  - `mime_helpers.py` - Helper functions to classify and identify text-based MIME types
  - `push_notification_auth.py` - JWT-based authentication for sending and receiving push notifications

- **Subdirectories:**
  - `embeds/` - Comprehensive system for processing embedded dynamic expressions with multi-step transformations

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Main entry point for the utils package, exporting the most commonly used utility functions
**Import:** `from solace_ai_connector.common.utils import is_text_based_mime_type`

**Classes/Functions/Constants:**
- `is_text_based_mime_type(mime_type: Optional[str]) -> bool` - Checks if a MIME type is text-based

#### asyncio_macos_fix.py
**Purpose:** Provides automatic fix for asyncio subprocess creation issues on macOS by patching the event loop policy
**Import:** `from solace_ai_connector.common.utils import asyncio_macos_fix` (importing applies the patch)

**Classes/Functions/Constants:**
- `apply_macos_asyncio_fix() -> bool` - Applies the asyncio fix for macOS subprocess support
- `ensure_asyncio_compatibility() -> bool` - Ensures asyncio compatibility (called automatically on import)

#### in_memory_cache.py
**Purpose:** Thread-safe singleton in-memory cache with TTL support for storing frequently accessed data
**Import:** `from solace_ai_connector.common.utils.in_memory_cache import InMemoryCache`

**Classes/Functions/Constants:**
- **`InMemoryCache`** - Singleton cache class
  - `set(key: str, value: Any, ttl: Optional[int] = None) -> None` - Store key-value with optional TTL
  - `get(key: str, default: Any = None) -> Any` - Retrieve value by key with default fallback
  - `delete(key: str) -> bool` - Delete specific key-value pair
  - `clear() -> bool` - Remove all cached data

#### log_formatters.py
**Purpose:** Custom logging formatters for structured log output compatible with monitoring platforms
**Import:** `from solace_ai_connector.common.utils.log_formatters import DatadogJsonFormatter`

**Classes/Functions/Constants:**
- **`DatadogJsonFormatter(logging.Formatter)`** - JSON formatter for Datadog compatibility
  - `format(record) -> str` - Formats log records as JSON with Datadog-standard fields

#### mime_helpers.py
**Purpose:** Utilities for handling and classifying MIME types, focusing on text-based content identification
**Import:** `from solace_ai_connector.common.utils.mime_helpers import is_text_based_mime_type, is_text_based_file, TEXT_CONTAINER_MIME_TYPES`

**Classes/Functions/Constants:**
- `is_text_based_mime_type(mime_type: Optional[str]) -> bool` - Check if MIME type represents text content
- `is_text_based_file(mime_type: Optional[str], content_bytes: Optional[bytes] = None) -> bool` - Advanced text detection with content analysis
- `TEXT_CONTAINER_MIME_TYPES: Set[str]` - Set of non-text/* MIME types that contain text (JSON, XML, etc.)

#### push_notification_auth.py
**Purpose:** JWT-based authentication system for secure push notification sending and receiving
**Import:** `from solace_ai_connector.common.utils.push_notification_auth import PushNotificationSenderAuth, PushNotificationReceiverAuth`

**Classes/Functions/Constants:**
- **`PushNotificationSenderAuth`** - Handles sending authenticated notifications
  - `generate_jwk() -> None` - Generate RSA key pair for signing
  - `handle_jwks_endpoint(request: Request) -> JSONResponse` - Serve public keys endpoint
  - `send_push_notification(url: str, data: dict) -> None` - Send authenticated notification
  - `verify_push_notification_url(url: str) -> bool` - Verify notification endpoint
- **`PushNotificationReceiverAuth`** - Handles receiving and verifying notifications
  - `load_jwks(jwks_url: str) -> None` - Load public keys from JWKS endpoint
  - `verify_push_notification(request: Request) -> bool` - Verify incoming notification

### Subdirectory APIs

#### embeds/
**Purpose:** Comprehensive system for processing embedded dynamic expressions using `«...»` syntax with support for math, datetime, UUIDs, and artifact content with transformation pipelines
**Key Exports:** Main resolution functions, evaluators, and constants for embed processing
**Import Examples:**
```python
from solace_ai_connector.common.utils.embeds import resolve_embeds_recursively_in_string, evaluate_embed, EMBED_REGEX
from solace_ai_connector.common.utils.embeds.constants import EARLY_EMBED_TYPES, LATE_EMBED_TYPES
from solace_ai_connector.common.utils.embeds.types import DataFormat
```

## Complete Usage Guide

### 1. Basic Utility Usage

#### MIME Type Classification
```python
from solace_ai_connector.common.utils import is_text_based_mime_type
from solace_ai_connector.common.utils.mime_helpers import is_text_based_file, TEXT_CONTAINER_MIME_TYPES

# Basic MIME type checking
if is_text_based_mime_type("application/json"):
    print("JSON is text-based")

# Advanced file content analysis
content = b'{"key": "value"}'
if is_text_based_file("application/octet-stream", content):
    print("Content appears to be text despite generic MIME type")

# Check against known text containers
if "application/yaml" in TEXT_CONTAINER_MIME_TYPES:
    print("YAML is a known text container")
```

#### In-Memory Caching
```python
from solace_ai_connector.common.utils.in_memory_cache import InMemoryCache

# Get singleton cache instance
cache = InMemoryCache()

# Store data with TTL
cache.set("user_session", {"user_id": "123", "role": "admin"}, ttl=3600)
cache.set("config", {"debug": True})  # No TTL - persists until cleared

# Retrieve data
session = cache.get("user_session", {})
config = cache.get("config")

# Clean up
cache.delete("user_session")
cache.clear()  # Remove all data
```

#### Custom Logging
```python
import logging
from solace_ai_connector.common.utils.log_formatters import DatadogJsonFormatter

# Set up Datadog-compatible logging
logger = logging.getLogger("my_app")
handler = logging.StreamHandler()
handler.setFormatter(DatadogJsonFormatter())
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# Log with automatic JSON formatting
logger.info("User action completed", extra={"user_id": "123", "action": "login"})
```

### 2. Push Notification Authentication

#### Sender Setup
```python
from solace_ai_connector.common.utils.push_notification_auth import PushNotificationSenderAuth
from starlette.applications import Starlette
from starlette.routing import Route

# Initialize sender
sender_auth = PushNotificationSenderAuth()
sender_auth.generate_jwk()

# Set up JWKS endpoint for clients
app = Starlette(routes=[
    Route("/.well-known/jwks.json", sender_auth.handle_jwks_endpoint, methods=["GET"])
])

# Send authenticated notification
await sender_auth.send_push_notification(
    url="https://client.example.com/webhook",
    data={"event": "user_login", "user_id": "123", "timestamp": "2024-01-15T10:30:00Z"}
)
```

#### Receiver Setup
```python
from solace_ai_connector.common.utils.push_notification_auth import PushNotificationReceiverAuth
from starlette.requests import Request
from starlette.responses import JSONResponse

# Initialize receiver
receiver_auth = PushNotificationReceiverAuth()
await receiver_auth.load_jwks("https://sender.example.com/.well-known/jwks.json")

# Verify incoming notifications
async def webhook_handler(request: Request):
    try:
        if await receiver_auth.verify_push_notification(request):
            data = await request.json()
            # Process verified notification
            return JSONResponse({"status": "success"})
        else:
            return JSONResponse({"error": "Invalid authentication"}, status_code=401)
    except Exception as e:
        return JSONResponse({"error": str(e)}, status_code=400)
```

### 3. Embedded Expressions Processing

#### Basic Embed Resolution
```python
from solace_ai_connector.common.utils.embeds import resolve_embeds_recursively_in_string, evaluate_embed
from solace_ai_connector.common.utils.embeds.constants import EARLY_EMBED_TYPES, LATE_EMBED_TYPES

# Simple math and datetime embeds
text = "Price: «math:10 * 1.15 | .2f», Generated: «datetime:%Y-%m-%d %H:%M», ID: «uuid:new»"

context = {
    "session_context": {"app_name": "my_app"},
    "config": {"gateway_recursive_embed_depth": 5}
}

resolved = await resolve_embeds_recursively_in_string(
    text=text,
    context=context,
    resolver_func=evaluate_embed,
    types_to_resolve=EARLY_EMBED_TYPES,
    log_identifier="[MyApp]",
    config=context["config"],
    max_depth=5
)
# Result: "Price: 11.50, Generated: 2024-01-15 10:30, ID: 550e8400-e29b-41d4-a716-446655440000"
```

#### Advanced Artifact Content Processing
```python
# Complex artifact processing with transformation chains
template = """
Report Summary:
«artifact_content:sales_data.csv >>> head:10 >>> select_cols:product,revenue >>> format:text»

Top Products (JSON):
«artifact_content:sales_data.csv >>> jsonpath:$[?(@.revenue > 1000)] >>> select_fields:product,revenue >>> format:json_pretty»

Configuration:
«artifact_content:config.json >>> jsonpath:$.database >>> format:json»
"""

context = {
    "artifact_service": artifact_service_instance,
    "session_context": {
        "app_name": "sales_app",
        "user_id": "analyst_123"
    },
    "config": {
        "gateway_recursive_embed_depth": 12,
        "gateway_max_artifact_resolve_size_bytes": 10485760
    }
}

resolved_report = await resolve_embeds_recursively_in_string(
    text=template,
    context=context,
    resolver_func=evaluate_embed,
    types_to_resolve=EARLY_EMBED_TYPES.union(LATE_EMBED_TYPES),
    log_identifier="[SalesReport]",
    config=context["config"],
    max_depth=12
)
```

### 4. Integrated Usage Patterns

#### Request Processing Pipeline
```python
from solace_ai_connector.common.utils import is_text_based_mime_type
from solace_ai_connector.common.utils.in_memory_cache import InMemoryCache
from solace_ai_connector.common.utils.embeds import resolve_embeds_recursively_in_string

async def process_request(content_type: str, template: str, context: dict):
    cache = InMemoryCache()
    
    # Validate content type
    if not is_text_based_mime_type(content_type):
        raise ValueError(f"Unsupported content type: {content_type}")
    
    # Check cache first
    cache_key = f"processed_{hash(template)}"
    cached_result = cache.get(cache_key)
    if cached_result:
        return cached_result
    
    # Process embeds
    result = await resolve_embeds_recursively_in_string(
        text=template,
        context=context,
        resolver_func=evaluate_embed,
        types_to_resolve=EARLY_EMBED_TYPES.union(LATE_EMBED_TYPES),
        log_identifier="[RequestProcessor]",
        config=context.get("config", {}),
        max_depth=10
    )
    
    # Cache result for 5 minutes
    cache.set(cache_key, result, ttl=300)
    return result
```

#### Platform Compatibility Setup
```python
# Early in application startup
from solace_ai_connector.common.utils import asyncio_macos_fix

# The fix is applied automatically on import, but you can check status
if asyncio_macos_fix.ensure_asyncio_compatibility():
    print("Asyncio compatibility ensured")
else:
    print("Warning: Asyncio compatibility could not be ensured")

# Now safe to use asyncio subprocess operations on macOS
import asyncio

async def run_subprocess():
    process = await asyncio.create_subprocess_exec(
        "echo", "Hello World",
        stdout=asyncio.subprocess.PIPE
    )
    stdout, _ = await process.communicate()
    return stdout.decode()
```

This comprehensive guide provides developers with everything needed to effectively use the `utils` directory, from basic utility functions to complex embedded expression processing and secure communication patterns.

# content_hash: ba11166cc7e984a70b285dfab39c6fab6a0f272117ad984c7d0299b2120f8c98

================================================================================

## Section 17: core_a2a/core_a2a_llm.txt

**Source file:** `core_a2a/core_a2a_llm.txt`

# DEVELOPER GUIDE: core_a2a

## Quick Summary
The `core_a2a` directory provides a reusable service layer for core Agent-to-Agent (A2A) interactions. It handles task submission (both regular and streaming), task cancellation, and agent discovery processing while being decoupled from specific gateway implementations and SAC messaging details.

## Files Overview
- `__init__.py` - Package initialization file for the core A2A service layer
- `service.py` - Main service class that encapsulates A2A protocol logic and agent registry operations

## Developer API Reference

### __init__.py
**Purpose:** Package initialization for the core A2A service layer
**Import:** `import core_a2a`

No public classes, functions, or constants defined.

### service.py
**Purpose:** Provides the main CoreA2AService class for handling A2A protocol operations
**Import:** `from core_a2a.service import CoreA2AService`

**Classes:**
- `CoreA2AService(agent_registry: AgentRegistry, namespace: str)` - Main service class for A2A operations
  - `submit_task(agent_name: str, a2a_message: A2AMessage, session_id: str, client_id: str, reply_to_topic: str, user_id: str = "default_user", a2a_user_config: Optional[Dict[str, Any]] = None, metadata_override: Optional[Dict[str, Any]] = None) -> Tuple[str, Dict, Dict]` - Constructs topic, payload, and user properties for non-streaming task requests
  - `submit_streaming_task(agent_name: str, a2a_message: A2AMessage, session_id: str, client_id: str, reply_to_topic: str, status_to_topic: str, user_id: str = "default_user", a2a_user_config: Optional[Dict[str, Any]] = None, metadata_override: Optional[Dict[str, Any]] = None) -> Tuple[str, Dict, Dict]` - Constructs topic, payload, and user properties for streaming task requests
  - `cancel_task(agent_name: str, task_id: str, client_id: str, user_id: str = "default_user") -> Tuple[str, Dict, Dict]` - Constructs topic, payload, and user properties for task cancellation
  - `get_agent(agent_name: str) -> Optional[AgentCard]` - Retrieves a specific agent card by name from the registry
  - `get_all_agents() -> List[AgentCard]` - Retrieves all currently discovered agent cards from the registry
  - `process_discovery_message(agent_card: AgentCard)` - Processes an incoming agent card discovery message
  - `agent_registry: AgentRegistry` - The shared agent registry instance
  - `namespace: str` - The A2A namespace string
  - `log_identifier: str` - Identifier used for logging

**Functions:**
None (all functionality is encapsulated in the CoreA2AService class)

**Constants/Variables:**
None

**Usage Examples:**
```python
# Import required dependencies
from core_a2a.service import CoreA2AService
from common.agent_registry import AgentRegistry
from common.types import A2AMessage, AgentCard

# Initialize the service
agent_registry = AgentRegistry()
namespace = "my_NAMESPACE"
service = CoreA2AService(agent_registry, namespace)

# Submit a regular task
message = A2AMessage(parts=[{"type": "text", "content": "Hello"}])
topic, payload, user_props = service.submit_task(
    agent_name="my_agent",
    a2a_message=message,
    session_id="session_123",
    client_id="client_456",
    reply_to_topic="responses/client_456",
    user_id="user_789"
)

# Submit a streaming task
topic, payload, user_props = service.submit_streaming_task(
    agent_name="my_agent",
    a2a_message=message,
    session_id="session_123",
    client_id="client_456",
    reply_to_topic="responses/client_456",
    status_to_topic="status/client_456",
    user_id="user_789"
)

# Cancel a task
topic, payload, user_props = service.cancel_task(
    agent_name="my_agent",
    task_id="task-abc123",
    client_id="client_456"
)

# Get agent information
agent = service.get_agent("my_agent")
all_agents = service.get_all_agents()

# Process discovery message
agent_card = AgentCard(name="new_agent", description="A new agent")
service.process_discovery_message(agent_card)
```

# content_hash: b3d56974dc9be38b9bf0b07616ffccf5e845e2eb48bc1c6790de06d9023ec6a2

================================================================================

## Section 18: gateway/base/base_llm.txt

**Source file:** `gateway/base/base_llm.txt`

# DEVELOPER GUIDE: gateway/base

## Quick Summary
The `base` directory provides the foundational framework for building Gateway implementations within the Solace AI Connector. It establishes abstract base classes that handle common gateway functionality including A2A (Agent-to-Agent) protocol communication, configuration management, Solace broker integration, user authentication, and task context management. Developers subclass these base classes to create gateways that bridge external platforms (web APIs, chat systems, etc.) with the AI agent ecosystem.

## Files Overview
- `__init__.py` - Package initialization file
- `app.py` - Contains `BaseGatewayApp` for application-level configuration and setup
- `component.py` - Contains `BaseGatewayComponent` for core gateway logic and A2A message processing
- `task_context.py` - Provides `TaskContextManager` for thread-safe task context storage

## Developer API Reference

### __init__.py
**Purpose:** Initializes the gateway.base package
**Import:** `from gateway.base import ...`

---

### app.py
**Purpose:** Provides the base application class that handles configuration schema merging, Solace broker setup, and component instantiation
**Import:** `from gateway.base.app import BaseGatewayApp, BaseGatewayComponent`

**Classes:**
- `BaseGatewayComponent(ComponentBase)` - Base marker class for gateway components
- `BaseGatewayApp(app_info: Dict[str, Any], **kwargs)` - Main application class for gateway implementations
  - `_get_gateway_component_class(self) -> Type[BaseGatewayComponent]` - **[Abstract]** Must return the specific gateway component class
  - `namespace: str` - Absolute topic prefix for A2A communication
  - `gateway_id: str` - Unique ID for this gateway instance
  - `artifact_service_config: Dict` - Configuration for the shared ADK Artifact Service
  - `enable_embed_resolution: bool` - Flag to enable late-stage embed resolution
  - `gateway_max_artifact_resolve_size_bytes: int` - Maximum size for artifact resolution
  - `gateway_recursive_embed_depth: int` - Maximum depth for recursive embed resolution

**Constants/Variables:**
- `BASE_GATEWAY_APP_SCHEMA: Dict[str, List[Dict[str, Any]]]` - Base configuration schema
- `SPECIFIC_APP_SCHEMA_PARAMS_ATTRIBUTE_NAME: str` - Class attribute name for subclass-specific parameters

**Usage Examples:**
```python
from typing import Type, List, Dict, Any
from gateway.base.app import BaseGatewayApp
from .component import MyGatewayComponent

class MyGatewayApp(BaseGatewayApp):
    # Define additional configuration parameters
    SPECIFIC_APP_SCHEMA_PARAMS: List[Dict[str, Any]] = [
        {
            "name": "api_key",
            "required": True,
            "type": "string",
            "description": "API key for external platform"
        }
    ]

    def _get_gateway_component_class(self) -> Type[MyGatewayComponent]:
        return MyGatewayComponent

# Usage in configuration
app_config = {
    "name": "my-gateway",
    "app_class": MyGatewayApp,
    "app_config": {
        "namespace": "myorg/prod",
        "artifact_service": {"type": "local_file"},
        "api_key": "secret-key"
    }
}
```

---

### component.py
**Purpose:** Provides the abstract base class for gateway components with core A2A protocol handling, service management, and external platform integration
**Import:** `from gateway.base.component import BaseGatewayComponent`

**Classes:**
- `BaseGatewayComponent(**kwargs: Any)` - Abstract base class for gateway components
  - **Public Methods:**
    - `get_config(self, key: str, default: Any = None) -> Any` - Retrieves configuration values, checking app_config first
    - `publish_a2a_message(self, topic: str, payload: Dict, user_properties: Optional[Dict] = None) -> None` - Publishes A2A messages to Solace broker
    - `authenticate_and_enrich_user(self, external_event_data: Any) -> Optional[Dict[str, Any]]` - Orchestrates user authentication and identity enrichment
    - `submit_a2a_task(self, target_agent_name: str, a2a_parts: List[A2APart], external_request_context: Dict[str, Any], user_identity: Any, is_streaming: bool = True, api_version: str = "v2") -> str` - Submits tasks to agents and returns task_id
    - `run(self) -> None` - Starts component operations including message processing and external listener
    - `cleanup(self) -> None` - Cleans up resources and stops all operations
  - **Abstract Methods (Must Implement):**
    - `_extract_initial_claims(self, external_event_data: Any) -> Optional[Dict[str, Any]]` - Extract user identity from platform event
    - `_start_listener(self) -> None` - Start listening to external platform
    - `_stop_listener(self) -> None` - Stop external platform listener
    - `_translate_external_input(self, external_event: Any) -> Tuple[str, List[A2APart], Dict[str, Any]]` - Convert external input to A2A format
    - `_send_update_to_external(self, external_request_context: Dict[str, Any], event_data: Union[TaskStatusUpdateEvent, TaskArtifactUpdateEvent], is_final_chunk_of_update: bool) -> None` - Send streaming updates to external platform
    - `_send_final_response_to_external(self, external_request_context: Dict[str, Any], task_data: Task) -> None` - Send final response to external platform
    - `_send_error_to_external(self, external_request_context: Dict[str, Any], error_data: JSONRPCError) -> None` - Send error to external platform
  - **Properties:**
    - `namespace: str` - A2A communication namespace
    - `gateway_id: str` - Unique gateway identifier
    - `agent_registry: AgentRegistry` - Registry of available agents
    - `core_a2a_service: CoreA2AService` - A2A protocol service
    - `shared_artifact_service: Optional[BaseArtifactService]` - Artifact storage service
    - `task_context_manager: TaskContextManager` - Task context storage
    - `identity_service: Optional[BaseIdentityService]` - User identity service

**Usage Examples:**
```python
from typing import Any, Dict, List, Optional, Tuple, Union
from gateway.base.component import BaseGatewayComponent
from ...common.types import Part as A2APart, TextPart, Task, TaskStatusUpdateEvent, TaskArtifactUpdateEvent, JSONRPCError

class MyGatewayComponent(BaseGatewayComponent):
    
    async def _extract_initial_claims(self, external_event_data: Any) -> Optional[Dict[str, Any]]:
        # Extract user identity from your platform's event
        user_id = external_event_data.get("user_id")
        if user_id:
            return {"id": user_id, "source": "my_platform"}
        return None
    
    def _start_listener(self) -> None:
        # Start your platform listener (web server, websocket, etc.)
        self.server = start_my_platform_server()
    
    def _stop_listener(self) -> None:
        # Stop your platform listener
        if hasattr(self, 'server'):
            self.server.stop()
    
    def _translate_external_input(self, external_event: Any) -> Tuple[str, List[A2APart], Dict[str, Any]]:
        # Convert platform input to A2A format
        agent_name = external_event.get("target_agent", "default-agent")
        message_text = external_event.get("message", "")
        parts = [TextPart(text=message_text)]
        context = {
            "platform_user_id": external_event.get("user_id"),
            "platform_channel": external_event.get("channel_id")
        }
        return agent_name, parts, context
    
    async def _send_update_to_external(self, external_request_context: Dict[str, Any], 
                                     event_data: Union[TaskStatusUpdateEvent, TaskArtifactUpdateEvent], 
                                     is_final_chunk_of_update: bool) -> None:
        # Send streaming update back to your platform
        channel = external_request_context.get("platform_channel")
        if isinstance(event_data, TaskStatusUpdateEvent) and event_data.status.message:
            for part in event_data.status.message.parts:
                if isinstance(part, TextPart):
                    await self.send_to_platform(channel, part.text)
    
    async def _send_final_response_to_external(self, external_request_context: Dict[str, Any], task_data: Task) -> None:
        # Send final response to your platform
        channel = external_request_context.get("platform_channel")
        if task_data.status and task_data.status.message:
            for part in task_data.status.message.parts:
                if isinstance(part, TextPart):
                    await self.send_final_to_platform(channel, part.text)
    
    async def _send_error_to_external(self, external_request_context: Dict[str, Any], error_data: JSONRPCError) -> None:
        # Send error message to your platform
        channel = external_request_context.get("platform_channel")
        await self.send_error_to_platform(channel, f"Error: {error_data.message}")

# Example of handling an incoming request
async def handle_platform_request(self, platform_event):
    # Authenticate user
    user_identity = await self.authenticate_and_enrich_user(platform_event)
    if not user_identity:
        await self.send_error_to_platform(platform_event.channel, "Authentication failed")
        return
    
    # Translate input
    agent_name, a2a_parts, context = self._translate_external_input(platform_event)
    
    # Submit task
    task_id = await self.submit_a2a_task(
        target_agent_name=agent_name,
        a2a_parts=a2a_parts,
        external_request_context=context,
        user_identity=user_identity,
        is_streaming=True
    )
    
    # Task responses will be handled automatically via the abstract methods
```

---

### task_context.py
**Purpose:** Provides thread-safe storage and retrieval of task context data
**Import:** `from gateway.base.task_context import TaskContextManager`

**Classes:**
- `TaskContextManager()` - Thread-safe manager for task context storage
  - `store_context(self, task_id: str, context_data: Dict[str, Any]) -> None` - Store context for a task
  - `get_context(self, task_id: str) -> Optional[Dict[str, Any]]` - Retrieve context for a task
  - `remove_context(self, task_id: str) -> Optional[Dict[str, Any]]` - Remove and return context for a task
  - `clear_all_contexts_for_testing(self) -> None` - Clear all contexts (testing only)

**Usage Examples:**
```python
from gateway.base.task_context import TaskContextManager

# Initialize manager
context_manager = TaskContextManager()

# Store context when submitting a task
task_context = {
    "user_id": "user123",
    "channel_id": "channel456",
    "original_message_id": "msg789"
}
context_manager.store_context("task-abc-123", task_context)

# Retrieve context when processing response
context = context_manager.get_context("task-abc-123")
if context:
    channel = context.get("channel_id")
    # Send response to the correct channel

# Clean up when task is complete
context_manager.remove_context("task-abc-123")
```

# content_hash: 46452d0e698f0f926d2e24b30ed82a6df7cde1c604ecf2a4bc9af5e0326574f9

================================================================================

## Section 19: gateway/gateway_llm.txt

**Source file:** `gateway/gateway_llm.txt`

# DEVELOPER GUIDE: gateway

## Quick Summary
The `gateway` directory provides a comprehensive framework for building gateway implementations that bridge external platforms with the Solace AI Connector's A2A (Agent-to-Agent) messaging system. The architecture consists of a foundational base framework and three specialized gateway implementations: HTTP/SSE for web interfaces, Slack for team collaboration, and Webhook for external system integration. All gateways share common patterns for authentication, message translation, and real-time communication while providing platform-specific features.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Marks the directory as a Python package (empty file)
  - `gateway_llm.txt`: Documentation file containing comprehensive developer guide content
- **Subdirectories:**
  - `base/`: Foundational classes and utilities for building all gateway implementations
  - `http_sse/`: A complete HTTP/SSE gateway with a FastAPI web server for real-time web UI backends
  - `slack/`: A gateway for integrating with the Slack collaboration platform
  - `webhook/`: A universal webhook gateway for receiving HTTP requests from external systems

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Initializes the `gateway` module, making it a Python package
**Import:** `from gateway import ...`

**Classes/Functions/Constants:**
This file is empty and contains no direct exports.

#### gateway_llm.txt
**Purpose:** Contains comprehensive documentation and developer guide content
**Import:** Not applicable (documentation file)

**Classes/Functions/Constants:**
This is a text documentation file, not a Python module.

### Subdirectory APIs

#### base/
**Purpose:** Provides the foundational, abstract classes for building all Gateway implementations. It establishes a framework for configuration, A2A message handling, and managing the lifecycle of requests from external platforms.
**Key Exports:** `BaseGatewayApp`, `BaseGatewayComponent`, `TaskContextManager`
**Import Examples:**
```python
from gateway.base.app import BaseGatewayApp
from gateway.base.component import BaseGatewayComponent
from gateway.base.task_context import TaskContextManager
```

**Key Classes:**
- **`BaseGatewayApp`**: Main application class that handles configuration schema merging, Solace broker setup, and component instantiation
  - `_get_gateway_component_class(self)`: **[Abstract Method]** Must return the specific gateway component class
- **`BaseGatewayComponent`**: Abstract base class for gateway logic with methods for A2A communication
  - `submit_a2a_task(...)`: Primary method for submitting tasks to agents
  - `publish_a2a_message(...)`: Lower-level method for publishing A2A messages
  - Abstract methods: `_extract_initial_claims()`, `_start_listener()`, `_stop_listener()`, `_translate_external_input()`, `_send_update_to_external()`, `_send_final_response_to_external()`, `_send_error_to_external()`
- **`TaskContextManager`**: Thread-safe storage for mapping A2A task IDs to external request context

#### http_sse/
**Purpose:** Implements a complete HTTP/SSE gateway to serve a web-based user interface, bridging web protocols with the backend A2A messaging fabric.
**Key Exports:** `WebUIBackendApp`, `WebUIBackendComponent`, `SSEManager`, `SessionManager`, and various dependency injectors
**Import Examples:**
```python
from gateway.http_sse.app import WebUIBackendApp
from gateway.http_sse.component import WebUIBackendComponent
from gateway.http_sse.sse_manager import SSEManager
from gateway.http_sse.session_manager import SessionManager
from gateway.http_sse.dependencies import get_agent_service, get_task_service, get_user_id
```

**Key Classes:**
- **`WebUIBackendApp`**: Main SAC App class that defines configuration schema and launches the component
- **`WebUIBackendComponent`**: Core component hosting FastAPI server and managing shared state
- **`SessionManager`**: Manages web user sessions and A2A client/session ID mapping
- **`SSEManager`**: Manages Server-Sent Event connections for real-time streaming updates
- **Services**: `AgentService`, `TaskService`, `PeopleService` for business logic

#### slack/
**Purpose:** Provides a gateway for integrating the Solace AI Connector with the Slack collaboration platform, enabling bot interactions within Slack channels and threads.
**Key Exports:** `SlackGatewayApp`, `SlackGatewayComponent`, and various utility functions
**Import Examples:**
```python
from gateway.slack.app import SlackGatewayApp
from gateway.slack.component import SlackGatewayComponent
from gateway.slack.utils import generate_a2a_session_id, send_slack_message, correct_slack_markdown
```

#### webhook/
**Purpose:** Provides a universal webhook gateway for receiving HTTP requests from external systems and triggering A2A tasks. It is highly configurable for different authentication methods, payload formats, and target agents.
**Key Exports:** `WebhookGatewayApp`, `WebhookGatewayComponent`
**Import Examples:**
```python
from gateway.webhook.app import WebhookGatewayApp
from gateway.webhook.component import WebhookGatewayComponent
from gateway.webhook.dependencies import get_sac_component
```

## Complete Usage Guide

### 1. Creating a Custom Gateway

To create a new gateway, extend the base classes:

```python
# my_gateway/app.py
from gateway.base.app import BaseGatewayApp
from .component import MyGatewayComponent

class MyGatewayApp(BaseGatewayApp):
    """Defines the application and its configuration for My Platform."""
    SPECIFIC_APP_SCHEMA_PARAMS = [
        {
            "name": "my_platform_api_key",
            "required": True,
            "type": "string",
            "description": "API key for my platform"
        }
    ]

    def _get_gateway_component_class(self):
        return MyGatewayComponent

# my_gateway/component.py
from gateway.base.component import BaseGatewayComponent
from typing import Any, Dict, List, Optional, Tuple, Union

class MyGatewayComponent(BaseGatewayComponent):
    
    async def _extract_initial_claims(self, external_event_data: Any) -> Optional[Dict[str, Any]]:
        # Extract user identity from platform event
        user_id = external_event_data.get("user_id")
        if user_id:
            return {"id": user_id, "source": "my_platform"}
        return None
    
    def _start_listener(self) -> None:
        # Start platform listener (web server, websocket, etc.)
        self.server = self._start_my_platform_server()
    
    def _stop_listener(self) -> None:
        # Stop platform listener
        if hasattr(self, 'server'):
            self.server.stop()
    
    def _translate_external_input(self, external_event: Any) -> Tuple[str, List, Dict[str, Any]]:
        # Convert platform input to A2A format
        agent_name = external_event.get("target_agent", "default-agent")
        message_text = external_event.get("message", "")
        parts = [{"type": "text", "text": message_text}]
        context = {
            "platform_user_id": external_event.get("user_id"),
            "platform_channel": external_event.get("channel_id")
        }
        return agent_name, parts, context
    
    async def _send_update_to_external(self, external_request_context: Dict[str, Any], 
                                     event_data: Any, is_final_chunk_of_update: bool) -> None:
        # Send streaming update back to platform
        channel = external_request_context.get("platform_channel")
        await self._send_to_platform(channel, event_data)
    
    async def _send_final_response_to_external(self, external_request_context: Dict[str, Any], 
                                             task_data: Any) -> None:
        # Send final response to platform
        channel = external_request_context.get("platform_channel")
        await self._send_final_to_platform(channel, task_data)
    
    async def _send_error_to_external(self, external_request_context: Dict[str, Any], 
                                    error_data: Any) -> None:
        # Send error message to platform
        channel = external_request_context.get("platform_channel")
        await self._send_error_to_platform(channel, f"Error: {error_data.message}")
```

### 2. Using the HTTP/SSE Gateway

Set up a web UI backend:

```python
from gateway.http_sse.app import WebUIBackendApp

# Configuration
app_config = {
    "name": "my-webui-backend",
    "session_secret_key": "your-secret-key",
    "fastapi_host": "0.0.0.0",
    "fastapi_port": 8000,
    "namespace": "/my-namespace",
    "gateway_id": "webui-gateway-01"
}

# Create and run the app
webui_app = WebUIBackendApp(app_info=app_config)
webui_app.run()
```

Create custom API endpoints:

```python
from fastapi import APIRouter, Depends
from gateway.http_sse.dependencies import (
    get_agent_service, 
    get_task_service,
    get_user_id,
    ensure_session_id
)

router = APIRouter()

@router.get("/my-agents")
async def get_my_agents(
    agent_service = Depends(get_agent_service),
    user_id: str = Depends(get_user_id)
):
    agents = agent_service.get_all_agents()
    return {"user_id": user_id, "agents": [agent.model_dump() for agent in agents]}

@router.get("/stream/{task_id}")
async def stream_task_updates(
    task_id: str,
    sse_manager = Depends(get_sse_manager)
):
    async def event_generator():
        connection_queue = await sse_manager.create_sse_connection(task_id)
        try:
            while True:
                event = await connection_queue.get()
                if event is None:  # Close signal
                    break
                yield f"event: {event['event']}\ndata: {event['data']}\n\n"
        finally:
            await sse_manager.remove_sse_connection(task_id, connection_queue)
    
    return StreamingResponse(event_generator(), media_type="text/event-stream")
```

### 3. Using the Slack Gateway

```python
from gateway.slack.app import SlackGatewayApp

# Configuration for Slack integration
slack_config = {
    "name": "my-slack-gateway",
    "slack_bot_token": "xoxb-your-bot-token",
    "slack_signing_secret": "your-signing-secret",
    "namespace": "/my-namespace",
    "gateway_id": "slack-gateway-01"
}

# Create and run the Slack gateway
slack_app = SlackGatewayApp(app_info=slack_config)
slack_app.run()
```

### 4. Using the Webhook Gateway

```python
from gateway.webhook.app import WebhookGatewayApp

# Configuration for webhook integration
webhook_config = {
    "name": "my-webhook-gateway",
    "webhook_port": 8080,
    "webhook_path": "/webhook",
    "target_agent": "default-agent",
    "namespace": "/my-namespace",
    "gateway_id": "webhook-gateway-01"
}

# Create and run the webhook gateway
webhook_app = WebhookGatewayApp(app_info=webhook_config)
webhook_app.run()
```

### 5. Working with Task Context and A2A Messages

```python
from gateway.base.task_context import TaskContextManager

# Initialize task context manager
context_manager = TaskContextManager()

# Store context when submitting a task
task_context = {
    "user_id": "user123",
    "channel_id": "channel456",
    "original_message_id": "msg789"
}
context_manager.store_context("task-abc-123", task_context)

# Submit an A2A task
async def handle_external_request(self, external_event):
    # Authenticate user
    user_identity = await self.authenticate_and_enrich_user(external_event)
    
    # Translate input to A2A format
    agent_name, a2a_parts, context = self._translate_external_input(external_event)
    
    # Submit task to agent
    task_id = await self.submit_a2a_task(
        target_agent_name=agent_name,
        a2a_parts=a2a_parts,
        external_request_context=context,
        user_identity=user_identity,
        is_streaming=True
    )
    
    return task_id

# Retrieve context when processing response
context = context_manager.get_context("task-abc-123")
if context:
    channel = context.get("channel_id")
    # Send response to the correct channel

# Clean up when task is complete
context_manager.remove_context("task-abc-123")
```

This comprehensive guide shows how the gateway directory provides a flexible framework for building various types of gateways, from web UIs to chat platforms to webhook integrations, all sharing common patterns for A2A communication, authentication, and message translation.

# content_hash: 2f4ab2a3beae8e7fcce51be22a0b97422a4dc638a7bdc2929fa4860e21cf4112

================================================================================

## Section 20: gateway/http_sse/components/components_llm.txt

**Source file:** `gateway/http_sse/components/components_llm.txt`

# DEVELOPER GUIDE: components

## Quick Summary
This directory contains components for the HTTP SSE (Server-Sent Events) gateway, designed to work within the Solace AI Connector (SAC) framework. The primary component forwards messages received from the Solace broker to an internal queue, enabling real-time visualization in a web-based user interface.

## Files Overview
- `__init__.py` - Makes the `VisualizationForwarderComponent` class directly importable from the `components` package
- `visualization_forwarder_component.py` - Defines a component that forwards messages from a broker input to a Python `queue.Queue` for visualization

## Developer API Reference

### __init__.py
**Purpose:** Exposes the public components of this directory for easy importing
**Import:** `from gateway.http_sse.components import VisualizationForwarderComponent`

**Exports:**
- `VisualizationForwarderComponent` - The main component class for forwarding messages to a visualization queue

### visualization_forwarder_component.py
**Purpose:** A Solace AI Connector (SAC) component that listens for messages from a `BrokerInput` and forwards them to a specified Python `queue.Queue` for real-time display in web UI
**Import:** `from gateway.http_sse.components.visualization_forwarder_component import VisualizationForwarderComponent`

**Classes:**
- `VisualizationForwarderComponent(**kwargs: Any)` - A component that forwards messages to a target queue, initialized with configuration parameters including `target_queue_ref`
  - `invoke(message: SolaceMessage, data: Dict[str, Any]) -> None` - Core method called by SAC framework for each incoming message; formats data and places it onto target queue (framework-managed, not called directly)

**Constants/Variables:**
- `info: Dict` - Metadata dictionary required by SAC framework describing component's configuration parameters, input schema, and purpose

**Usage Examples:**
```python
import queue
from gateway.http_sse.components import VisualizationForwarderComponent
from solace_ai_connector.common.message import Message as SolaceMessage

# 1. Create a target queue that will receive the forwarded messages
# This queue is typically managed by another component, like a Web UI backend
visualization_queue = queue.Queue()

# 2. Instantiate the component with reference to the target queue
# This is usually done within a SAC flow configuration file
forwarder = VisualizationForwarderComponent(
    name="my_forwarder",
    target_queue_ref=visualization_queue
)

# 3. The invoke method is called automatically by the SAC framework
# when a message arrives from a connected BrokerInput component

# Example of consuming from the queue:
if not visualization_queue.empty():
    forwarded_data = visualization_queue.get()
    print(f"Received topic: {forwarded_data['topic']}")
    print(f"Received payload: {forwarded_data['payload']}")

# Expected structure of forwarded_data:
# {
#     "topic": "some/broker/topic",
#     "payload": {"key": "value"},
#     "user_properties": {"prop1": "value1"},
#     "_original_broker_message": <SolaceMessage object>
# }
```

# content_hash: 85f53126097e5f9eb960fd92135962e720e92c6a5e22107c62127cd28563c4b1

================================================================================

## Section 21: gateway/http_sse/http_sse_llm.txt

**Source file:** `gateway/http_sse/http_sse_llm.txt`

# DEVELOPER GUIDE: http_sse

## Quick Summary
The `http_sse` directory implements a complete HTTP/SSE (Server-Sent Events) gateway for the A2A (Agent-to-Agent) system. Its primary purpose is to serve a web-based user interface and act as a bridge between standard web protocols (HTTP, WebSockets/SSE) and the backend A2A messaging fabric.

The architecture is centered around the `WebUIBackendComponent`, a custom Solace AI Connector (SAC) component that hosts an embedded FastAPI web server. This component manages shared state and resources, such as the `SSEManager` for real-time updates, the `SessionManager` for user sessions, and the `AgentRegistry` for discovering available agents.

Subdirectories organize the functionality:
- `routers/` defines the REST API endpoints (e.g., `/tasks`, `/agents`).
- `services/` contains the business logic that the API endpoints call.
- `components/` contains specialized SAC components for message forwarding and visualization.
- `dependencies.py` uses FastAPI's dependency injection system to provide the routers and services with safe access to the shared resources managed by the main component.

This design creates a clean separation of concerns, where the web layer (FastAPI) is decoupled from the core messaging and state management layer (SAC Component).

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Standard Python package initializer
  - `app.py`: Defines the main SAC `WebUIBackendApp` with configuration schema
  - `component.py`: Core SAC component hosting FastAPI server and managing shared resources
  - `dependencies.py`: FastAPI dependency injectors for accessing shared resources
  - `main.py`: FastAPI application instance with middleware and router mounting
  - `session_manager.py`: Manages web user sessions and A2A client/session ID mapping
  - `sse_manager.py`: Manages Server-Sent Event connections for real-time updates

- **Subdirectories:**
  - `components/`: Specialized SAC components for message forwarding and visualization
  - `routers/`: FastAPI APIRouter modules for REST API endpoints
  - `services/`: Business logic layer for agents, tasks, and domain operations

## Developer API Reference

### Direct Files

#### app.py
**Purpose:** Defines the `WebUIBackendApp`, a custom SAC App class that specifies configuration schema and creates the `WebUIBackendComponent`
**Import:** `from gateway.http_sse.app import WebUIBackendApp`

**Classes/Functions/Constants:**
- **`WebUIBackendApp(BaseGatewayApp)`**: Main application class extending `BaseGatewayApp`
  - `__init__(app_info: Dict[str, Any], **kwargs)`: Initializes the WebUI backend app
  - `_get_gateway_component_class() -> type[BaseGatewayComponent]`: Returns `WebUIBackendComponent` class
- **`SPECIFIC_APP_SCHEMA_PARAMS: List[Dict[str, Any]]`**: Configuration parameters specific to HTTP/SSE gateway (session_secret_key, fastapi_host, fastapi_port, frontend settings, SSL configuration, etc.)

#### component.py
**Purpose:** Core component hosting FastAPI server, managing shared state, and implementing A2A message translation
**Import:** `from gateway.http_sse.component import WebUIBackendComponent`

**Classes/Functions/Constants:**
- **`WebUIBackendComponent(BaseGatewayComponent)`**: Main component class
  - **Public Accessor Methods:**
    - `get_sse_manager() -> SSEManager`: Returns shared SSEManager instance
    - `get_session_manager() -> SessionManager`: Returns shared SessionManager instance
    - `get_agent_registry() -> AgentRegistry`: Returns shared AgentRegistry instance
    - `get_core_a2a_service() -> CoreA2AService`: Returns core A2A service
    - `get_shared_artifact_service() -> Optional[BaseArtifactService]`: Returns artifact storage service
    - `get_namespace() -> str`: Returns configured A2A namespace
    - `get_gateway_id() -> str`: Returns unique gateway ID
    - `get_cors_origins() -> List[str]`: Returns CORS allowed origins
    - `get_embed_config() -> Dict[str, Any]`: Returns embed-related configuration
    - `get_config_resolver() -> ConfigResolver`: Returns ConfigResolver instance
  - **Core Logic Methods:**
    - `publish_a2a(topic: str, payload: Dict, user_properties: Optional[Dict] = None)`: Publishes A2A message
  - **GDK Hook Methods:**
    - `_start_listener()`: Starts FastAPI/Uvicorn server
    - `_stop_listener()`: Stops FastAPI/Uvicorn server
    - `_translate_external_input(external_event_data: Dict[str, Any]) -> Tuple[str, List[A2APart], Dict[str, Any]]`: Translates HTTP request to A2A message
    - `_send_update_to_external(external_request_context: Dict[str, Any], event_data: Union[TaskStatusUpdateEvent, TaskArtifactUpdateEvent], is_final_chunk_of_update: bool)`: Sends intermediate updates via SSE
    - `_send_final_response_to_external(external_request_context: Dict[str, Any], task_data: Task)`: Sends final response via SSE
    - `_send_error_to_external(external_request_context: Dict[str, Any], error_data: JSONRPCError)`: Sends error via SSE

#### dependencies.py
**Purpose:** FastAPI dependency injectors for accessing shared resources managed by WebUIBackendComponent
**Import:** `from gateway.http_sse.dependencies import get_sac_component, get_agent_registry, get_sse_manager, etc.`

**Classes/Functions/Constants:**
- **Setup Functions:**
  - `set_component_instance(component: WebUIBackendComponent)`: Sets component instance for dependencies
  - `set_api_config(config: Dict[str, Any])`: Sets API configuration
- **Core Dependencies:**
  - `get_sac_component() -> WebUIBackendComponent`: Gets component instance
  - `get_agent_registry() -> AgentRegistry`: Gets AgentRegistry
  - `get_sse_manager() -> SSEManager`: Gets SSEManager
  - `get_session_manager() -> SessionManager`: Gets SessionManager
  - `get_user_id(request: Request) -> str`: Gets user ID from request
  - `ensure_session_id(request: Request) -> str`: Ensures session ID exists
- **Service Dependencies:**
  - `get_agent_service() -> AgentService`: Gets AgentService instance
  - `get_task_service() -> TaskService`: Gets TaskService instance
  - `get_people_service() -> PeopleService`: Gets PeopleService instance
- **Configuration Dependencies:**
  - `get_namespace() -> str`: Gets A2A namespace
  - `get_gateway_id() -> str`: Gets gateway ID
  - `get_app_config() -> Dict[str, Any]`: Gets application configuration
  - `get_user_config(request: Request) -> Dict[str, Any]`: Gets user-specific configuration

#### main.py
**Purpose:** FastAPI application instance with middleware, routers, and exception handling
**Import:** `from gateway.http_sse.main import app, setup_dependencies`

**Classes/Functions/Constants:**
- **`app: FastAPI`**: Main FastAPI application instance
- **`setup_dependencies(component: WebUIBackendComponent)`**: Configures middleware and routers
- **Exception Handlers:**
  - `http_exception_handler(request: FastAPIRequest, exc: HTTPException)`: Handles HTTP exceptions
  - `validation_exception_handler(request: FastAPIRequest, exc: RequestValidationError)`: Handles validation errors
  - `generic_exception_handler(request: FastAPIRequest, exc: Exception)`: Handles unexpected exceptions
- **Health Endpoint:**
  - `read_root()`: Basic health check endpoint at `/health`

#### session_manager.py
**Purpose:** Manages web user sessions and mapping to A2A client/session IDs
**Import:** `from gateway.http_sse.session_manager import SessionManager`

**Classes/Functions/Constants:**
- **`SessionManager(secret_key: str, app_config: Dict[str, Any])`**: Session management class
  - `get_a2a_client_id(request: Request) -> str`: Gets/creates A2A client ID
  - `get_a2a_session_id(request: Request) -> Optional[str]`: Gets current A2A session ID
  - `start_new_a2a_session(request: Request) -> str`: Creates new A2A session
  - `ensure_a2a_session(request: Request) -> str`: Ensures session exists
  - `store_auth_tokens(request: Request, access_token: str, refresh_token: Optional[str])`: Stores auth tokens
  - `get_access_token(request: Request) -> Optional[str]`: Gets access token
  - `get_refresh_token(request: Request) -> Optional[str]`: Gets refresh token
  - `clear_auth_tokens(request: Request)`: Clears auth tokens
  - `dep_get_client_id() -> Callable`: Returns FastAPI dependency callable
  - `dep_ensure_session_id() -> Callable`: Returns FastAPI dependency callable

#### sse_manager.py
**Purpose:** Manages Server-Sent Event connections for streaming real-time updates
**Import:** `from gateway.http_sse.sse_manager import SSEManager`

**Classes/Functions/Constants:**
- **`SSEManager(max_queue_size: int = 200)`**: SSE connection manager
  - `create_sse_connection(task_id: str) -> asyncio.Queue`: Creates SSE connection queue
  - `remove_sse_connection(task_id: str, connection_queue: asyncio.Queue)`: Removes connection
  - `send_event(task_id: str, event_data: Dict[str, Any], event_type: str = "message")`: Sends event to connections
  - `close_connection(task_id: str, connection_queue: asyncio.Queue)`: Closes specific connection
  - `close_all_for_task(task_id: str)`: Closes all connections for task
  - `close_all()`: Closes all active connections

### Subdirectory APIs

#### components/
**Purpose:** Specialized SAC components for message forwarding and visualization
**Key Exports:** `VisualizationForwarderComponent`
**Import Examples:**
```python
from gateway.http_sse.components import VisualizationForwarderComponent
```

#### routers/
**Purpose:** FastAPI APIRouter modules defining REST API endpoints
**Key Exports:** Router instances for agents, tasks, SSE, artifacts, visualization, sessions, people, auth, users, config
**Import Examples:**
```python
from gateway.http_sse.routers import agents, tasks, sse, artifacts
from gateway.http_sse.routers.tasks import CancelTaskApiPayload
```

#### services/
**Purpose:** Business logic layer for domain-specific operations
**Key Exports:** `AgentService`, `TaskService`, `PeopleService`
**Import Examples:**
```python
from gateway.http_sse.services.agent_service import AgentService
from gateway.http_sse.services.task_service import TaskService, PublishFunc
from gateway.http_sse.services.people_service import PeopleService
```

## Complete Usage Guide

### 1. Basic Setup and Initialization

```python
# Create and configure the WebUI backend app
from gateway.http_sse.app import WebUIBackendApp

app_config = {
    "name": "my-webui-backend",
    "session_secret_key": "your-secret-key",
    "fastapi_host": "0.0.0.0",
    "fastapi_port": 8000,
    "namespace": "/my-namespace",
    "gateway_id": "webui-gateway-01"
}

webui_app = WebUIBackendApp(app_info=app_config)
webui_app.run()
```

### 2. Using Dependencies in FastAPI Routes

```python
from fastapi import APIRouter, Depends
from gateway.http_sse.dependencies import (
    get_agent_service, 
    get_task_service,
    get_user_id,
    ensure_session_id
)
from gateway.http_sse.services.agent_service import AgentService
from gateway.http_sse.services.task_service import TaskService

router = APIRouter()

@router.get("/my-agents")
async def get_my_agents(
    agent_service: AgentService = Depends(get_agent_service),
    user_id: str = Depends(get_user_id)
):
    agents = agent_service.get_all_agents()
    return {"user_id": user_id, "agents": [agent.model_dump() for agent in agents]}

@router.post("/my-task-cancel")
async def cancel_my_task(
    agent_name: str,
    task_id: str,
    task_service: TaskService = Depends(get_task_service),
    user_id: str = Depends(get_user_id),
    session_id: str = Depends(ensure_session_id)
):
    await task_service.cancel_task(agent_name, task_id, session_id, user_id)
    return {"status": "cancelled"}
```

### 3. Working with SSE for Real-time Updates

```python
from fastapi import Depends
from fastapi.responses import StreamingResponse
from gateway.http_sse.dependencies import get_sse_manager
from gateway.http_sse.sse_manager import SSEManager
import asyncio
import json

@router.get("/stream/{task_id}")
async def stream_task_updates(
    task_id: str,
    sse_manager: SSEManager = Depends(get_sse_manager)
):
    async def event_generator():
        connection_queue = await sse_manager.create_sse_connection(task_id)
        try:
            while True:
                event = await connection_queue.get()
                if event is None:  # Close signal
                    break
                yield f"event: {event['event']}\ndata: {event['data']}\n\n"
        finally:
            await sse_manager.remove_sse_connection(task_id, connection_queue)
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
    )
```

### 4. Publishing A2A Messages

```python
from gateway.http_sse.dependencies import get_publish_a2a_func, PublishFunc

@router.post("/send-message")
async def send_a2a_message(
    topic: str,
    message: dict,
    publish_func: PublishFunc = Depends(get_publish_a2a_func)
):
    user_properties = {"source": "webui", "timestamp": "2024-01-01T00:00:00Z"}
    publish_func(topic, message, user_properties)
    return {"status": "sent", "topic": topic}
```

### 5. Working with Sessions and User Context

```python
from gateway.http_sse.dependencies import (
    get_session_manager,
    get_user_config,
    get_app_config
)
from gateway.http_sse.session_manager import SessionManager

@router.post("/new-session")
async def create_new_session(
    request: Request,
    session_manager: SessionManager = Depends(get_session_manager)
):
    new_session_id = session_manager.start_new_a2a_session(request)
    client_id = session_manager.get_a2a_client_id(request)
    return {
        "session_id": new_session_id,
        "client_id": client_id
    }

@router.get("/user-config")
async def get_my_config(
    user_config: dict = Depends(get_user_config),
    app_config: dict = Depends(get_app_config)

# content_hash: 119cd18acc7c3e2a62453c45e31b1249548a44dceed18fbd045b7498e9491fc3

================================================================================

## Section 22: gateway/http_sse/routers/routers_llm.txt

**Source file:** `gateway/http_sse/routers/routers_llm.txt`

# DEVELOPER GUIDE: routers

## Quick Summary
The `routers` directory contains FastAPI `APIRouter` modules that define the REST API endpoints for the HTTP SSE Gateway. Each file groups endpoints by a specific domain of functionality, such as agent discovery, artifact management, user authentication, task submission, and real-time event streaming. These routers are the primary interface for frontend applications and other clients to interact with the gateway.

## Files Overview
- `__init__.py` - Marks the directory as a Python package
- `agents.py` - API endpoints for discovering available A2A agents
- `artifacts.py` - REST endpoints for managing session-specific artifacts (upload, download, list, delete)
- `auth.py` - Endpoints for handling the user authentication flow (login, callback, refresh, CSRF)
- `config.py` - API endpoint for providing configuration settings to the frontend application
- `people.py` - API endpoints for user search functionality, typically for autocomplete features
- `sessions.py` - API endpoints for managing user sessions (creating new sessions, getting current session info)
- `sse.py` - The Server-Sent Events (SSE) endpoint for streaming real-time task updates to the client
- `tasks.py` - API endpoints for submitting tasks to agents and managing their lifecycle (e.g., cancellation)
- `users.py` - API endpoint for retrieving information about the currently authenticated user
- `visualization.py` - API endpoints for managing A2A message visualization streams for monitoring and debugging

## Developer API Reference

### agents.py
**Purpose:** Provides REST endpoints for agent discovery
**Import:** `from gateway.http_sse.routers.agents import router`

**Functions:**
- `get_discovered_agents() -> List[AgentCard]` - Retrieves a list of all currently discovered and available A2A agents

**Usage Examples:**
```python
# To include this router in a FastAPI application
from fastapi import FastAPI
from gateway.http_sse.routers.agents import router

app = FastAPI()
app.include_router(router, prefix="/api/v1")

# Client would make GET request to /api/v1/agents
```

### artifacts.py
**Purpose:** Manages session-specific artifacts via REST endpoints
**Import:** `from gateway.http_sse.routers.artifacts import router`

**Functions:**
- `list_artifact_versions(filename: str) -> List[int]` - Lists available version numbers for a specific artifact
- `list_artifacts() -> List[ArtifactInfo]` - Retrieves detailed information for all artifacts in current session
- `get_latest_artifact(filename: str) -> StreamingResponse` - Downloads the latest version of an artifact
- `get_specific_artifact_version(filename: str, version: Union[int, str]) -> StreamingResponse` - Downloads a specific version
- `get_artifact_by_uri(uri: str) -> StreamingResponse` - Resolves artifact:// URI and streams content
- `upload_artifact(filename: str, upload_file: UploadFile, metadata_json: Optional[str]) -> Dict[str, Any]` - Uploads new artifact version
- `delete_artifact(filename: str) -> Response` - Deletes an artifact and all its versions

**Usage Examples:**
```python
# Upload an artifact
import httpx

async with httpx.AsyncClient() as client:
    with open("document.pdf", "rb") as f:
        response = await client.post(
            "/api/v1/artifacts/document.pdf",
            files={"upload_file": f},
            data={"metadata_json": '{"description": "Important document"}'}
        )

# Download latest version
response = await client.get("/api/v1/artifacts/document.pdf")
```

### auth.py
**Purpose:** Handles user authentication flow
**Import:** `from gateway.http_sse.routers.auth import router`

**Functions:**
- `initiate_login() -> RedirectResponse` - Initiates login flow by redirecting to external auth service
- `get_csrf_token() -> Dict[str, str]` - Generates and returns CSRF token
- `auth_callback(code: str) -> RedirectResponse` - Handles callback from OIDC provider
- `refresh_token(refresh_token: str) -> Dict[str, str]` - Refreshes access token

**Usage Examples:**
```python
# Get CSRF token
response = await client.get("/api/v1/csrf-token")
csrf_token = response.json()["csrf_token"]

# Refresh token
response = await client.post(
    "/api/v1/auth/refresh",
    json={"refresh_token": "your_refresh_token"}
)
```

### config.py
**Purpose:** Provides frontend configuration settings
**Import:** `from gateway.http_sse.routers.config import router`

**Functions:**
- `get_app_config() -> Dict[str, Any]` - Returns configuration settings needed by frontend

**Usage Examples:**
```python
# Get frontend configuration
response = await client.get("/api/v1/config")
config = response.json()
# Returns: frontend_server_url, frontend_auth_login_url, etc.
```

### people.py
**Purpose:** User search functionality for autocomplete
**Import:** `from gateway.http_sse.routers.people import router`

**Functions:**
- `search_people(q: str, limit: int = 10) -> List[Dict[str, Any]]` - Searches for users by name/email

**Usage Examples:**
```python
# Search for users
response = await client.get("/api/v1/people/search?q=john&limit=5")
users = response.json()
```

### sessions.py
**Purpose:** Manages user sessions
**Import:** `from gateway.http_sse.routers.sessions import router`

**Functions:**
- `create_new_session() -> JSONRPCResponse` - Forces creation of new A2A session
- `get_current_session() -> JSONRPCResponse` - Returns current session information

**Usage Examples:**
```python
# Create new session
response = await client.post("/api/v1/sessions/new")
session_id = response.json()["result"]["sessionId"]

# Get current session info
response = await client.get("/api/v1/sessions/current")
session_info = response.json()["result"]
```

### sse.py
**Purpose:** Server-Sent Events for real-time updates
**Import:** `from gateway.http_sse.routers.sse import router`

**Functions:**
- `subscribe_to_task_events(task_id: str) -> EventSourceResponse` - Establishes SSE connection for task updates

**Usage Examples:**
```python
# JavaScript client-side SSE connection
const eventSource = new EventSource(`/api/v1/sse/subscribe/${taskId}`);
eventSource.onmessage = function(event) {
    const data = JSON.parse(event.data);
    console.log('Task update:', data);
};
```

### tasks.py
**Purpose:** Task submission and management
**Import:** `from gateway.http_sse.routers.tasks import router`

**Classes:**
- `CancelTaskApiPayload(BaseModel)` - Request body for task cancellation
  - `agent_name: str` - Name of agent handling the task
  - `task_id: str` - ID of task to cancel

**Functions:**
- `send_task_to_agent(agent_name: str, message: str, files: List[UploadFile]) -> JSONRPCResponse` - Submits non-streaming task
- `subscribe_task_from_agent(agent_name: str, message: str, files: List[UploadFile]) -> JSONRPCResponse` - Submits streaming task
- `cancel_agent_task(payload: CancelTaskApiPayload) -> Dict[str, str]` - Cancels a task

**Usage Examples:**
```python
# Submit a task
response = await client.post(
    "/api/v1/tasks/send",
    data={"agent_name": "my-agent", "message": "Hello"},
    files=[("files", ("doc.txt", b"content", "text/plain"))]
)
task_id = response.json()["result"]["taskId"]

# Cancel a task
from gateway.http_sse.routers.tasks import CancelTaskApiPayload
cancel_payload = CancelTaskApiPayload(agent_name="my-agent", task_id=task_id)
await client.post("/api/v1/tasks/cancel", json=cancel_payload.model_dump())
```

### users.py
**Purpose:** User information endpoints
**Import:** `from gateway.http_sse.routers.users import router`

**Functions:**
- `get_current_user() -> Dict[str, Any]` - Retrieves information about currently authenticated user

**Usage Examples:**
```python
# Get current user info
response = await client.get("/api/v1/users/me")
user_info = response.json()
# Returns: username, authenticated, auth_method
```

### visualization.py
**Purpose:** A2A message visualization streams for monitoring
**Import:** `from gateway.http_sse.routers.visualization import router`

**Classes:**
- `SubscriptionTarget(BaseModel)` - Defines a target for A2A message monitoring
  - `type: str` - Type of target (e.g., "my_a2a_messages", "agent_a2a_messages")
  - `identifier: Optional[str]` - Target identifier (namespace, agent name, etc.)

- `VisualizationSubscribeRequest(BaseModel)` - Request to initiate visualization stream
  - `subscription_targets: Optional[List[SubscriptionTarget]]` - Targets to monitor
  - `client_stream_id: Optional[str]` - Client-generated stream ID

- `VisualizationSubscribeResponse(BaseModel)` - Response for successful subscription
  - `stream_id: str` - Unique stream ID
  - `sse_endpoint_url: str` - URL for SSE connection
  - `actual_subscribed_targets: List[ActualSubscribedTarget]` - Processed targets with status

**Functions:**
- `subscribe_to_visualization_stream(request_data: VisualizationSubscribeRequest) -> VisualizationSubscribeResponse` - Initiates visualization stream
- `get_visualization_stream_events(stream_id: str) -> EventSourceResponse` - SSE endpoint for visualization events
- `update_visualization_stream_config(stream_id: str, update_request: VisualizationConfigUpdateRequest) -> VisualizationConfigUpdateResponse` - Updates stream configuration
- `unsubscribe_from_visualization_stream(stream_id: str) -> Response` - Terminates visualization stream

**Usage Examples:**
```python
# Subscribe to visualization stream
from gateway.http_sse.routers.visualization import VisualizationSubscribeRequest, SubscriptionTarget

request = VisualizationSubscribeRequest(
    subscription_targets=[
        SubscriptionTarget(type="agent_a2a_messages", identifier="my-agent")
    ]
)
response = await client.post("/api/v1/visualization/subscribe", json=request.model_dump())
stream_info = response.json()

# Connect to SSE stream (JavaScript)
const eventSource = new EventSource(stream_info.sse_endpoint_url);
eventSource.onmessage = function(event) {
    const message = JSON.parse(event.data);
    console.log('A2A Message:', message);
};
```

# content_hash: c4effd7ba68b4a50be27f9508159f1b818ff68e04e1973b7eab7f7a7b3392fe3

================================================================================

## Section 23: gateway/http_sse/services/services_llm.txt

**Source file:** `gateway/http_sse/services/services_llm.txt`

# DEVELOPER GUIDE: services

## Quick Summary
The `services` directory contains the business logic layer for the HTTP SSE Gateway. It provides high-level services that abstract interactions with agent registries, identity providers, and A2A (Agent-to-Agent) messaging protocols. These services handle agent discovery, user searches, and task management operations.

## Files Overview
- `__init__.py` - Package initialization file marking the directory as a Python package
- `agent_service.py` - Service for retrieving information about discovered A2A agents
- `people_service.py` - Service for searching users via configured identity services  
- `task_service.py` - Service for handling A2A task operations like cancellation

## Developer API Reference

### __init__.py
**Purpose:** Marks the directory as a Python package
**Import:** N/A - No public interfaces

---

### agent_service.py
**Purpose:** Provides methods for accessing information about discovered A2A agents from the AgentRegistry
**Import:** `from gateway.http_sse.services.agent_service import AgentService`

**Classes:**
- `AgentService(agent_registry: AgentRegistry)` - Service for accessing agent information
  - `get_all_agents() -> List[AgentCard]` - Retrieves all currently discovered and registered agent cards
  - `get_agent_by_name(agent_name: str) -> Optional[AgentCard]` - Retrieves a specific agent card by name

**Usage Examples:**
```python
from gateway.http_sse.services.agent_service import AgentService
from common.agent_registry import AgentRegistry

# Initialize with agent registry
agent_registry = AgentRegistry()
agent_service = AgentService(agent_registry=agent_registry)

# Get all agents
all_agents = agent_service.get_all_agents()
print(f"Found {len(all_agents)} agents")

# Get specific agent
agent = agent_service.get_agent_by_name("my-agent")
if agent:
    print(f"Found agent: {agent.name}")
```

---

### people_service.py
**Purpose:** Provides user search functionality via configured identity services
**Import:** `from gateway.http_sse.services.people_service import PeopleService`

**Classes:**
- `PeopleService(identity_service: Optional[BaseIdentityService])` - Service for searching and retrieving user information
  - `search_for_users(query: str, limit: int = 10) -> List[Dict[str, Any]]` - Searches for users via the identity service (async)

**Usage Examples:**
```python
import asyncio
from gateway.http_sse.services.people_service import PeopleService
from common.services.identity_service import BaseIdentityService

# Initialize with identity service
identity_service = MyIdentityService()
people_service = PeopleService(identity_service=identity_service)

# Search for users
async def search_users():
    users = await people_service.search_for_users("john", limit=5)
    print(f"Found {len(users)} users")
    return users

# Run the search
asyncio.run(search_users())
```

---

### task_service.py
**Purpose:** Handles A2A task operations like cancellation using CoreA2AService and message publishing
**Import:** `from gateway.http_sse.services.task_service import TaskService, PublishFunc`

**Type Aliases:**
- `PublishFunc: Callable[[str, Dict, Optional[Dict]], None]` - Function type for publishing messages (topic, payload, user_properties)

**Classes:**
- `TaskService(core_a2a_service: CoreA2AService, publish_func: PublishFunc, namespace: str, gateway_id: str, sse_manager: SSEManager, task_context_map: Dict[str, Dict], task_context_lock: threading.Lock, app_name: str)` - Service for managing A2A task operations
  - `cancel_task(agent_name: str, task_id: str, client_id: str, user_id: str = "web_user") -> None` - Cancels a task by publishing A2A CancelTaskRequest (async)

**Usage Examples:**
```python
import asyncio
import threading
from gateway.http_sse.services.task_service import TaskService, PublishFunc
from core_a2a.service import CoreA2AService
from gateway.http_sse.sse_manager import SSEManager

# Define publish function
def my_publish_func(topic: str, payload: dict, user_properties: dict = None):
    print(f"Publishing to {topic}: {payload}")

# Initialize dependencies
core_a2a_service = CoreA2AService()
sse_manager = SSEManager()
task_context_map = {}
task_context_lock = threading.Lock()

# Create task service
task_service = TaskService(
    core_a2a_service=core_a2a_service,
    publish_func=my_publish_func,
    namespace="my-namespace",
    gateway_id="gateway-01",
    sse_manager=sse_manager,
    task_context_map=task_context_map,
    task_context_lock=task_context_lock,
    app_name="my-app"
)

# Cancel a task
async def cancel_task():
    await task_service.cancel_task(
        agent_name="data-processor",
        task_id="task-123",
        client_id="client-456",
        user_id="user-789"
    )

asyncio.run(cancel_task())
```

# content_hash: 7048bb1eb5d3d1217ddd189c1bd423e5eb1f938a2349871dd34bd75200a72264

================================================================================

## Section 24: llm.txt

**Source file:** `llm.txt`

# DEVELOPER GUIDE: src

## Quick Summary
The `src` directory serves as the main source code root for the Solace AI Connector, containing four primary subsystems that work together to enable comprehensive AI agent communication and hosting. The `agent` directory provides a complete framework for hosting Google ADK agents with A2A protocol support, the `common` directory offers foundational A2A protocol infrastructure and utilities, the `core_a2a` directory provides a reusable service layer for core A2A operations, and the `gateway` directory implements various gateway patterns for external platform integration. These components work together to create a distributed AI agent ecosystem with real-time communication, task delegation, and multi-platform integration capabilities.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Empty package initialization file.
- **Subdirectories:**
  - `agent/`: Complete ADK agent hosting framework with A2A protocol integration and comprehensive tool library.
  - `common/`: Foundational A2A protocol infrastructure, type systems, and client/server implementations.
  - `core_a2a/`: Reusable service layer for core A2A interactions and agent registry operations.
  - `gateway/`: Gateway framework with HTTP/SSE, Slack, and Webhook implementations for external platform integration.

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Standard Python package initializer. It allows the `src` directory and its subdirectories to be treated as a package.
**Import:** `from src import agent, common, gateway`

**Classes/Functions/Constants:**
This file is empty and has no public interfaces.

### Subdirectory APIs

#### agent/
**Purpose:** Provides a complete framework for hosting Google ADK agents with A2A protocol support and a comprehensive, extensible tool library.
**Key Exports:** `SamAgentApp`, `SamAgentComponent`, `AppLlmAgent`, and a wide array of built-in tools for data analysis, web requests, multimedia processing, and inter-agent communication.
**Import Examples:**
```python
from src.agent.sac.app import SamAgentApp
from src.agent.sac.component import SamAgentComponent
from src.agent.adk.app_llm_agent import AppLlmAgent
from src.agent.tools.builtin_data_analysis_tools import query_data_with_sql
from src.agent.tools.peer_agent_tool import PeerAgentTool
from src.agent.tools.web_tools import web_request
from src.agent.tools.image_tools import create_image_from_description
```

#### common/
**Purpose:** Provides the foundational infrastructure for Agent-to-Agent (A2A) communication, including the core protocol, data types, message translation, and client/server implementations.
**Key Exports:** A2A protocol functions, Pydantic type definitions (`Message`, `Task`, `AgentCard`), `A2AClient` for interacting with agents, `A2AServer` for building agents, and various utilities.
**Import Examples:**
```python
from src.common.a2a_protocol import get_agent_request_topic
from src.common.types import Message, Task, AgentCard, TextPart
from src.common.client import A2AClient, A2ACardResolver
from src.common.server import A2AServer, InMemoryTaskManager
from src.common.agent_registry import AgentRegistry
from src.common.utils.embeds import resolve_embeds_in_string
```

#### core_a2a/
**Purpose:** Provides a reusable, decoupled service layer for core A2A interactions, handling task submission, cancellation, and agent discovery.
**Key Exports:** `CoreA2AService` for managing A2A protocol logic without being tied to a specific gateway or messaging implementation.
**Import Examples:**
```python
from src.core_a2a.service import CoreA2AService
```

#### gateway/
**Purpose:** Provides a framework and multiple implementations for building gateways that bridge external platforms (like web UIs, Slack, or webhooks) with the A2A messaging system.
**Key Exports:** `BaseGatewayApp` and `BaseGatewayComponent` for creating custom gateways, and concrete implementations like `WebUIBackendApp`, `SlackGatewayApp`, and `WebhookGatewayApp`.
**Import Examples:**
```python
from src.gateway.base.app import BaseGatewayApp
from src.gateway.http_sse.app import WebUIBackendApp
from src.gateway.slack.app import SlackGatewayApp
from src.gateway.webhook.app import WebhookGatewayApp
from src.gateway.base.authorization_service import ConfigurableRbacAuthorizationService
```

## Complete Usage Guide
This guide demonstrates how the different subdirectories within `src` work together to build a complete, distributed AI agent system.

### 1. How to import and use functionality from subdirectories
The following examples show how to import and instantiate components from each major subdirectory.

```python
# 1. Import from the 'agent' directory to create an AI agent
from src.agent.sac.app import SamAgentApp

# 2. Import from the 'common' and 'core_a2a' directories for protocol infrastructure
from src.common.agent_registry import AgentRegistry
from src.common.types import AgentCard, AgentCapabilities, AgentSkill
from src.core_a2a.service import CoreA2AService

# 3. Import from the 'gateway' directory to create interfaces
from src.gateway.http_sse.app import WebUIBackendApp
from src.gateway.slack.app import SlackGatewayApp
from src.gateway.webhook.app import WebhookGatewayApp

# 4. Import tools from the 'agent/tools' subdirectory
from src.agent.tools.peer_agent_tool import PeerAgentTool
from src.agent.tools.builtin_data_analysis_tools import query_data_with_sql
```

### 2. How different parts work together
This section shows a step-by-step process for building a system, illustrating the synergy between the components.

#### Step 1: Create an ADK-powered agent (`agent/`)
First, define and configure an agent. This agent will automatically be equipped with a rich set of tools and A2A communication capabilities.

```python
# File: my_system.py
from src.agent.sac.app import SamAgentApp

# Configure the agent with all capabilities
agent_config = {
    "name": "data-analyst-agent",
    "app_config": {
        "namespace": "myorg/ai-agents",
        "agent_name": "data_analyst",
        "model": "gemini-1.5-pro",
        "instruction": "You are a data analysis expert with access to SQL, charting, web tools, and peer collaboration.",
        "agent_card": {
            "description": "AI agent for comprehensive data analysis and reporting",
            "capabilities": ["data_analysis", "web_research", "chart_generation", "peer_collaboration"]
        },
        "agent_card_publishing": {"interval_seconds": 30},
        "agent_discovery": {"enabled": True},
        "inter_agent_communication": {"allow_list": ["*"]}
    }
}

# Create the agent app (in a real scenario, this is run by the SAC framework)
agent_app = SamAgentApp(agent_config)
```

#### Step 2: Set Up A2A Protocol Infrastructure (`common/` and `core_a2a/`)
Next, set up the core services that manage agent discovery and task routing. This is often handled by the gateway components but can be used directly.

```python
# File: my_system.py (continued)
from src.common.agent_registry import AgentRegistry
from src.common.types import AgentCard, AgentCapabilities, AgentSkill
from src.core_a2a.service import CoreA2AService

# Initialize a shared agent registry
agent_registry = AgentRegistry()

# Create the core A2A service, which uses the registry
namespace = "myorg/ai-agents"
a2a_service = CoreA2AService(agent_registry, namespace)

# Manually register an agent's capabilities (this is usually done automatically by the agent itself)
data_analyst_card = AgentCard(
    name="data_analyst",
    display_name="Data Analyst",
    description="AI agent for data analysis",
    url=f"a2a://{namespace}/data_analyst",
    version="1.0.0",
    capabilities=AgentCapabilities(streaming=True, pushNotifications=True),
    skills=[AgentSkill(id="sql_analysis", name="SQL Data Analysis")]
)
a2a_service.process_discovery_message(data_analyst_card)
```

#### Step 3: Create Gateway Integrations (`gateway/`)
Create one or more gateways to expose the agent(s) to external platforms.

```python
# File: my_system.py (continued)
from src.gateway.http_sse.app import WebUIBackendApp
from src.gateway.slack.app import SlackGatewayApp

# Web UI Gateway for browser-based interactions
webui_config = {
    "name": "web-gateway",
    "app_config": {
        "namespace": "myorg/ai-agents",
        "gateway_id": "web-ui-gateway",
        "session_secret_key": "a-very-secret-key",
        "fastapi_host": "0.0.0.0",
        "fastapi_port": 8080,
        "artifact_service": {"type": "local_file", "base_path": "./artifacts"}
    }
}
webui_app = WebUIBackendApp(webui_config)

# Slack Gateway for team collaboration
slack_config = {
    "name": "slack-gateway",
    "app_config": {
        "namespace": "myorg/ai-agents",
        "gateway_id": "slack-gateway",
        "slack_bot_token": "${SLACK_BOT_TOKEN}",
        "slack_app_token": "${SLACK_APP_TOKEN}",
        "default_agent_name": "data_analyst"
    }
}
slack_app = SlackGatewayApp(slack_config)
```

### 3. Common usage patterns

#### Pattern 1: Inter-Agent Communication
An agent can use the `PeerAgentTool` (from `agent/tools/`) to delegate tasks to other agents, leveraging the `common/` protocol infrastructure.

```python
# This code would run within an agent's tool execution context.
from src.agent.tools.peer_agent_tool import PeerAgentTool

async def analyze_and_delegate_report(component, tool_context):
    # Assume 'component' is the SamAgentComponent instance hosting the current agent.
    
    # Step 1: Perform local analysis (using another tool)
    # ... analysis_result = await query_data_with_sql(...) ...

    # Step 2: Delegate report generation to a specialist agent
    peer_tool = PeerAgentTool(
        target_agent_name="report_generator",
        host_component=component
    )
    
    report_result = await peer_tool.run_async(
        args={
            "task_description": "Generate a professional PDF report from this analysis",
            "analysis_data": "artifact://analysis_result.json",
            "report_format": "PDF"
        },
        tool_context=tool_context
    )
    
    return report_result
```

#### Pattern 2: Building a Custom Gateway
Create a custom gateway to integrate with a new platform.

```python
# File: my_custom_gateway/app.py
from src.gateway.base.app import BaseGatewayApp
from .component import MyCustomGatewayComponent

class MyCustomGatewayApp(BaseGatewayApp):
    SPECIFIC_APP_SCHEMA_PARAMS = [
        {
            "name": "my_platform_api_key",
            "required": True,
            "type": "string",
            "description": "API key for My Platform"
        }
    ]

    def _get_gateway_component_class(self):
        return MyCustomGatewayComponent

# File: my_custom_gateway/component.py
from src.gateway.base.component import BaseGatewayComponent
from src.common.types import TextPart

class MyCustomGatewayComponent(BaseGatewayComponent):
    
    def _extract_initial_claims(self, external_event_data):
        # Extract user identity from platform event
        user_id = external_event_data.get("user_id")
        return {"id": user_id} if user_id else None
    
    def _translate_external_input(self, external_event):
        # Convert platform input to A2A format
        agent_name = external_event.get("target_agent", "default-agent")
        message_text = external_event.get("message", "")
        a2a_parts = [TextPart(text=message_text)]
        context = {"platform_user_id": external_event.get("user_id")}
        return agent_name, a2a_parts, context
    
    # ... implement other abstract methods
```

#### Pattern 3: Using the Client Library
Interact with remote agents using the client library.

```python
import asyncio
from src.common.client import A2AClient, A2ACardResolver

async def interact_with_remote_agent():
    # Discover agent capabilities
    resolver = A2ACardResolver(base_url="https://remote-agent.example.com")
    agent_card = resolver.get_agent_card()
    
    # Create client
    client = A2AClient(agent_card=agent_card)
    
    # Send a task
    task_payload = {
        "action": "analyze_data",
        "data": "sales_data.csv",
        "analysis_type": "trend_analysis"
    }
    
    # For streaming responses
    async for chunk in client.send_task_streaming(payload=task_payload):
        print(f"Received update: {chunk.result.content_chunk}")
    
    # For non-streaming responses
    response = await client.send_task(payload=task_payload)
    print(f"Task completed: {response.result.task_id}")

# Run the client example
asyncio.run(interact_with_remote_agent())
```

#### Pattern 4: Working with Artifacts and Tools
Use the comprehensive tool library for data processing and artifact management.

```python
from src.agent.tools.builtin_artifact_tools import list_artifacts, load_artifact, signal_artifact_for_return
from src.agent.tools.builtin_data_analysis_tools import query_data_with_sql
from src.agent.tools.image_tools import create_image_from_description
from src.agent.tools.audio_tools import text_to_speech

async def comprehensive_data_workflow(tool_context):
    # 1. List available data artifacts
    artifacts = await list_artifacts(tool_context=tool_context)
    print(f"Available artifacts: {artifacts}")
    
    # 2. Load and analyze data
    data_artifact = await load_artifact(
        filename="sales_data.csv",
        version=1,
        tool_context=tool_context
    )
    
    # 3. Query the data
    analysis_result = await query_data_with_sql(
        sql_query="SELECT region, SUM(sales) as total_sales FROM data GROUP BY region",
        data_source="sales_data.csv:1",
        tool_context=tool_context
    )
    
    # 4. Create visualization
    chart_result = await create_image_from_description(
        image_description="A bar chart showing total sales by region based on the analysis",
        output_filename="sales_by_region.png",
        tool_context=tool_context
    )
    
    # 5. Generate audio summary
    audio_result = await text_to_speech(
        text="The sales analysis shows strong performance in the North region with $2.5M in total sales.",
        output_filename="sales_summary.mp3",
        tool_context=tool_context
    )
    
    # 6. Signal final artifacts for return
    await signal_artifact_for_return(
        filename="sales_by_region.png",
        version=1,
        tool

# content_hash: e28ca9170a5b2a8fe61fe2cbb00a982e3f89d213d587ad0d2b548e44260cf72c

================================================================================


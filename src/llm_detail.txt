# LLM Summary Detail File

This file is a concatenation of all individual *llm.txt files found in the 'src' directory tree. Each section below corresponds to a specific directory's summary file.

================================================================================

## Section 1: llm.txt

**Source file:** `llm.txt`

# DEVELOPER GUIDE for the directory: src

## Quick Summary
The `src` directory serves as the main source code root for the Solace AI Connector, containing four primary subsystems that work together to enable comprehensive AI agent communication and hosting. The `agent` directory provides a complete framework for hosting Google ADK agents with A2A protocol support, the `common` directory offers foundational A2A protocol infrastructure and utilities, the `core_a2a` directory provides a reusable service layer for core A2A operations, and the `gateway` directory implements various gateway patterns for external platform integration. These components work together to create a distributed AI agent ecosystem with real-time communication, task delegation, and multi-platform integration capabilities.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Empty package initialization file.
- **Subdirectories:**
  - `agent/`: Complete ADK agent hosting framework with A2A protocol integration and comprehensive tool library.
  - `common/`: Foundational A2A protocol infrastructure, type systems, and client/server implementations.
  - `core_a2a/`: Reusable service layer for core A2A interactions and agent registry operations.
  - `gateway/`: Gateway framework with HTTP/SSE, Slack, and Webhook implementations for external platform integration.

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Standard Python package initializer. It allows the `src` directory and its subdirectories to be treated as a package.
**Import:** `from src import agent, common, gateway`

**Classes/Functions/Constants:**
This file is empty and has no public interfaces.

### Subdirectory APIs

#### agent/
**Purpose:** Provides a complete framework for hosting Google ADK agents with A2A protocol support and a comprehensive, extensible tool library.
**Key Exports:** `SamAgentApp`, `SamAgentComponent`, `AppLlmAgent`, and a wide array of built-in tools for data analysis, web requests, multimedia processing, and inter-agent communication.
**Import Examples:**
```python
from src.agent.sac.app import SamAgentApp
from src.agent.sac.component import SamAgentComponent
from src.agent.adk.app_llm_agent import AppLlmAgent
from src.agent.tools.builtin_data_analysis_tools import query_data_with_sql
from src.agent.tools.peer_agent_tool import PeerAgentTool
from src.agent.tools.web_tools import web_request
from src.agent.tools.image_tools import create_image_from_description
```

#### common/
**Purpose:** Provides the foundational infrastructure for Agent-to-Agent (A2A) communication, including the core protocol, data types, message translation, and client/server implementations.
**Key Exports:** A2A protocol functions, Pydantic type definitions (`Message`, `Task`, `AgentCard`), `A2AClient` for interacting with agents, `A2AServer` for building agents, and various utilities.
**Import Examples:**
```python
from src.common.a2a_protocol import get_agent_request_topic
from src.common.types import Message, Task, AgentCard, TextPart
from src.common.client import A2AClient, A2ACardResolver
from src.common.server import A2AServer, InMemoryTaskManager
from src.common.agent_registry import AgentRegistry
from src.common.utils.embeds import resolve_embeds_in_string
```

#### core_a2a/
**Purpose:** Provides a reusable, decoupled service layer for core A2A interactions, handling task submission, cancellation, and agent discovery.
**Key Exports:** `CoreA2AService` for managing A2A protocol logic without being tied to a specific gateway or messaging implementation.
**Import Examples:**
```python
from src.core_a2a.service import CoreA2AService
```

#### gateway/
**Purpose:** Provides a framework and multiple implementations for building gateways that bridge external platforms (like web UIs, Slack, or webhooks) with the A2A messaging system.
**Key Exports:** `BaseGatewayApp` and `BaseGatewayComponent` for creating custom gateways, and concrete implementations like `WebUIBackendApp`, `SlackGatewayApp`, and `WebhookGatewayApp`.
**Import Examples:**
```python
from src.gateway.base.app import BaseGatewayApp
from src.gateway.http_sse.app import WebUIBackendApp
from src.gateway.slack.app import SlackGatewayApp
from src.gateway.webhook.app import WebhookGatewayApp
from src.gateway.base.authorization_service import ConfigurableRbacAuthorizationService
```

## Complete Usage Guide
This guide demonstrates how the different subdirectories within `src` work together to build a complete, distributed AI agent system.

### 1. How to import and use functionality from subdirectories
The following examples show how to import and instantiate components from each major subdirectory.

```python
# 1. Import from the 'agent' directory to create an AI agent
from src.agent.sac.app import SamAgentApp

# 2. Import from the 'common' and 'core_a2a' directories for protocol infrastructure
from src.common.agent_registry import AgentRegistry
from src.common.types import AgentCard, AgentCapabilities, AgentSkill
from src.core_a2a.service import CoreA2AService

# 3. Import from the 'gateway' directory to create interfaces
from src.gateway.http_sse.app import WebUIBackendApp
from src.gateway.slack.app import SlackGatewayApp
from src.gateway.webhook.app import WebhookGatewayApp

# 4. Import tools from the 'agent/tools' subdirectory
from src.agent.tools.peer_agent_tool import PeerAgentTool
from src.agent.tools.builtin_data_analysis_tools import query_data_with_sql
```

### 2. How different parts work together
This section shows a step-by-step process for building a system, illustrating the synergy between the components.

#### Step 1: Create an ADK-powered agent (`agent/`)
First, define and configure an agent. This agent will automatically be equipped with a rich set of tools and A2A communication capabilities.

```python
# File: my_system.py
from src.agent.sac.app import SamAgentApp

# Configure the agent with all capabilities
agent_config = {
    "name": "data-analyst-agent",
    "app_config": {
        "namespace": "myorg/ai-agents",
        "agent_name": "data_analyst",
        "model": "gemini-1.5-pro",
        "instruction": "You are a data analysis expert with access to SQL, charting, web tools, and peer collaboration.",
        "agent_card": {
            "description": "AI agent for comprehensive data analysis and reporting",
            "capabilities": ["data_analysis", "web_research", "chart_generation", "peer_collaboration"]
        },
        "agent_card_publishing": {"interval_seconds": 30},
        "agent_discovery": {"enabled": True},
        "inter_agent_communication": {"allow_list": ["*"]}
    }
}

# Create the agent app (in a real scenario, this is run by the SAC framework)
agent_app = SamAgentApp(agent_config)
```

#### Step 2: Set Up A2A Protocol Infrastructure (`common/` and `core_a2a/`)
Next, set up the core services that manage agent discovery and task routing. This is often handled by the gateway components but can be used directly.

```python
# File: my_system.py (continued)
from src.common.agent_registry import AgentRegistry
from src.common.types import AgentCard, AgentCapabilities, AgentSkill
from src.core_a2a.service import CoreA2AService

# Initialize a shared agent registry
agent_registry = AgentRegistry()

# Create the core A2A service, which uses the registry
namespace = "myorg/ai-agents"
a2a_service = CoreA2AService(agent_registry, namespace)

# Manually register an agent's capabilities (this is usually done automatically by the agent itself)
data_analyst_card = AgentCard(
    name="data_analyst",
    display_name="Data Analyst",
    description="AI agent for data analysis",
    url=f"a2a://{namespace}/data_analyst",
    version="1.0.0",
    capabilities=AgentCapabilities(streaming=True, pushNotifications=True),
    skills=[AgentSkill(id="sql_analysis", name="SQL Data Analysis")]
)
a2a_service.process_discovery_message(data_analyst_card)
```

#### Step 3: Create Gateway Integrations (`gateway/`)
Create one or more gateways to expose the agent(s) to external platforms.

```python
# File: my_system.py (continued)
from src.gateway.http_sse.app import WebUIBackendApp
from src.gateway.slack.app import SlackGatewayApp

# Web UI Gateway for browser-based interactions
webui_config = {
    "name": "web-gateway",
    "app_config": {
        "namespace": "myorg/ai-agents",
        "gateway_id": "web-ui-gateway",
        "session_secret_key": "a-very-secret-key",
        "fastapi_host": "0.0.0.0",
        "fastapi_port": 8080,
        "artifact_service": {"type": "local_file", "base_path": "./artifacts"}
    }
}
webui_app = WebUIBackendApp(webui_config)

# Slack Gateway for team collaboration
slack_config = {
    "name": "slack-gateway",
    "app_config": {
        "namespace": "myorg/ai-agents",
        "gateway_id": "slack-gateway",
        "slack_bot_token": "${SLACK_BOT_TOKEN}",
        "slack_app_token": "${SLACK_APP_TOKEN}",
        "default_agent_name": "data_analyst"
    }
}
slack_app = SlackGatewayApp(slack_config)
```

### 3. Common usage patterns

#### Pattern 1: Inter-Agent Communication
An agent can use the `PeerAgentTool` (from `agent/tools/`) to delegate tasks to other agents, leveraging the `common/` protocol infrastructure.

```python
# This code would run within an agent's tool execution context.
from src.agent.tools.peer_agent_tool import PeerAgentTool

async def analyze_and_delegate_report(component, tool_context):
    # Assume 'component' is the SamAgentComponent instance hosting the current agent.
    
    # Step 1: Perform local analysis (using another tool)
    # ... analysis_result = await query_data_with_sql(...) ...

    # Step 2: Delegate report generation to a specialist agent
    peer_tool = PeerAgentTool(
        target_agent_name="report_generator",
        host_component=component
    )
    
    report_result = await peer_tool.run_async(
        args={
            "task_description": "Generate a professional PDF report from this analysis",
            "analysis_data": "artifact://analysis_result.json",
            "report_format": "PDF"
        },
        tool_context=tool_context
    )
    
    return report_result
```

#### Pattern 2: Building Custom Tools
Developers can extend the agent's capabilities by creating custom tools that integrate with the existing framework.

```python
from src.agent.tools.registry import tool_registry
from src.agent.tools.tool_definition import BuiltinTool
from google.adk.tools import ToolContext

async def custom_database_query(
    query: str,
    database_name: str = "default",
    tool_context: ToolContext = None,
    tool_config: dict = None
) -> dict:
    """Execute a custom database query with enhanced features."""
    
    # Access the host component for shared resources
    host_component = tool_context._invocation_context.agent.host_component
    
    # Get database connection from agent state
    db_connection = host_component.get_agent_specific_state('db_connection')
    
    # Execute query and save results as artifact
    try:
        result = await execute_query(db_connection, query, database_name)
        
        # Save results using the artifact helpers
        from src.agent.utils.artifact_helpers import save_artifact_with_metadata
        import json
        from datetime import datetime, timezone
        
        artifact_result = await save_artifact_with_metadata(
            artifact_service=host_component.get_shared_artifact_service(),
            app_name=host_component.get_config()["app_name"],
            user_id=tool_context.user_id,
            session_id=tool_context.session_id,
            filename=f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            content_bytes=json.dumps(result).encode(),
            mime_type="application/json",
            metadata_dict={
                "query": query,
                "database": database_name,
                "tool": "custom_database_query"
            },
            timestamp=datetime.now(timezone.utc)
        )
        
        return {
            "status": "success",
            "rows_returned": len(result),
            "artifact_filename": artifact_result["filename"]
        }
        
    except Exception as e:
        return {"status": "error", "error_message": str(e)}

# Register the custom tool
custom_tool = BuiltinTool(
    name="custom_database_query",
    description="Execute custom database queries with enhanced features",
    function=custom_database_query,
    category="data_analysis"
)
tool_registry.register(custom_tool)
```

#### Pattern 3: Client-Side Integration
External applications can interact with the agent system using the client library from the `common/` directory.

```python
import asyncio
from src.common.client import A2AClient, A2ACardResolver

async def client_integration_example():
    # Discover available agents
    resolver = A2ACardResolver("https://agents.myorg.com")
    agent_card = resolver.get_agent_card()
    
    # Create client for agent interaction
    client = A2AClient(agent_card=agent_card)
    
    # Submit a task with streaming response
    task_payload = {
        "action": "analyze_data",
        "data_file": "sales_report.csv",
        "analysis_type": "quarterly_trends"
    }
    
    print("Submitting task and streaming response...")
    async for response in client.send_task_streaming(task_payload):
        if hasattr(response.result, 'text_delta'):
            print(response.result.text_delta, end='', flush=True)
        elif hasattr(response.result, 'artifact'):
            print(f"\nArtifact created: {response.result.artifact.name}")

# Run the client example
# asyncio.run(client_integration_example())
```

#### Pattern 4: Multimedia Processing Workflow
The system supports rich multimedia processing through specialized tools.

```python
from src.agent.tools.audio_tools import text_to_speech, multi_speaker_text_to_speech
from src.agent.tools.image_tools import create_image_from_description

async def multimedia_workflow(tool_context):
    # Generate speech from text
    tts_result = await text_to_speech(
        text="Welcome to our AI-powered presentation system!",
        output_filename="intro.mp3",
        gender="female",
        tone="professional",
        language="en-US",
        tool_context=tool_context
    )
    
    # Create a multi-speaker dialogue
    conversation_result = await multi_speaker_text_to_speech(
        conversation_text="""
        Presenter: Today we'll discuss our quarterly results.
        Analyst: The data shows significant growth in Q4.
        Presenter: Let's dive into the details.
        """,
        speaker_configs=[
            {"name": "Presenter", "gender": "female", "tone": "professional"},
            {"name": "

================================================================================

## Section 2: solace_agent_mesh/agent/adk/adk_llm.txt

**Source file:** `solace_agent_mesh/agent/adk/adk_llm.txt`

# DEVELOPER GUIDE for adk directory

## Quick Summary
The `adk` directory serves as the core integration layer between the Solace AI Connector framework and Google's Agent Development Kit (ADK). It provides the essential components for building, configuring, and running sophisticated AI agents within a Solace messaging environment.

The architecture is designed for modularity and extensibility. The `setup.py` module acts as the main configuration hub, using factory functions from `services.py` to initialize pluggable services (like `FilesystemArtifactService` for artifact storage) and loading tools (Python functions, MCP tools) via the `ADKToolWrapper`.

Once initialized, the `AppLlmAgent` (a custom agent class) is managed by the `runner.py` module, which handles the asynchronous task execution loop. The agent's behavior is dynamically augmented at runtime by a rich set of callbacks from `callbacks.py`. These callbacks inject dynamic instructions, manage large tool responses, log events to Solace, and handle advanced features like streaming artifact creation and auto-continuation of conversations. The `models/` subdirectory provides the concrete LLM clients, with `LiteLlm` offering broad compatibility with various model providers.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Standard Python package initializer
  - `adk_llm.txt`: Documentation file containing developer guide content
  - `adk_llm_detail.txt`: Concatenated LLM summary file from all subdirectories
  - `app_llm_agent.py`: Defines a custom `LlmAgent` subclass that holds a reference to its host component
  - `callbacks.py`: Provides a rich set of ADK callback functions for dynamic instructions, metadata injection, and Solace integration
  - `embed_resolving_mcp_toolset.py`: Custom MCPToolset that resolves embeds in tool parameters before calling MCP tools
  - `filesystem_artifact_service.py`: A local filesystem-based implementation of ADK's `BaseArtifactService`
  - `intelligent_mcp_callbacks.py`: Intelligent MCP callback functions for processing and saving MCP tool responses as typed artifacts
  - `invocation_monitor.py`: A utility for monitoring and logging agent invocations to YAML files for debugging
  - `mcp_content_processor.py`: Intelligent processing of MCP tool responses, converting raw content into appropriately typed artifacts
  - `runner.py`: Manages the asynchronous execution of ADK agent tasks, including cancellation support
  - `services.py`: Contains factory functions for initializing ADK services (session, artifact, memory) based on configuration
  - `setup.py`: Handles the high-level initialization of the ADK agent, tools, and runner
  - `stream_parser.py`: An internal utility for parsing fenced artifact blocks from an LLM's streaming response
  - `tool_wrapper.py`: A wrapper for Python functions to make them compatible with ADK, handling embed resolution and config injection
- **Subdirectories:**
  - `artifacts/`: Contains filesystem and S3-compatible artifact storage implementations
  - `models/`: Contains concrete `BaseLlm` implementations for interfacing with various LLM providers

## Developer API Reference

### Direct Files

#### app_llm_agent.py
**Purpose:** A custom `LlmAgent` subclass that includes a reference to its hosting component, allowing callbacks and tools to access host-level configurations and services.
**Import:** `from solace_agent_mesh.agent.adk.app_llm_agent import AppLlmAgent`

**Classes/Functions/Constants:**
- `AppLlmAgent(host_component: Any = None, **kwargs)`: A custom `LlmAgent` that can be linked to a host component. The `host_component` is set post-initialization and is excluded from serialization.

#### callbacks.py
**Purpose:** Provides a suite of ADK callback functions that hook into the agent's lifecycle to inject custom logic. These are typically not called directly but are assigned to the agent during setup.
**Import:** `from solace_agent_mesh.agent.adk import callbacks`

**Classes/Functions/Constants:**
- `inject_dynamic_instructions_callback(...)`: Injects instructions into the prompt based on host configuration, active tools, and peer agents
- `manage_large_mcp_tool_responses_callback(...)`: Intercepts large tool responses, saves them as artifacts, and returns a truncated summary to the LLM
- `after_tool_callback_inject_metadata(...)`: After a tool creates an artifact, this loads its metadata and injects it into the tool response
- `process_artifact_blocks_callback(...)`: Processes streaming text to identify and save fenced artifact blocks (e.g., `«««save_artifact:...»»»`)
- `auto_continue_on_max_tokens_callback(...)`: Automatically continues a conversation if the LLM response was interrupted due to token limits
- `notify_tool_invocation_start_callback(...)`: Sends a status update over Solace when a tool is about to be invoked
- `solace_llm_invocation_callback(...)`: Sends a status update over Solace when the agent calls the LLM
- `repair_history_callback(...)`: Proactively checks for and repairs dangling tool calls in conversation history

#### embed_resolving_mcp_toolset.py
**Purpose:** Custom MCPToolset that resolves embeds in tool parameters before calling MCP tools, enabling dynamic content injection.
**Import:** `from solace_agent_mesh.agent.adk.embed_resolving_mcp_toolset import EmbedResolvingMCPToolset, EmbedResolvingMCPTool`

**Classes/Functions/Constants:**
- `EmbedResolvingMCPToolset(connection_params, tool_filter=None, auth_scheme=None, auth_credential=None, tool_config=None)`: Custom MCPToolset that creates EmbedResolvingMCPTool instances
- `EmbedResolvingMCPTool(original_mcp_tool, tool_config=None)`: Custom MCPTool that resolves embeds in parameters before calling the actual MCP tool

#### filesystem_artifact_service.py
**Purpose:** An implementation of `BaseArtifactService` that stores artifacts on the local filesystem, organized by scope, user, and session.
**Import:** `from solace_agent_mesh.agent.adk.filesystem_artifact_service import FilesystemArtifactService`

**Classes/Functions/Constants:**
- `FilesystemArtifactService(base_path: str)`: A service for managing artifacts on the local disk
  - `async save_artifact(...) -> int`: Saves an artifact and returns its version number
  - `async load_artifact(...) -> Optional[adk_types.Part]`: Loads a specific version of an artifact, or the latest if unspecified
  - `async list_artifact_keys(...) -> List[str]`: Lists the names of all artifacts for a given user/session
  - `async delete_artifact(...)`: Deletes an artifact and all its versions
  - `async list_versions(...) -> List[int]`: Lists all version numbers for a specific artifact

#### intelligent_mcp_callbacks.py
**Purpose:** Intelligent MCP callback functions that use intelligent content processing to save MCP tool responses as appropriately typed artifacts.
**Import:** `from solace_agent_mesh.agent.adk.intelligent_mcp_callbacks import save_mcp_response_as_artifact_intelligent, McpSaveResult, McpSaveStatus`

**Classes/Functions/Constants:**
- `save_mcp_response_as_artifact_intelligent(tool, tool_context, host_component, mcp_response_dict, original_tool_args) -> McpSaveResult`: Intelligently processes and saves MCP tool response content as typed artifacts
- `McpSaveStatus`: Enumeration for the status of an MCP save operation (SUCCESS, PARTIAL_SUCCESS, ERROR)
- `McpSaveResult`: The definitive result of an MCP response save operation with status, message, and artifact details

#### invocation_monitor.py
**Purpose:** A debugging utility that logs the entire lifecycle of an agent invocation, from the initial request to the final response, into a structured YAML file.
**Import:** `from solace_agent_mesh.agent.adk.invocation_monitor import InvocationMonitor`

**Classes/Functions/Constants:**
- `InvocationMonitor()`: A class that monitors and logs agent message flows
  - `log_message_event(direction: str, topic: str, payload: any, ...)`: Logs a single message event
  - `cleanup()`: Finalizes any active logging sessions

#### mcp_content_processor.py
**Purpose:** Intelligent processing of MCP tool responses, converting raw MCP content into appropriately typed and formatted artifacts based on the MCP specification content types.
**Import:** `from solace_agent_mesh.agent.adk.mcp_content_processor import MCPContentProcessor, MCPContentItem, MCPContentProcessorConfig`

**Classes/Functions/Constants:**
- `MCPContentProcessor(tool_name: str, tool_args: Dict[str, Any])`: Main processor for MCP tool response content
  - `process_mcp_response(mcp_response_dict) -> List[MCPContentItem]`: Process an MCP tool response and extract content items
- `MCPContentItem`: Represents a processed MCP content item with metadata
- `MCPContentProcessorConfig`: Configuration for MCP content processing

#### runner.py
**Purpose:** Provides the core asynchronous task execution logic for the ADK agent, including robust cancellation handling.
**Import:** `from solace_agent_mesh.agent.adk.runner import run_adk_async_task_thread_wrapper, TaskCancelledError`

**Classes/Functions/Constants:**
- `run_adk_async_task_thread_wrapper(component, adk_session, adk_content, ...)`: A high-level wrapper that runs an ADK task in a separate thread and handles all cleanup and error finalization
- `run_adk_async_task(component, task_context, adk_session, adk_content, run_config, a2a_context) -> bool`: Runs the ADK Runner asynchronously and processes intermediate events
- `TaskCancelledError(Exception)`: Custom exception raised when an agent task is cancelled externally

#### services.py
**Purpose:** Provides factory functions to initialize the various ADK services based on the agent's configuration file.
**Import:** `from solace_agent_mesh.agent.adk.services import initialize_session_service, initialize_artifact_service, initialize_memory_service, ScopedArtifactServiceWrapper`

**Classes/Functions/Constants:**
- `initialize_session_service(component) -> BaseSessionService`: Creates a session service (e.g., `InMemorySessionService`)
- `initialize_artifact_service(component) -> BaseArtifactService`: Creates an artifact service (e.g., `FilesystemArtifactService`, `GcsArtifactService`)
- `initialize_memory_service(component) -> BaseMemoryService`: Creates a memory service (e.g., `InMemoryMemoryService`)
- `ScopedArtifactServiceWrapper`: A wrapper that transparently applies configured scope to artifact operations

#### setup.py
**Purpose:** The main entry point for configuring and instantiating the ADK agent and its dependencies. These functions tie all the other modules together.
**Import:** `from solace_agent_mesh.agent.adk.setup import load_adk_tools, initialize_adk_agent, initialize_adk_runner`

**Classes/Functions/Constants:**
- `async load_adk_tools(component) -> Tuple[List[Union[BaseTool, Callable]], List[BuiltinTool]]`: Loads all configured tools, including Python functions, MCP tools, and built-ins, wrapping them with `ADKToolWrapper`
- `initialize_adk_agent(component, loaded_explicit_tools, enabled_builtin_tools) -> AppLlmAgent`: Creates an `AppLlmAgent` instance, assigns all the necessary callbacks from `callbacks.py`, and attaches the tools
- `initialize_adk_runner(component) -> Runner`: Initializes the ADK Runner with the agent and services

#### stream_parser.py
**Purpose:** A stateful stream parser for identifying and extracting fenced artifact blocks from an LLM's text stream.
**Import:** `from solace_agent_mesh.agent.adk.stream_parser import FencedBlockStreamParser, BlockStartedEvent, BlockCompletedEvent`

**Classes/Functions/Constants:**
- `FencedBlockStreamParser(progress_update_interval_bytes=4096)`: Processes a stream of text chunks to identify and extract fenced artifact blocks
  - `process_chunk(text_chunk: str) -> ParserResult`: Processes the next chunk of text from the stream
  - `finalize() -> ParserResult`: Call at the end of an LLM turn to handle any unterminated blocks
- `BlockStartedEvent`, `BlockCompletedEvent`, `BlockProgressedEvent`, `BlockInvalidatedEvent`: Events emitted by the parser

#### tool_wrapper.py
**Purpose:** A wrapper for Python functions to make them compatible with ADK, handling embed resolution and config injection.
**Import:** `from solace_agent_mesh.agent.adk.tool_wrapper import ADKToolWrapper`

**Classes/Functions/Constants:**
- `ADKToolWrapper(original_func, tool_config, tool_name, origin, raw_string_args=None)`: A consolidated wrapper for ADK tools that handles metadata preservation, embed resolution, config injection, and error handling

### Subdirectory APIs

#### artifacts/
**Purpose:** Contains filesystem and S3-compatible artifact storage implementations for managing artifacts with versioning, user namespacing, and session-based organization
**Key Exports:** `FilesystemArtifactService`, `S3ArtifactService` classes for local and cloud artifact storage
**Import Examples:**
```python
from solace_agent_mesh.agent.adk.artifacts.filesystem_artifact_service import FilesystemArtifactService
from solace_agent_mesh.agent.adk.artifacts.s3_artifact_service import S3ArtifactService
```

#### models/
**Purpose:** Contains concrete `BaseLlm` implementations for interfacing with various LLM providers
**Key Exports:** `LiteLlm` class for broad model provider compatibility, `OAuth2ClientCredentialsTokenManager` for OAuth authentication
**Import Examples:**
```python
from solace_agent_mesh.agent.adk.models.lite_llm import LiteLlm
from solace_agent_mesh.agent.adk.models.oauth2_token_manager import OAuth2ClientCredentialsTokenManager
```

## Complete Usage Guide

### 1. Basic ADK Agent Setup

```python
from solace_agent_mesh.agent.adk.setup import load_adk_tools, initialize_adk_agent, initialize_adk_runner
from solace_agent_mesh.agent.adk.services import initialize_session_service, initialize_artifact_service, initialize_memory_service
from solace_agent_mesh.agent.adk.models.lite_llm import LiteLlm

# Initialize services
session_service = initialize_session_service(component)
artifact_service = initialize_artifact_service(component)
memory_service = initialize_memory_service(component)

# Load tools
loaded_tools, builtin_tools, cleanup_hooks = await load_adk_tools(component)

# Initialize agent
agent = initialize_adk_agent(component, loaded_tools, builtin_tools)

# Initialize runner
runner = initialize_adk_runner(component)
```

### 2. Custom LLM Model Configuration

```python
from solace_agent_mesh.agent.adk.models.lite_llm import LiteLlm

# Configure LiteLlm for different providers
# OpenAI
llm = LiteLlm(
    model="gpt-4-turbo",
    temperature=0.7,
    max_completion_tokens=1000,
    cache_strategy="5m"
)

# Anthropic
llm = LiteLlm(
    model="claude-3-sonnet-20240229",
    temperature=0.5
)

# Vertex AI
llm = LiteLlm(
    model="gemini-pro",
    temperature=0.3
)

# With OAuth authentication
llm = LiteLlm(
    model="custom-model",
    oauth_token_url="https://auth.example.com/oauth/token",
    oauth_client_id="your-client-id",
    oauth_client_secret="your-client-secret",

================================================================================

## Section 3: solace_agent_mesh/agent/adk/artifacts/artifacts_llm.txt

**Source file:** `solace_agent_mesh/agent/adk/artifacts/artifacts_llm.txt`

# DEVELOPER GUIDE: artifacts

## Quick Summary
The artifacts directory provides ADK ArtifactService implementations for the Solace Agent Mesh. It includes filesystem and S3-compatible storage backends for managing artifacts with versioning, user namespacing, and session-based organization.

## Files Overview
- `__init__.py` - Package initialization for artifact service implementations
- `filesystem_artifact_service.py` - Local filesystem-based artifact storage implementation
- `s3_artifact_service.py` - Amazon S3 compatible storage implementation for artifacts

## Developer API Reference

### filesystem_artifact_service.py
**Purpose:** Provides local filesystem storage for artifacts with structured directory organization and metadata management.

**Import:** `from solace_agent_mesh.agent.adk.artifacts.filesystem_artifact_service import FilesystemArtifactService`

**Classes:**
- `FilesystemArtifactService(base_path: str)` - Filesystem-based artifact service implementation
  - `save_artifact(*, app_name: str, user_id: str, session_id: str, filename: str, artifact: adk_types.Part) -> int` - Saves an artifact and returns version number
  - `load_artifact(*, app_name: str, user_id: str, session_id: str, filename: str, version: int | None = None) -> adk_types.Part | None` - Loads an artifact by version (latest if None)
  - `list_artifact_keys(*, app_name: str, user_id: str, session_id: str) -> list[str]` - Lists all artifact filenames for a scope
  - `delete_artifact(*, app_name: str, user_id: str, session_id: str, filename: str) -> None` - Deletes all versions of an artifact
  - `list_versions(*, app_name: str, user_id: str, session_id: str, filename: str) -> list[int]` - Lists all version numbers for an artifact
  - `base_path: str` - Root directory for artifact storage

**Constants/Variables:**
- `METADATA_FILE_SUFFIX: str` - File suffix for metadata files (".meta")

**Usage Examples:**
```python
from solace_agent_mesh.agent.adk.artifacts.filesystem_artifact_service import FilesystemArtifactService
from google.genai import types as adk_types

# Initialize the service
artifact_service = FilesystemArtifactService(base_path="/path/to/artifacts")

# Save an artifact
artifact_data = b"Hello, World!"
artifact_part = adk_types.Part.from_bytes(data=artifact_data, mime_type="text/plain")
version = await artifact_service.save_artifact(
    app_name="my_app",
    user_id="user123",
    session_id="session456",
    filename="greeting.txt",
    artifact=artifact_part
)

# Load the latest version
loaded_artifact = await artifact_service.load_artifact(
    app_name="my_app",
    user_id="user123", 
    session_id="session456",
    filename="greeting.txt"
)

# Load a specific version
specific_version = await artifact_service.load_artifact(
    app_name="my_app",
    user_id="user123",
    session_id="session456", 
    filename="greeting.txt",
    version=1
)

# List all artifacts
artifact_keys = await artifact_service.list_artifact_keys(
    app_name="my_app",
    user_id="user123",
    session_id="session456"
)

# List versions of an artifact
versions = await artifact_service.list_versions(
    app_name="my_app",
    user_id="user123",
    session_id="session456",
    filename="greeting.txt"
)

# Delete an artifact
await artifact_service.delete_artifact(
    app_name="my_app",
    user_id="user123",
    session_id="session456",
    filename="greeting.txt"
)
```

### s3_artifact_service.py
**Purpose:** Provides S3-compatible storage for artifacts with structured key organization and AWS integration.

**Import:** `from solace_agent_mesh.agent.adk.artifacts.s3_artifact_service import S3ArtifactService`

**Classes:**
- `S3ArtifactService(bucket_name: str, s3_client: BaseClient | None = None, **kwargs)` - S3-based artifact service implementation
  - `save_artifact(*, app_name: str, user_id: str, session_id: str, filename: str, artifact: adk_types.Part) -> int` - Saves an artifact to S3 and returns version number
  - `load_artifact(*, app_name: str, user_id: str, session_id: str, filename: str, version: int | None = None) -> adk_types.Part | None` - Loads an artifact from S3 by version (latest if None)
  - `list_artifact_keys(*, app_name: str, user_id: str, session_id: str) -> list[str]` - Lists all artifact filenames for a scope
  - `delete_artifact(*, app_name: str, user_id: str, session_id: str, filename: str) -> None` - Deletes all versions of an artifact from S3
  - `list_versions(*, app_name: str, user_id: str, session_id: str, filename: str) -> list[int]` - Lists all version numbers for an artifact
  - `bucket_name: str` - S3 bucket name for storage
  - `s3: BaseClient` - Boto3 S3 client instance

**Usage Examples:**
```python
from solace_agent_mesh.agent.adk.artifacts.s3_artifact_service import S3ArtifactService
from google.genai import types as adk_types
import boto3

# Initialize with default credentials
artifact_service = S3ArtifactService(bucket_name="my-artifacts-bucket")

# Initialize with custom S3 client
s3_client = boto3.client(
    's3',
    endpoint_url='https://minio.example.com',
    aws_access_key_id='access_key',
    aws_secret_access_key='secret_key'
)
artifact_service = S3ArtifactService(
    bucket_name="my-artifacts-bucket",
    s3_client=s3_client
)

# Save an artifact
artifact_data = b"Hello, S3!"
artifact_part = adk_types.Part.from_bytes(data=artifact_data, mime_type="text/plain")
version = await artifact_service.save_artifact(
    app_name="my_app",
    user_id="user123",
    session_id="session456", 
    filename="greeting.txt",
    artifact=artifact_part
)

# Load the latest version
loaded_artifact = await artifact_service.load_artifact(
    app_name="my_app",
    user_id="user123",
    session_id="session456",
    filename="greeting.txt"
)

# Save user-scoped artifact (persists across sessions)
user_artifact = adk_types.Part.from_bytes(data=b"User data", mime_type="text/plain")
await artifact_service.save_artifact(
    app_name="my_app", 
    user_id="user123",
    session_id="session456",
    filename="user:profile.json",  # user: prefix for user-scoped storage
    artifact=user_artifact
)

# List all artifacts (includes both session and user-scoped)
artifact_keys = await artifact_service.list_artifact_keys(
    app_name="my_app",
    user_id="user123", 
    session_id="session456"
)

# Delete an artifact
await artifact_service.delete_artifact(
    app_name="my_app",
    user_id="user123",
    session_id="session456",
    filename="greeting.txt"
)
```

================================================================================

## Section 4: solace_agent_mesh/agent/adk/models/models_llm.txt

**Source file:** `solace_agent_mesh/agent/adk/models/models_llm.txt`

# DEVELOPER GUIDE for models directory

## Quick Summary
This directory contains concrete implementations of the `BaseLlm` interface, providing wrappers for various Large Language Model APIs. These classes translate the ADK's standard `LlmRequest` into provider-specific formats and parse responses back into standard `LlmResponse` objects.

## Files Overview
- `lite_llm.py` - LLM client using the `litellm` library to support hundreds of models from different providers
- `oauth2_token_manager.py` - OAuth 2.0 Client Credentials token manager for LLM authentication

## Developer API Reference

### lite_llm.py
**Purpose:** Provides the `LiteLlm` class, a `BaseLlm` implementation that interfaces with hundreds of LLM models through the `litellm` library. Supports models from OpenAI, Anthropic, Vertex AI, and many other providers by simply changing the model string.

**Import:** `from solace_agent_mesh.agent.adk.models.lite_llm import LiteLlm`

**Classes:**
- `LiteLlm(model: str, cache_strategy: str = "5m", **kwargs)` - Wrapper around `litellm` supporting any model it recognizes
  - `generate_content_async(llm_request: LlmRequest, stream: bool = False) -> AsyncGenerator[LlmResponse, None]` - Generates content asynchronously with optional streaming
  - `supported_models() -> list[str]` - Returns list of supported models (empty for LiteLlm due to dynamic model support)
  - `model: str` - The name of the LiteLlm model
  - `llm_client: LiteLLMClient` - The LLM client instance used for API calls

- `LiteLLMClient()` - Internal client providing completion methods for better testability
  - `acompletion(model, messages, tools, **kwargs) -> Union[ModelResponse, CustomStreamWrapper]` - Asynchronous completion call
  - `completion(model, messages, tools, stream=False, **kwargs) -> Union[ModelResponse, CustomStreamWrapper]` - Synchronous completion call

- `FunctionChunk(BaseModel)` - Represents a function call chunk in streaming responses
  - `id: Optional[str]` - Function call ID
  - `name: Optional[str]` - Function name
  - `args: Optional[str]` - Function arguments as JSON string
  - `index: Optional[int]` - Index of the function call

- `TextChunk(BaseModel)` - Represents a text chunk in streaming responses
  - `text: str` - The text content

- `UsageMetadataChunk(BaseModel)` - Represents token usage information
  - `prompt_tokens: int` - Number of tokens in the prompt
  - `completion_tokens: int` - Number of tokens in the completion
  - `total_tokens: int` - Total number of tokens used

**Functions:**
- `_content_to_message_param(content: types.Content) -> Union[Message, list[Message]]` - Converts ADK Content to litellm Message format
- `_get_content(parts: Iterable[types.Part]) -> Union[OpenAIMessageContent, str]` - Converts parts to litellm content format
- `_function_declaration_to_tool_param(function_declaration: types.FunctionDeclaration) -> dict` - Converts function declarations to OpenAPI spec format
- `_model_response_to_generate_content_response(response: ModelResponse) -> LlmResponse` - Converts litellm response to LlmResponse

**Usage Examples:**
```python
import asyncio
import os
from solace_agent_mesh.agent.adk.models.lite_llm import LiteLlm
from solace_agent_mesh.agent.adk.models.llm_request import LlmRequest, LlmConfig
from google.genai.types import Content, Part

# Set environment variables for your chosen provider
# For OpenAI:
# os.environ["OPENAI_API_KEY"] = "your-api-key"
# For Vertex AI:
# os.environ["VERTEXAI_PROJECT"] = "your-project-id"
# os.environ["VERTEXAI_LOCATION"] = "your-location"

async def main():
    # Initialize LiteLlm with a specific model
    llm = LiteLlm(
        model="gpt-4-turbo",
        temperature=0.7,
        max_completion_tokens=150,
        cache_strategy="5m"  # Options: "none", "5m", "1h"
    )
    
    # Create a request
    request = LlmRequest(
        contents=[
            Content(
                role="user",
                parts=[Part.from_text("Explain quantum computing in simple terms")]
            )
        ],
        config=LlmConfig(
            temperature=0.5,
            max_output_tokens=200
        )
    )
    
    # Non-streaming generation
    print("=== Non-streaming ===")
    async for response in llm.generate_content_async(request, stream=False):
        print(f"Response: {response.text}")
        if response.usage_metadata:
            print(f"Tokens used: {response.usage_metadata.total_token_count}")
    
    # Streaming generation
    print("\n=== Streaming ===")
    async for response in llm.generate_content_async(request, stream=True):
        if response.text:
            print(response.text, end="", flush=True)
        if response.usage_metadata:
            print(f"\nTotal tokens: {response.usage_metadata.total_token_count}")

# Example with OAuth authentication
async def oauth_example():
    llm = LiteLlm(
        model="custom-model",
        oauth_token_url="https://auth.example.com/oauth/token",
        oauth_client_id="your-client-id",
        oauth_client_secret="your-client-secret",
        oauth_scope="llm.read llm.write",
        oauth_ca_cert="/path/to/ca.crt",  # Optional
        oauth_token_refresh_buffer_seconds=300,  # Optional
        oauth_max_retries=3  # Optional
    )
    
    request = LlmRequest(
        contents=[Content(role="user", parts=[Part.from_text("Hello!")])]
    )
    
    async for response in llm.generate_content_async(request):
        print(response.text)

if __name__ == "__main__":
    asyncio.run(main())
```

### oauth2_token_manager.py
**Purpose:** Provides OAuth 2.0 Client Credentials flow implementation for LLM authentication with automatic token management, caching, and refresh capabilities.

**Import:** `from solace_agent_mesh.agent.adk.models.oauth2_token_manager import OAuth2ClientCredentialsTokenManager`

**Classes:**
- `OAuth2ClientCredentialsTokenManager(token_url: str, client_id: str, client_secret: str, scope: Optional[str] = None, ca_cert_path: Optional[str] = None, refresh_buffer_seconds: int = 300, max_retries: int = 3)` - Manages OAuth 2.0 Client Credentials tokens with caching and automatic refresh
  - `get_token() -> str` - Get a valid OAuth 2.0 access token (async)
  - `token_url: str` - OAuth 2.0 token endpoint URL
  - `client_id: str` - OAuth client identifier
  - `client_secret: str` - OAuth client secret
  - `scope: Optional[str]` - OAuth scope (space-separated string)
  - `ca_cert_path: Optional[str]` - Path to custom CA certificate file
  - `refresh_buffer_seconds: int` - Seconds before actual expiry to refresh token
  - `max_retries: int` - Maximum number of retry attempts for token requests

**Usage Examples:**
```python
import asyncio
from solace_agent_mesh.agent.adk.models.oauth2_token_manager import OAuth2ClientCredentialsTokenManager

async def main():
    # Initialize OAuth token manager
    token_manager = OAuth2ClientCredentialsTokenManager(
        token_url="https://auth.example.com/oauth/token",
        client_id="your-client-id",
        client_secret="your-client-secret",
        scope="llm.read llm.write",  # Optional
        ca_cert_path="/path/to/ca.crt",  # Optional for custom CA
        refresh_buffer_seconds=300,  # Refresh 5 minutes before expiry
        max_retries=3  # Retry failed requests up to 3 times
    )
    
    try:
        # Get a valid access token
        access_token = await token_manager.get_token()
        print(f"Access token: {access_token[:20]}...")
        
        # Token is automatically cached and reused
        # Subsequent calls will return cached token if still valid
        cached_token = await token_manager.get_token()
        print(f"Cached token: {cached_token[:20]}...")
        
    except Exception as e:
        print(f"Failed to get OAuth token: {e}")

# Example with custom SSL configuration
async def custom_ssl_example():
    token_manager = OAuth2ClientCredentialsTokenManager(
        token_url="https://secure-auth.example.com/oauth/token",
        client_id="client-123",
        client_secret="secret-456",
        ca_cert_path="/etc/ssl/certs/custom-ca.pem",  # Custom CA certificate
        refresh_buffer_seconds=600,  # Refresh 10 minutes early
        max_retries=5  # More retries for unreliable networks
    )
    
    token = await token_manager.get_token()
    print(f"Token obtained with custom SSL: {token[:20]}...")

if __name__ == "__main__":
    asyncio.run(main())
```

================================================================================

## Section 5: solace_agent_mesh/agent/agent_llm.txt

**Source file:** `solace_agent_mesh/agent/agent_llm.txt`

# DEVELOPER GUIDE for agent directory

## Quick Summary
The `agent` directory provides a comprehensive framework for hosting Google ADK (Agent Development Kit) agents within the Solace AI Connector ecosystem. It bridges ADK agents with the A2A (Agent-to-Agent) protocol over Solace messaging, enabling distributed agent communication, task delegation, and rich tool functionality.

The architecture is modular, consisting of several key components:
- **`sac/` (Solace AI Connector):** The main entry point, providing the `SamAgentApp` and `SamAgentComponent` to host the agent and manage its lifecycle and communication over the Solace event mesh.
- **`adk/` (Agent Development Kit):** The core integration layer with Google's ADK. It defines the custom `AppLlmAgent`, manages asynchronous task execution, and provides a rich set of callbacks to augment agent behavior.
- **`tools/`:** A comprehensive and extensible library of tools available to the agent, covering data analysis, artifact management, web requests, multimedia processing, and inter-agent communication.
- **`protocol/`:** The underlying implementation of the A2A (Agent-to-Agent) communication protocol, handling message routing and event processing.
- **`utils/`:** A collection of helper modules for common tasks like artifact management, configuration parsing, and context handling.
- **`testing/`:** Utilities to aid in debugging and testing custom agent implementations.
- **`proxies/`:** Framework for creating proxy applications that enable communication with downstream agents using various protocols.

These components work together to create a robust environment where an ADK agent can be configured with specific instructions and tools, communicate with other agents, and execute complex tasks in a distributed, event-driven manner.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Standard Python package initializer that marks the `agent` directory as a Python package
  - `agent_llm.txt`: Documentation file containing comprehensive developer guide content
  - `agent_llm_detail.txt`: Concatenated documentation file from all subdirectories
- **Subdirectories:**
  - `adk/`: Provides the core integration layer with Google's ADK, including custom agents, services, and callbacks
  - `protocol/`: Implements the A2A protocol event handlers for message routing and agent communication
  - `proxies/`: Framework for creating proxy applications that bridge different agent protocols
  - `sac/`: Contains the Solace AI Connector app and component implementations for hosting ADK agents
  - `testing/`: Provides utilities for testing the A2A framework and debugging agent behavior
  - `tools/`: A comprehensive, registry-based tool library for AI agents
  - `utils/`: Contains helper utilities for configuration, context handling, and artifact management

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Standard Python package initializer. It allows the `agent` directory to be treated as a package.
**Import:** `import solace_agent_mesh.agent`

**Classes/Functions/Constants:** [None - empty file]

#### agent_llm.txt
**Purpose:** Documentation file containing comprehensive developer guide content
**Import:** Not applicable - this is a documentation file, not a code module

**Classes/Functions/Constants:** [None - documentation file]

#### agent_llm_detail.txt
**Purpose:** Concatenated documentation file from all subdirectories
**Import:** Not applicable - this is a documentation file, not a code module

**Classes/Functions/Constants:** [None - documentation file]

### Subdirectory APIs

#### adk/
**Purpose:** Provides the core integration layer between the Solace AI Connector and Google's ADK
**Key Exports:** `AppLlmAgent`, `initialize_adk_agent`, `initialize_adk_runner`, `load_adk_tools`, `FilesystemArtifactService`, `S3ArtifactService`, `LiteLlm`
**Import Examples:**
```python
from solace_agent_mesh.agent.adk.setup import load_adk_tools, initialize_adk_agent, initialize_adk_runner
from solace_agent_mesh.agent.adk.app_llm_agent import AppLlmAgent
from solace_agent_mesh.agent.adk.artifacts.filesystem_artifact_service import FilesystemArtifactService
from solace_agent_mesh.agent.adk.artifacts.s3_artifact_service import S3ArtifactService
from solace_agent_mesh.agent.adk.models.lite_llm import LiteLlm
from solace_agent_mesh.agent.adk.services import initialize_session_service, initialize_artifact_service
```

#### protocol/
**Purpose:** Implements the core logic for Agent-to-Agent (A2A) communication protocol
**Key Exports:** `process_event`, `handle_a2a_request`, `handle_agent_card_message`, `publish_agent_card`
**Import Examples:**
```python
from solace_agent_mesh.agent.protocol.event_handlers import process_event, publish_agent_card
```

#### proxies/
**Purpose:** Framework for creating proxy applications that enable communication with downstream agents using various protocols
**Key Exports:** `BaseProxyApp`, `BaseProxyComponent`, `A2AProxyApp`, `A2AProxyComponent`, `OAuth2TokenCache`
**Import Examples:**
```python
from solace_agent_mesh.agent.proxies.base.app import BaseProxyApp
from solace_agent_mesh.agent.proxies.base.component import BaseProxyComponent
from solace_agent_mesh.agent.proxies.a2a.app import A2AProxyApp
from solace_agent_mesh.agent.proxies.a2a.component import A2AProxyComponent
from solace_agent_mesh.agent.proxies.a2a.oauth_token_cache import OAuth2TokenCache
```

#### sac/
**Purpose:** Provides the Solace AI Connector app and component implementations for hosting ADK agents
**Key Exports:** `SamAgentApp`, `SamAgentComponent`, `TaskExecutionContext`
**Import Examples:**
```python
from solace_agent_mesh.agent.sac.app import SamAgentApp
from solace_agent_mesh.agent.sac.component import SamAgentComponent
from solace_agent_mesh.agent.sac.task_execution_context import TaskExecutionContext
```

#### testing/
**Purpose:** Provides utilities for testing the A2A framework and debugging agent behavior
**Key Exports:** `pretty_print_event_history`
**Import Examples:**
```python
from solace_agent_mesh.agent.testing.debug_utils import pretty_print_event_history
```

#### tools/
**Purpose:** A comprehensive, registry-based tool library for AI agents
**Key Exports:** `tool_registry`, `BuiltinTool`, `PeerAgentTool`, and various tool functions
**Import Examples:**
```python
from solace_agent_mesh.agent.tools.registry import tool_registry
from solace_agent_mesh.agent.tools.peer_agent_tool import PeerAgentTool
from solace_agent_mesh.agent.tools.audio_tools import text_to_speech
from solace_agent_mesh.agent.tools.builtin_artifact_tools import list_artifacts, load_artifact
from solace_agent_mesh.agent.tools.image_tools import create_image_from_description
```

#### utils/
**Purpose:** Contains helper utilities for configuration, context handling, and artifact management
**Key Exports:** `save_artifact_with_metadata`, `load_artifact_content_or_metadata`, `resolve_instruction_provider`
**Import Examples:**
```python
from solace_agent_mesh.agent.utils.artifact_helpers import save_artifact_with_metadata, load_artifact_content_or_metadata
from solace_agent_mesh.agent.utils.config_parser import resolve_instruction_provider
from solace_agent_mesh.agent.utils.context_helpers import get_session_from_callback_context
```

## Complete Usage Guide

### 1. Basic Agent Setup and Configuration

```python
# Import the main SAC components
from solace_agent_mesh.agent.sac.app import SamAgentApp
from solace_agent_mesh.agent.sac.component import SamAgentComponent

# The agent is typically configured via YAML and instantiated by the SAC framework
# Example agent-config.yaml:
"""
app:
  class_name: solace_agent_mesh.agent.sac.app.SamAgentApp
  app_config:
    namespace: "my-org/production"
    agent_name: "customer-support-agent"
    model: "gemini-1.5-pro-latest"
    tools:
      - tool_type: "builtin"
        tool_name: "text_to_speech"
      - tool_type: "builtin"
        tool_name: "list_artifacts"
    agent_card:
      description: "An agent that can answer questions about customer accounts."
    session_service:
      type: "memory"
    artifact_service:
      type: "filesystem"
      base_path: "/tmp/artifacts"
"""
```

### 2. Working with ADK Components

```python
from solace_agent_mesh.agent.adk.setup import load_adk_tools, initialize_adk_agent, initialize_adk_runner
from solace_agent_mesh.agent.adk.services import initialize_session_service, initialize_artifact_service
from solace_agent_mesh.agent.adk.models.lite_llm import LiteLlm

async def setup_adk_agent(component):
    # Initialize services
    session_service = initialize_session_service(component)
    artifact_service = initialize_artifact_service(component)
    
    # Load tools
    loaded_tools, builtin_tools = await load_adk_tools(component)
    
    # Initialize agent with LLM
    agent = initialize_adk_agent(component, loaded_tools, builtin_tools)
    
    # Initialize runner
    runner = initialize_adk_runner(component)
    
    return agent, runner
```

### 3. Custom Tool Development

```python
from solace_agent_mesh.agent.tools.registry import tool_registry
from solace_agent_mesh.agent.tools.tool_definition import BuiltinTool
from google.adk.tools import ToolContext

# Define a custom tool function
async def my_custom_tool(
    query: str,
    tool_context: ToolContext = None,
    tool_config: dict = None
) -> dict:
    """A custom tool that processes queries."""
    # Access the host component
    host_component = tool_context._invocation_context.agent.host_component
    
    # Use agent state
    db_connection = host_component.get_agent_specific_state('db_connection')
    
    # Process the query
    result = await process_query(query, db_connection)
    
    return {"result": result, "status": "success"}

# Register the tool
custom_tool = BuiltinTool(
    name="my_custom_tool",
    description="Processes custom queries",
    function=my_custom_tool,
    category="custom"
)
tool_registry.register(custom_tool)
```

### 4. Artifact Management

```python
from solace_agent_mesh.agent.utils.artifact_helpers import (
    save_artifact_with_metadata,
    load_artifact_content_or_metadata,
    get_artifact_info_list
)
from datetime import datetime, timezone

async def artifact_operations(component, artifact_service):
    # Save an artifact with metadata
    content = b"Hello, world!"
    result = await save_artifact_with_metadata(
        artifact_service=artifact_service,
        app_name=component.get_config()["app_name"],
        user_id="user123",
        session_id="session456",
        filename="greeting.txt",
        content_bytes=content,
        mime_type="text/plain",
        metadata_dict={"source": "custom_tool", "description": "A greeting"},
        timestamp=datetime.now(timezone.utc)
    )
    
    # Load the artifact
    loaded = await load_artifact_content_or_metadata(
        artifact_service=artifact_service,
        app_name=component.get_config()["app_name"],
        user_id="user123",
        session_id="session456",
        filename="greeting.txt",
        version="latest"
    )
    
    # List all artifacts
    artifacts = await get_artifact_info_list(
        artifact_service=artifact_service,
        app_name=component.get_config()["app_name"],
        user_id="user123",
        session_id="session456"
    )
    
    return artifacts
```

### 5. Inter-Agent Communication

```python
from solace_agent_mesh.agent.tools.peer_agent_tool import PeerAgentTool

# Create a peer agent tool (typically done automatically by the framework)
peer_tool = PeerAgentTool("data_analyst_agent", host_component)

# The LLM can then use this tool to delegate tasks:
# "Please use the data_analyst_agent to analyze the sales data in report.csv"

# The framework handles the A2A protocol communication automatically
```

### 6. Audio and Multimedia Tools

```python
from solace_agent_mesh.agent.tools.audio_tools import text_to_speech, multi_speaker_text_to_speech
from solace_agent_mesh.agent.tools.image_tools import create_image_from_description, describe_image

async def multimedia_example(tool_context):
    # Generate speech from text
    tts_result = await text_to_speech(
        text="Welcome to our service!",
        output_filename="welcome.mp3",
        gender="female",
        tone="friendly",
        tool_context=tool_context
    )
    
    # Create a multi-speaker conversation
    conversation_result = await multi_speaker_text_to_speech(
        conversation_text="Alice: Hello there!\nBob: Hi Alice, how are you?",
        speaker_configs=[
            {"name": "Alice", "gender": "female", "tone": "bright"},
            {"name": "Bob", "gender": "male", "tone": "warm"}
        ],
        tool_context=tool_context
    )
    
    # Generate an image
    image_result = await create_image_from_description(
        image_description="A futuristic cityscape at sunset",
        output_filename="cityscape.png",
        tool_context=tool_context
    )
    
    return tts_result, conversation_result, image_result
```

### 7. Proxy Applications for External Agents

```python
from solace_agent_mesh.agent.proxies.a2a.app import A2AProxyApp

# Configure proxy for external A2A-over-HTTPS agents
proxy_config = {
    "app_config": {
        "namespace": "myorg/production",
        "proxied_agents": [
            {
                "name": "external-agent",
                "url": "https://external-agent.example.com",
                "authentication": {
                    "type": "oauth2_client_credentials",
                    "token_url": "https://auth.example.com/oauth/token",
                    "client_id": "my-client-id",
                    "client_secret": "my-client-secret"
                }
            }
        ],
        "artifact_service": {
            "type": "gcs",
            "bucket_name": "my-artifacts-bucket"
        }
    }
}

# Create and run the proxy
proxy_app = A2AProxyApp(proxy_config)
# Proxy automatically handles discovery and request forwarding
```

### 8. Testing and Debugging

```python
from solace_agent_mesh.agent.testing.debug_utils import pretty_print_event_history
from solace_agent_mesh.agent.adk.invocation_monitor import InvocationMonitor

# Debug event history in tests
def test_agent_behavior():
    event_history = [
        {"result": {"status": {"state": "EXECUTING"}}},
        {"result": {"status": {"state": "COMPLETED"}}}
    ]
    
    # Print formatted event history for debugging
    pretty_print_event_history(event_history)

# Monitor agent invocations
monitor = InvocationMonitor()
monitor.log_message_event("

================================================================================

## Section 6: solace_agent_mesh/agent/protocol/protocol_llm.txt

**Source file:** `solace_agent_mesh/agent/protocol/protocol_llm.txt`

# DEVELOPER GUIDE: protocol

## Quick Summary
The `protocol` directory implements the core logic for Agent-to-Agent (A2A) communication. It handles receiving and processing requests, responses, and discovery messages (Agent Cards) over the Solace event mesh. It acts as the bridge between the A2A protocol and the underlying Google ADK execution environment.

## Files Overview
- `__init__.py` - Empty package initialization file
- `event_handlers.py` - Contains the primary logic for handling all A2A protocol events, including routing incoming messages, managing task execution, and handling agent discovery

## Developer API Reference

### __init__.py
**Purpose:** Standard Python package initialization file
**Import:** `from solace_agent_mesh.agent.protocol import *`

This is an empty package initialization file and has no public interfaces.

### event_handlers.py
**Purpose:** Central hub for processing all events related to the A2A protocol. Routes events to appropriate handlers and manages task lifecycle.
**Import:** `from solace_agent_mesh.agent.protocol.event_handlers import process_event, handle_a2a_request, handle_agent_card_message, handle_a2a_response, publish_agent_card, handle_sam_event, cleanup_agent_session`

**Functions:**
- `process_event(component, event: Event) -> None` - Main event router that processes incoming events and delegates to specific handlers based on event type and topic
- `handle_a2a_request(component, message: SolaceMessage) -> None` - Handles incoming A2A request messages, starts ADK runner for SendTask requests, and processes CancelTask requests
- `handle_agent_card_message(component, message: SolaceMessage) -> None` - Processes incoming Agent Card discovery messages and updates peer agent registry
- `handle_a2a_response(component, message: SolaceMessage) -> None` - Handles responses and status updates from peer agents, manages parallel task completion
- `publish_agent_card(component) -> None` - Publishes the agent's capabilities and information to the discovery topic
- `handle_sam_event(component, message: SolaceMessage, topic: str) -> None` - Handles incoming SAM system events like session deletion
- `cleanup_agent_session(component, session_id: str, user_id: str) -> None` - Cleans up agent-side session data when sessions are deleted

**Internal Helper Functions:**
- `_register_peer_artifacts_in_parent_context(parent_task_context: "TaskExecutionContext", peer_task_object: Task, log_identifier: str) -> None` - Registers artifacts produced by peer agents in the parent task context
- `_publish_peer_tool_result_notification(component: "SamAgentComponent", correlation_data: Dict[str, Any], payload_to_queue: Any, log_identifier: str) -> None` - Publishes a ToolResultData status update for a completed peer tool call

**Usage Examples:**
```python
# Main event processing (typically called by the SAC framework)
from solace_agent_mesh.agent.protocol.event_handlers import process_event
from solace_ai_connector.common.event import Event, EventType

# Process an incoming event
await process_event(component, event)

# Publish agent discovery card
from solace_agent_mesh.agent.protocol.event_handlers import publish_agent_card

publish_agent_card(component)

# Handle specific message types (usually called internally by process_event)
from solace_agent_mesh.agent.protocol.event_handlers import handle_a2a_request

await handle_a2a_request(component, solace_message)

# Handle SAM system events
from solace_agent_mesh.agent.protocol.event_handlers import handle_sam_event

handle_sam_event(component, message, topic)

# Clean up session data
from solace_agent_mesh.agent.protocol.event_handlers import cleanup_agent_session

await cleanup_agent_session(component, "session_123", "user_456")
```

**Key Event Flow:**
1. `process_event()` receives all events and routes based on type (MESSAGE, TIMER, CACHE_EXPIRY)
2. For MESSAGE events, routes to specific handlers based on topic patterns:
   - Agent request topics → `handle_a2a_request()`
   - Discovery topics → `handle_agent_card_message()`
   - Response/status topics → `handle_a2a_response()`
   - SAM events topics → `handle_sam_event()`
3. For TIMER events, handles periodic agent card publishing
4. For CACHE_EXPIRY events, delegates to component's cache handling

**Dependencies:**
- Requires `SamAgentComponent` instance with proper configuration
- Uses A2A protocol types from `a2a.types`
- Integrates with Google ADK for task execution
- Manages task contexts through `TaskExecutionContext`

================================================================================

## Section 7: solace_agent_mesh/agent/proxies/a2a/a2a_llm.txt

**Source file:** `solace_agent_mesh/agent/proxies/a2a/a2a_llm.txt`

# DEVELOPER GUIDE: a2a

## Quick Summary
The `a2a` directory provides a concrete implementation for proxying standard A2A-over-HTTPS agents. It enables the Solace Agent Mesh to communicate with downstream agents that implement the A2A (Agent-to-Agent) protocol over HTTP/HTTPS, handling authentication, request forwarding, and response processing.

## Files Overview
- `__init__.py` - Package initialization for A2A-over-HTTPS proxy implementation
- `app.py` - Main application class that validates A2A-specific configuration
- `component.py` - Core proxy component that handles A2A protocol communication and request forwarding
- `config.py` - Pydantic configuration models for A2A proxy settings and authentication
- `oauth_token_cache.py` - OAuth 2.0 token caching system with automatic expiration

## Developer API Reference

### app.py
**Purpose:** Provides the main application class for A2A proxy with configuration validation
**Import:** `from solace_agent_mesh.agent.proxies.a2a.app import A2AProxyApp`

**Classes:**
- `A2AProxyApp(app_info: Dict[str, Any], **kwargs)` - Main A2A proxy application class
  - Inherits from `BaseProxyApp` and adds A2A-specific configuration validation
  - Validates authentication settings, URLs, and other A2A-specific parameters

**Usage Examples:**
```python
from solace_agent_mesh.agent.proxies.a2a.app import A2AProxyApp

# Create A2A proxy app with configuration
app_info = {
    "app_config": {
        "proxied_agents": [
            {
                "name": "my-agent",
                "url": "https://agent.example.com",
                "authentication": {
                    "type": "oauth2_client_credentials",
                    "token_url": "https://auth.example.com/token",
                    "client_id": "my-client-id",
                    "client_secret": "my-secret"
                }
            }
        ]
    }
}

app = A2AProxyApp(app_info)
```

### component.py
**Purpose:** Core component that handles A2A protocol communication, authentication, and request forwarding
**Import:** `from solace_agent_mesh.agent.proxies.a2a.component import A2AProxyComponent`

**Classes:**
- `A2AProxyComponent(**kwargs: Any)` - Main proxy component for A2A-over-HTTPS agents
  - `clear_client_cache() -> None` - Clears all cached A2A clients and OAuth tokens
  - `cleanup() -> None` - Cleans up resources on component shutdown

**Usage Examples:**
```python
from solace_agent_mesh.agent.proxies.a2a.component import A2AProxyComponent

# Create component (typically done by the framework)
component = A2AProxyComponent(
    proxied_agents_config=[
        {
            "name": "my-agent",
            "url": "https://agent.example.com",
            "authentication": {
                "type": "static_bearer",
                "token": "my-bearer-token"
            }
        }
    ]
)

# Clear cache if needed (useful for testing)
component.clear_client_cache()

# Cleanup when shutting down
component.cleanup()
```

### config.py
**Purpose:** Pydantic configuration models for A2A proxy settings and authentication validation
**Import:** `from solace_agent_mesh.agent.proxies.a2a.config import A2AProxyAppConfig, AuthenticationConfig, A2AProxiedAgentConfig`

**Classes:**
- `AuthenticationConfig()` - Authentication configuration for downstream A2A agents
  - `type: Optional[Literal["static_bearer", "static_apikey", "oauth2_client_credentials"]]` - Authentication type
  - `token: Optional[str]` - Authentication token (for static types)
  - `token_url: Optional[str]` - OAuth 2.0 token endpoint URL
  - `client_id: Optional[str]` - OAuth 2.0 client identifier
  - `client_secret: Optional[str]` - OAuth 2.0 client secret
  - `scope: Optional[str]` - OAuth 2.0 scope string
  - `token_cache_duration_seconds: int` - Token cache duration (default: 3300)

- `A2AProxiedAgentConfig()` - Configuration for a single A2A agent
  - `url: str` - Base URL of the downstream A2A agent
  - `authentication: Optional[AuthenticationConfig]` - Authentication details

- `A2AProxyAppConfig()` - Complete configuration for A2A proxy application
  - `proxied_agents: List[A2AProxiedAgentConfig]` - List of agents to proxy

**Usage Examples:**
```python
from solace_agent_mesh.agent.proxies.a2a.config import (
    A2AProxyAppConfig, 
    A2AProxiedAgentConfig, 
    AuthenticationConfig
)

# OAuth 2.0 authentication
oauth_auth = AuthenticationConfig(
    type="oauth2_client_credentials",
    token_url="https://auth.example.com/token",
    client_id="my-client-id",
    client_secret="my-secret",
    scope="agent:read agent:write",
    token_cache_duration_seconds=3300
)

# Static bearer token authentication
bearer_auth = AuthenticationConfig(
    type="static_bearer",
    token="my-bearer-token"
)

# Agent configuration
agent_config = A2AProxiedAgentConfig(
    name="my-agent",
    url="https://agent.example.com",
    authentication=oauth_auth
)

# Complete app configuration
app_config = A2AProxyAppConfig(
    proxied_agents=[agent_config]
)

# Validate configuration
validated_config = A2AProxyAppConfig.model_validate({
    "proxied_agents": [
        {
            "name": "test-agent",
            "url": "https://agent.example.com",
            "authentication": {
                "type": "static_bearer",
                "token": "abc123"
            }
        }
    ]
})
```

### oauth_token_cache.py
**Purpose:** Thread-safe OAuth 2.0 token caching with automatic expiration
**Import:** `from solace_agent_mesh.agent.proxies.a2a.oauth_token_cache import OAuth2TokenCache, CachedToken`

**Classes:**
- `CachedToken(access_token: str, expires_at: float)` - Represents a cached token with expiration
  - `access_token: str` - The OAuth 2.0 access token
  - `expires_at: float` - Unix timestamp when token expires

- `OAuth2TokenCache()` - Thread-safe in-memory cache for OAuth tokens
  - `get(agent_name: str) -> Optional[str]` - Retrieves cached token if valid
  - `set(agent_name: str, access_token: str, cache_duration_seconds: int) -> None` - Caches token with expiration
  - `invalidate(agent_name: str) -> None` - Removes token from cache

**Usage Examples:**
```python
from solace_agent_mesh.agent.proxies.a2a.oauth_token_cache import OAuth2TokenCache

# Create token cache
cache = OAuth2TokenCache()

# Cache a token for 1 hour
await cache.set("my-agent", "access_token_123", 3600)

# Retrieve cached token
token = await cache.get("my-agent")
if token:
    print(f"Using cached token: {token}")
else:
    print("No valid cached token found")

# Invalidate cached token
await cache.invalidate("my-agent")
```

================================================================================

## Section 8: solace_agent_mesh/agent/proxies/base/base_llm.txt

**Source file:** `solace_agent_mesh/agent/proxies/base/base_llm.txt`

# DEVELOPER GUIDE: base

## Quick Summary
The `base` directory contains protocol-agnostic abstract base classes for implementing proxy applications in the Solace Agent Mesh. These classes handle common functionality like A2A message routing, agent discovery, task lifecycle management, and artifact resolution, allowing concrete proxy implementations to focus on protocol-specific details.

## Files Overview
- `__init__.py` - Package initialization for base proxy classes
- `app.py` - Abstract base class for proxy applications with configuration validation and component setup
- `component.py` - Abstract base class for proxy components handling Solace interaction and task management
- `config.py` - Pydantic configuration models for proxy applications
- `proxy_task_context.py` - Runtime state container for individual proxied agent tasks

## Developer API Reference

### __init__.py
**Purpose:** Package initialization file for base proxy classes
**Import:** `from solace_agent_mesh.agent.proxies.base import *`

This file contains only package documentation and no public API.

### app.py
**Purpose:** Abstract base class for proxy applications that handles configuration validation and automatic component setup
**Import:** `from solace_agent_mesh.agent.proxies.base.app import BaseProxyApp`

**Classes:**
- `BaseProxyApp(app_info: Dict[str, Any], **kwargs)` - Abstract base for proxy apps that automatically configures subscriptions and components
  - `_get_component_class() -> Type[BaseProxyComponent]` - Abstract method to return the specific proxy component class

**Usage Examples:**
```python
from solace_agent_mesh.agent.proxies.base.app import BaseProxyApp
from solace_agent_mesh.agent.proxies.base.component import BaseProxyComponent

class MyProxyApp(BaseProxyApp):
    def _get_component_class(self):
        return MyProxyComponent

# App will automatically:
# - Validate configuration against BaseProxyAppConfig
# - Generate Solace subscriptions for all proxied agents
# - Create component instance with proper broker settings
```

### component.py
**Purpose:** Abstract base class for proxy components that handles Solace interaction, discovery, and task lifecycle
**Import:** `from solace_agent_mesh.agent.proxies.base.component import BaseProxyComponent`

**Classes:**
- `BaseProxyComponent(**kwargs: Any)` - Abstract base for proxy components with async event processing
  - `process_event(event: Event) -> None` - Processes incoming Solace events
  - `invoke(message: SolaceMessage, data: dict) -> dict` - Placeholder invoke method (not used)
  - `run() -> None` - Starts component operations and discovery timers
  - `cleanup() -> None` - Cleans up resources on shutdown
  - `clear_client_cache() -> None` - Clears cached clients (override in subclasses)
  - `_fetch_agent_card(agent_config: dict) -> Optional[AgentCard]` - Abstract method to fetch agent cards
  - `_forward_request(task_context: ProxyTaskContext, request: A2ARequest, agent_name: str) -> None` - Abstract method to forward requests

**Usage Examples:**
```python
from solace_agent_mesh.agent.proxies.base.component import BaseProxyComponent
from a2a.types import AgentCard, A2ARequest

class MyProxyComponent(BaseProxyComponent):
    async def _fetch_agent_card(self, agent_config: dict) -> Optional[AgentCard]:
        # Implement protocol-specific agent discovery
        url = agent_config.get("url")
        # ... fetch and return AgentCard
        
    async def _forward_request(self, task_context, request: A2ARequest, agent_name: str):
        # Implement protocol-specific request forwarding
        # ... forward request to downstream agent
        # ... handle responses and publish back to Solace
```

### config.py
**Purpose:** Pydantic configuration models for proxy applications
**Import:** `from solace_agent_mesh.agent.proxies.base.config import BaseProxyAppConfig, ProxiedAgentConfig, ArtifactServiceConfig`

**Classes:**
- `ArtifactServiceConfig()` - Configuration for artifact service
  - `type: str` - Service type ('memory', 'gcs', 'filesystem')
  - `base_path: Optional[str]` - Base directory for filesystem type
  - `bucket_name: Optional[str]` - GCS bucket name
  - `artifact_scope: Literal["namespace", "app", "custom"]` - Scope for artifacts
  - `artifact_scope_value: Optional[str]` - Custom scope identifier

- `ProxiedAgentConfig()` - Configuration for individual proxied agents
  - `name: str` - Agent name on Solace mesh
  - `request_timeout_seconds: Optional[int]` - Timeout override for this agent

- `BaseProxyAppConfig()` - Base configuration for proxy applications
  - `namespace: str` - Topic prefix for A2A communication
  - `proxied_agents: List[ProxiedAgentConfig]` - List of agents to proxy
  - `artifact_service: ArtifactServiceConfig` - Artifact service configuration
  - `discovery_interval_seconds: int` - Agent discovery interval (default: 60)
  - `default_request_timeout_seconds: int` - Default request timeout (default: 300)

**Usage Examples:**
```python
from solace_agent_mesh.agent.proxies.base.config import BaseProxyAppConfig

# Configuration validation
config_dict = {
    "namespace": "myorg/dev",
    "proxied_agents": [
        {"name": "my-agent", "request_timeout_seconds": 120}
    ],
    "artifact_service": {"type": "memory"},
    "discovery_interval_seconds": 30
}

config = BaseProxyAppConfig.model_validate(config_dict)
```

### proxy_task_context.py
**Purpose:** Runtime state container for individual proxied agent tasks
**Import:** `from solace_agent_mesh.agent.proxies.base.proxy_task_context import ProxyTaskContext`

**Classes:**
- `ProxyTaskContext(task_id: str, a2a_context: Dict[str, Any])` - Runtime state for a proxied task
  - `task_id: str` - Unique identifier for the task
  - `a2a_context: Dict[str, Any]` - A2A protocol context information

**Usage Examples:**
```python
from solace_agent_mesh.agent.proxies.base.proxy_task_context import ProxyTaskContext

# Create task context when handling new request
a2a_context = {
    "jsonrpc_request_id": "req-123",
    "logical_task_id": "task-456", 
    "session_id": "session-789",
    "user_id": "user123",
    "status_topic": "status/topic",
    "reply_to_topic": "reply/topic",
    "is_streaming": False
}

task_context = ProxyTaskContext(
    task_id="task-456",
    a2a_context=a2a_context
)

# Store in active tasks for lifecycle management
self.active_tasks[task_context.task_id] = task_context
```

================================================================================

## Section 9: solace_agent_mesh/agent/proxies/proxies_llm.txt

**Source file:** `solace_agent_mesh/agent/proxies/proxies_llm.txt`

# DEVELOPER GUIDE: proxies

## Quick Summary
The `proxies` directory provides a framework for creating proxy applications that enable the Solace Agent Mesh to communicate with downstream agents using various protocols. It consists of protocol-agnostic base classes in the `base/` subdirectory that handle common functionality like message routing, agent discovery, and task management, plus concrete implementations like `a2a/` for A2A-over-HTTPS protocol support.

## Files and Subdirectories Overview
- **Direct files:** 
  - `__init__.py` - Empty package initialization file
- **Subdirectories:**
  - `base/` - Abstract base classes for proxy applications and components with common functionality
  - `a2a/` - Concrete implementation for proxying A2A-over-HTTPS agents with authentication support

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Package initialization (empty file)
**Import:** `from solace_agent_mesh.agent.proxies import *`

No public API - this is an empty initialization file.

### Subdirectory APIs

#### base/
**Purpose:** Provides abstract base classes and configuration models for building proxy applications
**Key Exports:** BaseProxyApp, BaseProxyComponent, BaseProxyAppConfig, ProxyTaskContext
**Import Examples:**
```python
from solace_agent_mesh.agent.proxies.base.app import BaseProxyApp
from solace_agent_mesh.agent.proxies.base.component import BaseProxyComponent
from solace_agent_mesh.agent.proxies.base.config import BaseProxyAppConfig, ProxiedAgentConfig
from solace_agent_mesh.agent.proxies.base.proxy_task_context import ProxyTaskContext
```

#### a2a/
**Purpose:** Concrete implementation for proxying A2A-over-HTTPS agents with OAuth 2.0 and static authentication
**Key Exports:** A2AProxyApp, A2AProxyComponent, A2AProxyAppConfig, OAuth2TokenCache
**Import Examples:**
```python
from solace_agent_mesh.agent.proxies.a2a.app import A2AProxyApp
from solace_agent_mesh.agent.proxies.a2a.component import A2AProxyComponent
from solace_agent_mesh.agent.proxies.a2a.config import A2AProxyAppConfig, AuthenticationConfig
from solace_agent_mesh.agent.proxies.a2a.oauth_token_cache import OAuth2TokenCache
```

## Complete Usage Guide

### 1. Creating a Custom Proxy Implementation

To create a new proxy for a different protocol, extend the base classes:

```python
from solace_agent_mesh.agent.proxies.base.app import BaseProxyApp
from solace_agent_mesh.agent.proxies.base.component import BaseProxyComponent
from solace_agent_mesh.agent.proxies.base.config import BaseProxyAppConfig
from a2a.types import AgentCard, A2ARequest
from typing import Optional

# Custom configuration (extend BaseProxyAppConfig)
class MyProxyAppConfig(BaseProxyAppConfig):
    custom_setting: str = "default_value"

# Custom component implementation
class MyProxyComponent(BaseProxyComponent):
    async def _fetch_agent_card(self, agent_config: dict) -> Optional[AgentCard]:
        # Implement protocol-specific agent discovery
        url = agent_config.get("url")
        # Make HTTP request to get agent capabilities
        # Return AgentCard with agent information
        pass
        
    async def _forward_request(self, task_context, request: A2ARequest, agent_name: str):
        # Implement protocol-specific request forwarding
        # Forward request to downstream agent
        # Handle response and publish back to Solace
        pass

# Custom app class
class MyProxyApp(BaseProxyApp):
    def _get_component_class(self):
        return MyProxyComponent
```

### 2. Using the A2A Proxy Implementation

The most common use case is using the built-in A2A proxy:

```python
from solace_agent_mesh.agent.proxies.a2a.app import A2AProxyApp
from solace_agent_mesh.agent.proxies.a2a.config import A2AProxyAppConfig, AuthenticationConfig

# Configuration with OAuth 2.0 authentication
app_info = {
    "app_config": {
        "namespace": "myorg/production",
        "proxied_agents": [
            {
                "name": "external-agent",
                "url": "https://external-agent.example.com",
                "request_timeout_seconds": 120,
                "authentication": {
                    "type": "oauth2_client_credentials",
                    "token_url": "https://auth.example.com/oauth/token",
                    "client_id": "my-client-id",
                    "client_secret": "my-client-secret",
                    "scope": "agent:read agent:write",
                    "token_cache_duration_seconds": 3300
                }
            },
            {
                "name": "api-key-agent", 
                "url": "https://api-agent.example.com",
                "authentication": {
                    "type": "static_bearer",
                    "token": "my-api-key"
                }
            }
        ],
        "artifact_service": {
            "type": "gcs",
            "bucket_name": "my-artifacts-bucket",
            "artifact_scope": "namespace"
        },
        "discovery_interval_seconds": 30,
        "default_request_timeout_seconds": 300
    }
}

# Create and run the proxy app
app = A2AProxyApp(app_info)
# App automatically handles Solace subscriptions and agent discovery
```

### 3. Working with Authentication

The A2A proxy supports multiple authentication methods:

```python
from solace_agent_mesh.agent.proxies.a2a.config import AuthenticationConfig

# OAuth 2.0 Client Credentials
oauth_auth = AuthenticationConfig(
    type="oauth2_client_credentials",
    token_url="https://auth.provider.com/token",
    client_id="client123",
    client_secret="secret456", 
    scope="read write",
    token_cache_duration_seconds=3300  # Cache for 55 minutes
)

# Static Bearer Token
bearer_auth = AuthenticationConfig(
    type="static_bearer",
    token="Bearer abc123xyz"
)

# Static API Key
apikey_auth = AuthenticationConfig(
    type="static_apikey",
    token="api-key-value"
)
```

### 4. Managing OAuth Token Cache

For OAuth 2.0 authentication, tokens are automatically cached:

```python
from solace_agent_mesh.agent.proxies.a2a.oauth_token_cache import OAuth2TokenCache
from solace_agent_mesh.agent.proxies.a2a.component import A2AProxyComponent

# Access the component to manage cache
component = A2AProxyComponent(proxied_agents_config=config)

# Clear all cached tokens (useful for testing or credential rotation)
component.clear_client_cache()

# Direct cache usage (advanced)
cache = OAuth2TokenCache()
await cache.set("agent-name", "access_token", 3600)
token = await cache.get("agent-name")
await cache.invalidate("agent-name")
```

### 5. Task Context and Lifecycle Management

The proxy framework automatically manages task contexts:

```python
from solace_agent_mesh.agent.proxies.base.proxy_task_context import ProxyTaskContext

# Task contexts are created automatically when requests arrive
# They contain A2A protocol information and task state
task_context = ProxyTaskContext(
    task_id="unique-task-id",
    a2a_context={
        "jsonrpc_request_id": "req-123",
        "logical_task_id": "task-456",
        "session_id": "session-789", 
        "user_id": "user123",
        "status_topic": "status/myorg/production/external-agent",
        "reply_to_topic": "reply/myorg/production/external-agent",
        "is_streaming": False
    }
)

# Access task information in custom components
print(f"Handling task: {task_context.task_id}")
print(f"User: {task_context.a2a_context['user_id']}")
```

### 6. Configuration Validation

All proxy configurations use Pydantic for validation:

```python
from solace_agent_mesh.agent.proxies.a2a.config import A2AProxyAppConfig
from pydantic import ValidationError

try:
    config = A2AProxyAppConfig.model_validate({
        "namespace": "myorg/dev",
        "proxied_agents": [
            {
                "name": "test-agent",
                "url": "https://agent.example.com",
                "authentication": {
                    "type": "oauth2_client_credentials",
                    "token_url": "https://auth.example.com/token",
                    "client_id": "client123"
                    # Missing client_secret - will cause validation error
                }
            }
        ]
    })
except ValidationError as e:
    print(f"Configuration error: {e}")
```

### 7. Integration Patterns

Common patterns for integrating proxies into larger applications:

```python
# Pattern 1: Direct instantiation
from solace_agent_mesh.agent.proxies.a2a.app import A2AProxyApp

app = A2AProxyApp(app_info)
# App handles its own lifecycle

# Pattern 2: Component access for advanced control
from solace_agent_mesh.agent.proxies.a2a.component import A2AProxyComponent

component = A2AProxyComponent(
    proxied_agents_config=config["proxied_agents"],
    namespace=config["namespace"],
    # ... other broker settings
)

# Manual lifecycle management
await component.run()
# ... application logic
await component.cleanup()

# Pattern 3: Custom proxy with base classes
class CustomProtocolProxy(BaseProxyComponent):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.custom_clients = {}
    
    async def _fetch_agent_card(self, agent_config):
        # Custom discovery logic
        pass
        
    async def _forward_request(self, task_context, request, agent_name):
        # Custom forwarding logic  
        pass
```

This comprehensive guide covers all the main use cases for the proxies directory, from using the built-in A2A proxy to creating custom proxy implementations for new protocols.

================================================================================

## Section 10: solace_agent_mesh/agent/sac/sac_llm.txt

**Source file:** `solace_agent_mesh/agent/sac/sac_llm.txt`

# DEVELOPER GUIDE for the directory: sac

## Quick Summary
The `sac` (Solace AI Connector) directory provides the core implementation for hosting a Google ADK (Agent Development Kit) agent within the Solace AI Connector framework. It acts as a bridge, enabling ADK agents to communicate using the A2A (Agent-to-Agent) protocol over Solace messaging. This allows for the creation of distributed, collaborative agent systems where agents can delegate tasks, share information, and work together to solve complex problems.

## Files Overview
- `__init__.py` - Empty package marker file
- `app.py` - Custom SAC App class that automatically configures Solace subscriptions and broker settings for A2A communication
- `component.py` - Main SAC Component that hosts the ADK agent, manages its lifecycle, and handles all A2A protocol messaging
- `patch_adk.py` - Runtime patches for the Google ADK library to enhance or correct its behavior
- `task_execution_context.py` - State management class that encapsulates all runtime information for a single, in-flight A2A task

## Developer API Reference

### app.py
**Purpose:** Provides a custom SAC App class that simplifies the configuration of an A2A agent
**Import:** `from solace_agent_mesh.agent.sac.app import SamAgentApp`

**Classes:**
- `SamAgentApp(app_info: Dict[str, Any], **kwargs)` - Custom App class for SAM Agent Host with namespace prefixing and automatic subscription generation
  - `app_schema: Dict` - Class attribute defining comprehensive configuration schema for agent host validation

**Constants/Variables:**
- `info: Dict[str, str]` - Metadata dictionary about the SamAgentApp class for SAC framework discovery

**Usage Examples:**
```python
# SamAgentApp is typically instantiated by the SAC framework from YAML config
# Example agent-config.yaml:
# app:
#   class_name: solace_agent_mesh.agent.sac.app.SamAgentApp
#   app_config:
#     namespace: "my-org/production"
#     agent_name: "customer-support-agent"
#     model: "gemini-1.5-pro-latest"
#     tools:
#       - tool_type: "builtin"
#         tool_name: "file_search"
#     agent_card:
#       description: "An agent that can answer questions about customer accounts."
#     agent_card_publishing:
#       interval_seconds: 60
#     session_service:
#       type: "memory"
```

### component.py
**Purpose:** Core component that hosts a Google ADK agent and bridges communication to A2A protocol
**Import:** `from solace_agent_mesh.agent.sac.component import SamAgentComponent`

**Classes:**
- `SamAgentComponent(**kwargs)` - Solace AI Connector component that hosts a Google ADK agent
  - `process_event(event: Event) -> None` - Main entry point for all SAC framework events
  - `handle_timer_event(timer_data: Dict[str, Any]) -> None` - Handles scheduled timer events for agent card publishing
  - `handle_cache_expiry_event(cache_data: Dict[str, Any]) -> None` - Handles cache expiry events for peer agent timeouts
  - `finalize_task_success(a2a_context: Dict) -> None` - Async method to finalize successful task completion
  - `finalize_task_canceled(a2a_context: Dict) -> None` - Finalizes task as CANCELED
  - `finalize_task_error(exception: Exception, a2a_context: Dict) -> None` - Async method to finalize failed tasks
  - `cleanup() -> None` - Cleans up resources on component shutdown
  - `set_agent_specific_state(key: str, value: Any) -> None` - Sets key-value pair in agent state dictionary
  - `get_agent_specific_state(key: str, default: Optional[Any] = None) -> Any` - Retrieves value from agent state
  - `get_async_loop() -> Optional[asyncio.AbstractEventLoop]` - Returns dedicated asyncio event loop
  - `set_agent_system_instruction_string(instruction_string: str) -> None` - Sets static system prompt injection
  - `set_agent_system_instruction_callback(callback_function: Callable) -> None` - Sets dynamic system prompt callback
  - `get_gateway_id() -> str` - Returns unique identifier for agent host instance
  - `submit_a2a_task(target_agent_name: str, a2a_message: A2AMessage, user_id: str, user_config: Dict[str, Any], sub_task_id: str) -> str` - Submits task to peer agent
  - `get_agent_context() -> Dict[str, Any]` - Returns agent context for middleware interactions

**Constants/Variables:**
- `info: Dict` - Metadata dictionary for SAC framework
- `CORRELATION_DATA_PREFIX: str` - Prefix for cache keys when tracking peer requests
- `HOST_COMPONENT_VERSION: str` - Version string of the host component

**Usage Examples:**
```python
# Custom initialization function example
from solace_agent_mesh.agent.sac.component import SamAgentComponent

def initialize_my_agent(host_component: SamAgentComponent, config: dict):
    """Custom initialization function for the agent."""
    # Store database connection in agent state
    db_connection = create_database_connection(config.get('db_url'))
    host_component.set_agent_specific_state('db_connection', db_connection)
    
    # Set custom system instruction
    host_component.set_agent_system_instruction_string(
        "You are a specialized customer service agent with access to our database."
    )

# Tool accessing agent state
def my_custom_tool(host_component: SamAgentComponent, query: str) -> str:
    """Tool that uses stored database connection."""
    db_connection = host_component.get_agent_specific_state('db_connection')
    if db_connection:
        return db_connection.execute_query(query)
    return "Database not available"

# Scheduling async work from synchronous code
def schedule_background_task(host_component: SamAgentComponent):
    """Schedule async work on the component's event loop."""
    loop = host_component.get_async_loop()
    if loop:
        asyncio.run_coroutine_threadsafe(my_async_task(), loop)
```

### patch_adk.py
**Purpose:** Contains runtime patches for the Google ADK library to enhance behavior
**Import:** `from solace_agent_mesh.agent.sac.patch_adk import patch_adk`

**Functions:**
- `patch_adk() -> None` - Applies all necessary patches to the ADK library

**Usage Examples:**
```python
from solace_agent_mesh.agent.sac.patch_adk import patch_adk

# Apply patches before using ADK
patch_adk()
```

### task_execution_context.py
**Purpose:** State management class for single, in-flight agent tasks
**Import:** `from solace_agent_mesh.agent.sac.task_execution_context import TaskExecutionContext`

**Classes:**
- `TaskExecutionContext(task_id: str, a2a_context: Dict[str, Any])` - Encapsulates runtime state for a single agent task
  - `cancel() -> None` - Signals that the task should be cancelled
  - `is_cancelled() -> bool` - Checks if cancellation event has been set
  - `append_to_streaming_buffer(text: str) -> None` - Appends text to streaming buffer
  - `flush_streaming_buffer() -> str` - Returns and clears streaming buffer content
  - `get_streaming_buffer_content() -> str` - Returns buffer content without clearing
  - `append_to_run_based_buffer(text: str) -> None` - Appends text to run-based response buffer
  - `register_peer_sub_task(sub_task_id: str, correlation_data: Dict[str, Any]) -> None` - Adds peer sub-task tracking
  - `claim_sub_task_completion(sub_task_id: str) -> Optional[Dict[str, Any]]` - Atomically retrieves and removes sub-task data
  - `register_parallel_call_sent(invocation_id: str) -> None` - Registers new parallel tool call
  - `handle_peer_timeout(sub_task_id: str, correlation_data: Dict, timeout_sec: int, invocation_id: str) -> bool` - Handles peer timeout
  - `record_parallel_result(result: Dict, invocation_id: str) -> bool` - Records parallel tool call result
  - `clear_parallel_invocation_state(invocation_id: str) -> None` - Removes completed invocation state
  - `register_produced_artifact(filename: str, version: int) -> None` - Tracks newly created artifacts
  - `add_artifact_signal(signal: Dict[str, Any]) -> None` - Adds artifact return signal
  - `get_and_clear_artifact_signals() -> List[Dict[str, Any]]` - Retrieves and clears artifact signals
  - `set_event_loop(loop: asyncio.AbstractEventLoop) -> None` - Stores event loop reference
  - `get_event_loop() -> Optional[asyncio.AbstractEventLoop]` - Retrieves stored event loop
  - `record_token_usage(input_tokens: int, output_tokens: int, model: str, source: str = "agent", tool_name: Optional[str] = None, cached_input_tokens: int = 0) -> None` - Records token usage for LLM calls
  - `get_token_usage_summary() -> Dict[str, Any]` - Returns summary of all token usage for the task

**Usage Examples:**
```python
from solace_agent_mesh.agent.sac.task_execution_context import TaskExecutionContext

# Create task context
a2a_context = {
    "logical_task_id": "task-123",
    "user_id": "user-456",
    "session_id": "session-789"
}
task_context = TaskExecutionContext("task-123", a2a_context)

# Use streaming buffer
task_context.append_to_streaming_buffer("Hello ")
task_context.append_to_streaming_buffer("world!")
content = task_context.flush_streaming_buffer()  # Returns "Hello world!"

# Track peer sub-tasks
correlation_data = {
    "peer_agent_name": "math-agent",
    "adk_function_call_id": "call-123"
}
task_context.register_peer_sub_task("sub-task-456", correlation_data)

# Handle completion
completed_data = task_context.claim_sub_task_completion("sub-task-456")
if completed_data:
    print(f"Sub-task completed: {completed_data}")

# Track token usage
task_context.record_token_usage(
    input_tokens=100,
    output_tokens=50,
    model="gemini-1.5-pro",
    source="agent"
)

# Get usage summary
usage = task_context.get_token_usage_summary()
print(f"Total tokens used: {usage['total_tokens']}")
```

================================================================================

## Section 11: solace_agent_mesh/agent/testing/testing_llm.txt

**Source file:** `solace_agent_mesh/agent/testing/testing_llm.txt`

## Quick Summary
The `testing` directory provides utilities for testing the A2A (Agent-to-Agent) framework, with a focus on debugging tools that help developers understand test failures by providing readable representations of agent event histories.

## Files Overview
- `__init__.py` - Package initialization file marking the directory as a Python module
- `debug_utils.py` - Debugging utilities including pretty-printing for A2A event history
- `testing_llm.txt` - Documentation file (not a code module)
- `testing_llm_detail.txt` - Concatenated documentation file (not a code module)

## Developer API Reference

### debug_utils.py
**Purpose:** Provides debugging utilities for the declarative test framework, including a pretty-printer for A2A event history
**Import:** `from solace_agent_mesh.agent.testing.debug_utils import pretty_print_event_history`

**Functions:**
- `pretty_print_event_history(event_history: List[Dict[str, Any]], max_string_length: int = 200) -> None` - Formats and prints a list of A2A event payloads for debugging, intelligently parsing different event types and truncating long strings for readability

**Usage Examples:**
```python
# Import the debugging utility
from solace_agent_mesh.agent.testing.debug_utils import pretty_print_event_history
from typing import List, Dict, Any

# Example: Debug a failed test by printing event history
event_history: List[Dict[str, Any]] = [
    {
        "result": {
            "status": {
                "state": "EXECUTING",
                "message": {
                    "parts": [
                        {"type": "text", "text": "Processing your request..."}
                    ]
                }
            },
            "final": False
        }
    },
    {
        "error": {
            "code": "TIMEOUT_ERROR",
            "message": "Request timed out after 30 seconds"
        }
    }
]

# Print formatted event history for debugging
pretty_print_event_history(event_history)

# Print with custom string truncation length
pretty_print_event_history(event_history, max_string_length=100)

# Handle empty event history (when test fails before any events)
pretty_print_event_history([])
```

================================================================================

## Section 12: solace_agent_mesh/agent/tools/tools_llm.txt

**Source file:** `solace_agent_mesh/agent/tools/tools_llm.txt`

# DEVELOPER GUIDE for tools

## Quick Summary
The `tools` directory contains the complete tool system for the Solace Agent Mesh, providing built-in tools for artifact management, data analysis, audio processing, image generation, web scraping, and dynamic tool creation. It includes a registry system for tool discovery and management, with support for declarative YAML-based configurations and multiple tool types including built-in, custom Python, and MCP tools.

## Files Overview
- `__init__.py` - Imports all tool modules to trigger registration
- `audio_tools.py` - Text-to-speech, transcription, and audio manipulation tools
- `builtin_artifact_tools.py` - Core artifact management (CRUD operations, metadata handling)
- `builtin_data_analysis_tools.py` - Data visualization and chart generation tools
- `dynamic_tool.py` - Base classes for creating custom dynamic tools
- `general_agent_tools.py` - General purpose tools (file conversion, diagram generation)
- `image_tools.py` - Image generation, editing, and multimodal analysis tools
- `peer_agent_tool.py` - Tool for delegating tasks to other agents
- `registry.py` - Singleton registry for tool discovery and management
- `test_tools.py` - Testing and debugging utilities for timeouts and error handling
- `tool_config_types.py` - Pydantic models for YAML-based tool configurations
- `tool_definition.py` - Base tool definition classes and structures
- `web_tools.py` - Web scraping and content extraction tools

## Developer API Reference

### __init__.py
**Purpose:** Ensures all tool modules are imported to trigger registration
**Import:** `from solace_agent_mesh.agent.tools import *`

### audio_tools.py
**Purpose:** Audio processing, text-to-speech, and transcription capabilities
**Import:** `from solace_agent_mesh.agent.tools.audio_tools import select_voice, text_to_speech, multi_speaker_text_to_speech, concatenate_audio, transcribe_audio`

**Functions:**
- `select_voice(gender: Optional[str] = None, tone: Optional[str] = None, exclude_voices: Optional[List[str]] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Selects a suitable voice based on criteria
- `text_to_speech(text: str, output_filename: Optional[str] = None, voice_name: Optional[str] = None, gender: Optional[str] = None, tone: Optional[str] = None, language: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Converts text to speech using Gemini TTS
- `multi_speaker_text_to_speech(conversation_text: str, output_filename: Optional[str] = None, speaker_configs: Optional[List[Dict[str, str]]] = None, language: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Multi-speaker TTS for conversations
- `concatenate_audio(clips_to_join: List[Dict[str, Any]], output_filename: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Combines multiple audio clips
- `transcribe_audio(audio_filename: str, output_filename: Optional[str] = None, description: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Transcribes audio to text

**Constants/Variables:**
- `ALL_AVAILABLE_VOICES: List[str]` - List of all available TTS voices
- `SUPPORTED_LANGUAGES: Dict[str, str]` - Mapping of language names to BCP-47 codes
- `VOICE_TONE_MAPPING: Dict[str, List[str]]` - Maps tones to voice names
- `GENDER_TO_VOICE_MAPPING: Dict[str, List[str]]` - Maps genders to voice names

**Usage Examples:**
```python
# Select a voice
result = await select_voice(gender="female", tone="friendly")
voice_name = result["voice_name"]

# Generate speech
result = await text_to_speech(
    text="Hello world",
    voice_name=voice_name,
    tool_context=context
)

# Multi-speaker conversation
conversation = "Speaker1: Hello\nSpeaker2: Hi there"
result = await multi_speaker_text_to_speech(
    conversation_text=conversation,
    speaker_configs=[
        {"name": "Speaker1", "gender": "female", "tone": "friendly"},
        {"name": "Speaker2", "gender": "male", "tone": "professional"}
    ],
    tool_context=context
)
```

### builtin_artifact_tools.py
**Purpose:** Core artifact management operations (CRUD, metadata, embeds)
**Import:** `from solace_agent_mesh.agent.tools.builtin_artifact_tools import list_artifacts, load_artifact, append_to_artifact, apply_embed_and_create_artifact, extract_content_from_artifact, delete_artifact`

**Functions:**
- `list_artifacts(tool_context: ToolContext = None) -> Dict[str, Any]` - Lists all artifacts with metadata summaries
- `load_artifact(filename: str, version: int, load_metadata_only: bool = False, max_content_length: Optional[int] = None, tool_context: ToolContext = None) -> Dict[str, Any]` - Loads artifact content or metadata
- `append_to_artifact(filename: str, content_chunk: str, mime_type: str, tool_context: ToolContext = None) -> Dict[str, Any]` - Appends content to existing artifact
- `apply_embed_and_create_artifact(output_filename: str, embed_directive: str, output_metadata: Optional[Dict[str, Any]] = None, tool_context: ToolContext = None) -> Dict[str, Any]` - Resolves embed directives and creates artifacts
- `extract_content_from_artifact(filename: str, extraction_goal: str, version: Optional[str] = "latest", output_filename_base: Optional[str] = None, tool_context: ToolContext = None) -> Dict[str, Any]` - Uses LLM to extract/transform artifact content
- `delete_artifact(filename: str, version: Optional[int] = None, tool_context: ToolContext = None) -> Dict[str, Any]` - Deletes artifact versions

**Usage Examples:**
```python
# List all artifacts
artifacts = await list_artifacts(tool_context=context)

# Load specific artifact
content = await load_artifact(
    filename="data.json",
    version=1,
    tool_context=context
)

# Extract content using LLM
result = await extract_content_from_artifact(
    filename="report.pdf",
    extraction_goal="Extract all financial figures and create a summary table",
    tool_context=context
)
```

### builtin_data_analysis_tools.py
**Purpose:** Data visualization and chart generation
**Import:** `from solace_agent_mesh.agent.tools.builtin_data_analysis_tools import create_chart_from_plotly_config`

**Functions:**
- `create_chart_from_plotly_config(config_content: str, config_format: Literal["json", "yaml"], output_filename: str, output_format: Optional[str] = "png", tool_context: ToolContext = None) -> Dict[str, Any]` - Creates charts from Plotly configurations

**Usage Examples:**
```python
# Create chart from JSON config
plotly_config = '{"data": [{"x": [1,2,3], "y": [4,5,6], "type": "scatter"}], "layout": {"title": "Sample Chart"}}'
result = await create_chart_from_plotly_config(
    config_content=plotly_config,
    config_format="json",
    output_filename="my_chart.png",
    tool_context=context
)
```

### dynamic_tool.py
**Purpose:** Base classes for creating custom dynamic tools
**Import:** `from solace_agent_mesh.agent.tools.dynamic_tool import DynamicTool, DynamicToolProvider`

**Classes:**
- `DynamicTool(tool_config: Optional[Union[dict, BaseModel]] = None)` - Base class for programmatic tools
  - `tool_name: str` - Property returning the function name
  - `tool_description: str` - Property returning tool description
  - `parameters_schema: adk_types.Schema` - Property returning parameter schema
  - `raw_string_args: List[str]` - Property listing args to skip embed resolution
  - `resolution_type: Literal["early", "all"]` - Property controlling embed resolution
  - `_run_async_impl(args: dict, tool_context: ToolContext, credential: Optional[str] = None) -> dict` - Abstract method to implement tool logic

- `DynamicToolProvider()` - Base class for tool providers
  - `register_tool(func: Callable) -> Callable` - Class method decorator for registering tools
  - `create_tools(tool_config: Optional[Union[dict, BaseModel]] = None) -> List[DynamicTool]` - Abstract method to create custom tools

**Usage Examples:**
```python
# Create a custom dynamic tool
class MyCustomTool(DynamicTool):
    @property
    def tool_name(self) -> str:
        return "my_custom_tool"
    
    @property
    def tool_description(self) -> str:
        return "Does something custom"
    
    @property
    def parameters_schema(self) -> adk_types.Schema:
        return adk_types.Schema(
            type=adk_types.Type.OBJECT,
            properties={
                "input": adk_types.Schema(type=adk_types.Type.STRING)
            },
            required=["input"]
        )
    
    async def _run_async_impl(self, args: dict, tool_context: ToolContext, credential: Optional[str] = None) -> dict:
        return {"result": f"Processed: {args['input']}"}

# Create a tool provider
class MyToolProvider(DynamicToolProvider):
    @DynamicToolProvider.register_tool
    async def my_decorated_tool(self, message: str, tool_context: ToolContext = None) -> dict:
        """A tool created via decorator."""
        return {"response": f"Hello {message}"}
    
    def create_tools(self, tool_config: Optional[Union[dict, BaseModel]] = None) -> List[DynamicTool]:
        return [MyCustomTool(tool_config)]
```

### general_agent_tools.py
**Purpose:** General purpose utility tools
**Import:** `from solace_agent_mesh.agent.tools.general_agent_tools import convert_file_to_markdown, mermaid_diagram_generator`

**Functions:**
- `convert_file_to_markdown(input_filename: str, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Converts files to Markdown using MarkItDown
- `mermaid_diagram_generator(mermaid_syntax: str, output_filename: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Generates PNG diagrams from Mermaid syntax

**Usage Examples:**
```python
# Convert PDF to Markdown
result = await convert_file_to_markdown(
    input_filename="document.pdf",
    tool_context=context
)

# Generate Mermaid diagram
mermaid_code = """
graph TD
    A[Start] --> B[Process]
    B --> C[End]
"""
result = await mermaid_diagram_generator(
    mermaid_syntax=mermaid_code,
    output_filename="flowchart.png",
    tool_context=context
)
```

### image_tools.py
**Purpose:** Image generation, editing, and multimodal analysis
**Import:** `from solace_agent_mesh.agent.tools.image_tools import create_image_from_description, describe_image, describe_audio, edit_image_with_gemini`

**Functions:**
- `create_image_from_description(image_description: str, output_filename: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Generates images from text descriptions
- `describe_image(image_filename: str, prompt: str = "What is in this image?", tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Describes images using vision API
- `describe_audio(audio_filename: str, prompt: str = "What is in this recording?", tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Describes audio using multimodal API
- `edit_image_with_gemini(image_filename: str, edit_prompt: str, output_filename: Optional[str] = None, tool_context: ToolContext = None, tool_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]` - Edits images using Gemini

**Usage Examples:**
```python
# Generate image
result = await create_image_from_description(
    image_description="A sunset over mountains",
    output_filename="sunset.png",
    tool_context=context
)

# Describe image
result = await describe_image(
    image_filename="photo.jpg",
    prompt="What objects are in this image?",
    tool_context=context
)

# Edit image
result = await edit_image_with_gemini(
    image_filename="original.jpg",
    edit_prompt="Add a rainbow in the sky",
    tool_context=context
)
```

### peer_agent_tool.py
**Purpose:** Tool for delegating tasks to other agents in the mesh
**Import:** `from solace_agent_mesh.agent.tools.peer_agent_tool import PeerAgentTool`

**Classes:**
- `PeerAgentTool(target_agent_name: str, host_component)` - Tool for peer agent communication
  - `target_agent_name: str` - Name of the target agent
  - `host_component` - Reference to the host component
  - `run_async(*, args: Dict[str, Any], tool_context: ToolContext) -> Any` - Delegates task to peer agent

**Usage Examples:**
```python
# Create peer tool (typically done automatically)
peer_tool = PeerAgentTool("data_analyst_agent", host_component)

# Use via ADK (the tool is registered automatically)
# The LLM would call: peer_data_analyst_agent(task_description="Analyze sales data", artifacts=[{"filename": "sales.csv"}])
```

### registry.py
**Purpose:** Singleton registry for tool discovery and management
**Import:** `from solace_agent_mesh.agent.tools.registry import tool_registry`

**Classes:**
- `_ToolRegistry()` - Singleton registry for tools
  - `register(tool: BuiltinTool)` - Registers a tool
  - `get_tool_by_name(name: str) -> Optional[BuiltinTool]` - Gets tool by name
  - `get_tools_by_category(category_name: str) -> List[BuiltinTool]` - Gets tools by category
  - `get_all_tools() -> List[BuiltinTool]` - Gets all registered tools
  - `clear()` - Clears registry (testing only)

**Constants/Variables:**
- `tool_registry: _ToolRegistry` - Global singleton instance

**Usage Examples:**
```python
from solace_agent_mesh.agent.tools.registry import tool_registry

# Register a tool

================================================================================

## Section 13: solace_agent_mesh/agent/utils/utils_llm.txt

**Source file:** `solace_agent_mesh/agent/utils/utils_llm.txt`

## Quick Summary
The `utils` directory provides a collection of helper modules designed to support the core functionality of the agent. These utilities encapsulate common, reusable logic for tasks such as artifact management (saving, loading, schema inference), configuration parsing, and safe interaction with the ADK's invocation context.

## Files Overview
- `__init__.py` - Empty package marker file
- `artifact_helpers.py` - Comprehensive artifact management functions including save/load operations, metadata handling, and schema inference
- `config_parser.py` - Configuration parsing utilities for resolving instruction providers
- `context_helpers.py` - Safe utilities for extracting data from ADK callback and invocation contexts

## Developer API Reference

### artifact_helpers.py
**Purpose:** Comprehensive artifact management with automatic metadata generation, schema inference, and async operations
**Import:** `from solace_agent_mesh.agent.utils.artifact_helpers import save_artifact_with_metadata, load_artifact_content_or_metadata, get_artifact_info_list, is_filename_safe, ensure_correct_extension`

**Functions:**
- `is_filename_safe(filename: str) -> bool` - Validates filename safety (no path traversal, separators, or reserved names)
- `ensure_correct_extension(filename_from_llm: str, desired_extension: str) -> str` - Ensures filename has correct extension
- `format_artifact_uri(app_name: str, user_id: str, session_id: str, filename: str, version: Union[int, str]) -> str` - Formats components into standard artifact:// URI
- `parse_artifact_uri(uri: str) -> Dict[str, Any]` - Parses artifact:// URI into constituent parts
- `save_artifact_with_metadata(artifact_service: BaseArtifactService, app_name: str, user_id: str, session_id: str, filename: str, content_bytes: bytes, mime_type: str, metadata_dict: Dict[str, Any], timestamp: datetime, explicit_schema: Optional[Dict] = None, schema_inference_depth: int = 2, schema_max_keys: int = 20, tool_context: Optional["ToolContext"] = None) -> Dict[str, Any]` - Saves artifact with auto-generated metadata and schema inference
- `load_artifact_content_or_metadata(artifact_service: BaseArtifactService, app_name: str, user_id: str, session_id: str, filename: str, version: Union[int, str], load_metadata_only: bool = False, return_raw_bytes: bool = False, max_content_length: Optional[int] = None, component: Optional[Any] = None, log_identifier_prefix: str = "[ArtifactHelper:load]", encoding: str = "utf-8", error_handling: str = "strict") -> Dict[str, Any]` - Loads artifact content or metadata with flexible options
- `get_artifact_info_list(artifact_service: BaseArtifactService, app_name: str, user_id: str, session_id: str) -> List[ArtifactInfo]` - Retrieves detailed info for all artifacts
- `get_latest_artifact_version(artifact_service: BaseArtifactService, app_name: str, user_id: str, session_id: str, filename: str) -> Optional[int]` - Gets latest version number for an artifact
- `format_metadata_for_llm(metadata: Dict[str, Any]) -> str` - Formats metadata into LLM-friendly text
- `decode_and_get_bytes(content_str: str, mime_type: str, log_identifier: str) -> Tuple[bytes, str]` - Decodes content based on MIME type (base64 for binary, UTF-8 for text)
- `generate_artifact_metadata_summary(component: "SamAgentComponent", artifact_identifiers: List[Dict[str, Any]], user_id: str, session_id: str, app_name: str, header_text: Optional[str] = None) -> str` - Generates YAML summary of multiple artifacts' metadata
- `process_artifact_upload(artifact_service: BaseArtifactService, component: Any, user_id: str, session_id: str, filename: str, content_bytes: bytes, mime_type: str, metadata_json: Optional[str] = None, log_prefix: str = "[ArtifactUpload]") -> Dict[str, Any]` - Common logic for processing artifact uploads with validation and storage

**Constants/Variables:**
- `METADATA_SUFFIX: str` - Suffix for metadata files (".metadata.json")
- `DEFAULT_SCHEMA_MAX_KEYS: int` - Default max keys for schema inference (20)

**Usage Examples:**
```python
import asyncio
from datetime import datetime, timezone
from solace_agent_mesh.agent.utils.artifact_helpers import (
    save_artifact_with_metadata,
    load_artifact_content_or_metadata,
    get_artifact_info_list,
    ensure_correct_extension,
    format_artifact_uri,
    parse_artifact_uri,
    process_artifact_upload
)

async def artifact_example():
    # Ensure safe filename
    safe_name = ensure_correct_extension("report", "csv")  # -> "report.csv"
    
    # Save artifact with metadata
    csv_data = b"name,age\nAlice,30\nBob,25"
    result = await save_artifact_with_metadata(
        artifact_service=service,
        app_name="my_app",
        user_id="user123",
        session_id="session456",
        filename=safe_name,
        content_bytes=csv_data,
        mime_type="text/csv",
        metadata_dict={"source": "user_upload", "description": "Employee data"},
        timestamp=datetime.now(timezone.utc)
    )
    
    # Process artifact upload (higher-level function)
    upload_result = await process_artifact_upload(
        artifact_service=service,
        component=component,
        user_id="user123",
        session_id="session456",
        filename="data.csv",
        content_bytes=csv_data,
        mime_type="text/csv",
        metadata_json='{"description": "Uploaded data"}'
    )
    
    # Load artifact content
    loaded = await load_artifact_content_or_metadata(
        artifact_service=service,
        app_name="my_app",
        user_id="user123", 
        session_id="session456",
        filename=safe_name,
        version="latest"
    )
    
    # Work with artifact URIs
    uri = format_artifact_uri("my_app", "user123", "session456", "report.csv", 1)
    # Returns: "artifact://my_app/user123/session456/report.csv?version=1"
    
    parsed = parse_artifact_uri(uri)
    # Returns: {"app_name": "my_app", "user_id": "user123", ...}
    
    # List all artifacts
    artifacts = await get_artifact_info_list(
        artifact_service=service,
        app_name="my_app",
        user_id="user123",
        session_id="session456"
    )
```

### config_parser.py
**Purpose:** Resolves configuration values that can be static strings or dynamic callable providers
**Import:** `from solace_agent_mesh.agent.utils.config_parser import resolve_instruction_provider, InstructionProvider`

**Functions:**
- `resolve_instruction_provider(component, config_value: Any) -> Union[str, InstructionProvider]` - Resolves instruction config from string or invoke block

**Usage Examples:**
```python
from solace_agent_mesh.agent.utils.config_parser import resolve_instruction_provider

# Static string instruction
instruction = resolve_instruction_provider(component, "You are a helpful assistant.")
# Returns: "You are a helpful assistant."

# Dynamic instruction provider (from YAML invoke block)
def dynamic_instruction(context):
    return f"Assistant for {context.user_id}"

instruction_func = resolve_instruction_provider(component, dynamic_instruction)
# Returns: the callable function
```

### context_helpers.py
**Purpose:** Safe utilities for extracting information from ADK contexts
**Import:** `from solace_agent_mesh.agent.utils.context_helpers import get_session_from_callback_context, get_original_session_id`

**Functions:**
- `get_session_from_callback_context(callback_context: CallbackContext) -> Session` - Safely extracts Session object from CallbackContext
- `get_original_session_id(invocation_context: Any) -> str` - Extracts base session ID, removing any colon-separated suffixes

**Usage Examples:**
```python
from solace_agent_mesh.agent.utils.context_helpers import (
    get_session_from_callback_context,
    get_original_session_id
)

# In a tool function with callback_context
def my_tool(callback_context):
    # Get full session object
    session = get_session_from_callback_context(callback_context)
    
    # Get original session ID (strips suffixes after colon)
    original_id = get_original_session_id(tool_context._invocation_context)
    # "session123:tool456" -> "session123"
```

================================================================================

## Section 14: solace_agent_mesh/common/a2a/a2a_llm.txt

**Source file:** `solace_agent_mesh/common/a2a/a2a_llm.txt`

# DEVELOPER GUIDE: a2a

## Quick Summary
The `a2a` directory provides a comprehensive abstraction layer for the A2A (Agent-to-Agent) protocol, offering helper functions for creating, consuming, and translating A2A protocol objects. It acts as a facade that insulates applications from the specifics of the underlying a2a-sdk, providing simplified interfaces for messages, artifacts, tasks, events, and protocol-level operations.

## Files Overview
- `__init__.py` - Main entry point exposing all commonly used A2A helpers
- `artifact.py` - Helpers for creating and consuming A2A Artifact objects
- `events.py` - Helpers for creating and consuming A2A asynchronous event objects
- `message.py` - Helpers for creating and consuming A2A Message and Part objects
- `protocol.py` - Helpers for A2A protocol-level concerns like topic construction and JSON-RPC
- `task.py` - Helpers for creating and consuming A2A Task objects
- `translation.py` - Helpers for translating between A2A protocol objects and other domains
- `types.py` - Custom type aliases and models for the A2A helper layer

## Developer API Reference

### __init__.py
**Purpose:** Main entry point that exposes all commonly used A2A helpers for easy access
**Import:** `from solace_agent_mesh.common.a2a import *`

This file re-exports all public functions from the other modules, allowing developers to import everything from the main package.

### artifact.py
**Purpose:** Provides helpers for creating and consuming A2A Artifact objects
**Import:** `from solace_agent_mesh.common.a2a.artifact import create_text_artifact, create_data_artifact, get_artifact_id`

**Functions:**
- `create_text_artifact(name: str, text: str, description: str = "", artifact_id: Optional[str] = None) -> Artifact` - Creates a new Artifact containing a single TextPart
- `create_data_artifact(name: str, data: dict[str, Any], description: str = "", artifact_id: Optional[str] = None) -> Artifact` - Creates a new Artifact containing a single DataPart
- `update_artifact_parts(artifact: Artifact, new_parts: List[ContentPart]) -> Artifact` - Returns a new Artifact with replaced parts
- `prepare_file_part_for_publishing(part: FilePart, mode: str, artifact_service: "BaseArtifactService", user_id: str, session_id: str, target_agent_name: str, log_identifier: str) -> Optional[FilePart]` - Prepares a FilePart for publishing based on the artifact handling mode
- `resolve_file_part_uri(part: FilePart, artifact_service: "BaseArtifactService", log_identifier: str) -> FilePart` - Resolves an artifact URI within a FilePart into embedded bytes
- `get_artifact_id(artifact: Artifact) -> str` - Safely retrieves the ID from an Artifact
- `get_artifact_name(artifact: Artifact) -> Optional[str]` - Safely retrieves the name from an Artifact
- `get_parts_from_artifact(artifact: Artifact) -> List[ContentPart]` - Extracts unwrapped content parts from an Artifact
- `is_text_only_artifact(artifact: Artifact) -> bool` - Checks if an artifact contains only TextParts
- `get_text_content_from_artifact(artifact: Artifact) -> List[str]` - Extracts all text content from TextParts in an artifact

**Usage Examples:**
```python
from solace_agent_mesh.common.a2a.artifact import create_text_artifact, get_artifact_id

# Create a text artifact
artifact = create_text_artifact(
    name="My Document",
    text="This is the content of my document",
    description="A sample text document"
)

# Get artifact ID
artifact_id = get_artifact_id(artifact)
```

### events.py
**Purpose:** Provides helpers for creating and consuming A2A asynchronous event objects
**Import:** `from solace_agent_mesh.common.a2a.events import create_status_update, create_artifact_update`

**Functions:**
- `create_data_signal_event(task_id: str, context_id: str, signal_data: SignalData, agent_name: str, part_metadata: Optional[Dict[str, Any]] = None) -> TaskStatusUpdateEvent` - Creates a TaskStatusUpdateEvent from signal data
- `create_status_update(task_id: str, context_id: str, message: Message, is_final: bool = False, metadata: Optional[Dict[str, Any]] = None) -> TaskStatusUpdateEvent` - Creates a new TaskStatusUpdateEvent
- `create_artifact_update(task_id: str, context_id: str, artifact: Artifact, append: bool = False, last_chunk: bool = False, metadata: Optional[Dict[str, Any]] = None) -> TaskArtifactUpdateEvent` - Creates a new TaskArtifactUpdateEvent
- `get_message_from_status_update(event: TaskStatusUpdateEvent) -> Optional[Message]` - Extracts Message from TaskStatusUpdateEvent
- `get_data_parts_from_status_update(event: TaskStatusUpdateEvent) -> List[DataPart]` - Extracts DataPart objects from status update
- `get_artifact_from_artifact_update(event: TaskArtifactUpdateEvent) -> Optional[Artifact]` - Extracts Artifact from TaskArtifactUpdateEvent
- `is_task_status_update(obj: Any) -> bool` - Checks if an object is a TaskStatusUpdateEvent
- `is_task_artifact_update(obj: Any) -> bool` - Checks if an object is a TaskArtifactUpdateEvent

**Usage Examples:**
```python
from solace_agent_mesh.common.a2a.events import create_status_update
from solace_agent_mesh.common.a2a.message import create_agent_text_message

# Create a status update event
message = create_agent_text_message("Processing your request...")
status_event = create_status_update(
    task_id="task-123",
    context_id="context-456",
    message=message,
    is_final=False
)
```

### message.py
**Purpose:** Provides helpers for creating and consuming A2A Message and Part objects
**Import:** `from solace_agent_mesh.common.a2a.message import create_agent_text_message, create_text_part, get_text_from_message`

**Functions:**
- `create_agent_text_message(text: str, task_id: Optional[str] = None, context_id: Optional[str] = None, message_id: Optional[str] = None) -> Message` - Creates agent message with TextPart
- `create_agent_data_message(data: dict[str, Any], task_id: Optional[str] = None, context_id: Optional[str] = None, message_id: Optional[str] = None, part_metadata: Optional[Dict[str, Any]] = None) -> Message` - Creates agent message with DataPart
- `create_agent_parts_message(parts: List[ContentPart], task_id: Optional[str] = None, context_id: Optional[str] = None, message_id: Optional[str] = None, metadata: Optional[Dict[str, Any]] = None) -> Message` - Creates agent message with multiple parts
- `create_user_message(parts: List[ContentPart], task_id: Optional[str] = None, context_id: Optional[str] = None, message_id: Optional[str] = None, metadata: Optional[Dict[str, Any]] = None) -> Message` - Creates user message with multiple parts
- `create_text_part(text: str, metadata: Optional[Dict[str, Any]] = None) -> TextPart` - Creates a TextPart object
- `create_file_part_from_uri(uri: str, name: Optional[str] = None, mime_type: Optional[str] = None, metadata: Optional[Dict[str, Any]] = None) -> FilePart` - Creates FilePart from URI
- `create_file_part_from_bytes(content_bytes: bytes, name: Optional[str] = None, mime_type: Optional[str] = None, metadata: Optional[Dict[str, Any]] = None) -> FilePart` - Creates FilePart from bytes
- `create_data_part(data: Dict[str, Any], metadata: Optional[Dict[str, Any]] = None) -> DataPart` - Creates a DataPart object
- `update_message_parts(message: Message, new_parts: List[ContentPart]) -> Message` - Returns a new Message with replaced parts
- `get_text_from_message(message: Message, delimiter: str = "\n") -> str` - Extracts and joins all text content from Message
- `get_data_parts_from_message(message: Message) -> List[DataPart]` - Extracts DataPart objects from Message
- `get_file_parts_from_message(message: Message) -> List[FilePart]` - Extracts FilePart objects from Message
- `get_message_id(message: Message) -> str` - Gets message ID
- `get_context_id(message: Message) -> Optional[str]` - Gets context ID
- `get_task_id(message: Message) -> Optional[str]` - Gets task ID
- `get_parts_from_message(message: Message) -> List[ContentPart]` - Extracts unwrapped content parts from Message
- `get_text_from_text_part(part: TextPart) -> str` - Gets text from TextPart
- `get_data_from_data_part(part: DataPart) -> Dict[str, Any]` - Gets data from DataPart
- `get_metadata_from_part(part: ContentPart) -> Optional[Dict[str, Any]]` - Gets metadata from any Part
- `get_file_from_file_part(part: FilePart) -> Optional[Union[FileWithUri, FileWithBytes]]` - Gets File object from FilePart
- `get_uri_from_file_part(part: FilePart) -> Optional[str]` - Gets URI from FilePart
- `get_bytes_from_file_part(part: FilePart) -> Optional[bytes]` - Gets decoded bytes from FilePart
- `get_filename_from_file_part(part: FilePart) -> Optional[str]` - Gets filename from FilePart
- `get_mimetype_from_file_part(part: FilePart) -> Optional[str]` - Gets MIME type from FilePart
- `is_text_part(part: Part) -> bool` - Checks if a Part contains a TextPart
- `is_file_part(part: Part) -> bool` - Checks if a Part contains a FilePart
- `is_data_part(part: Part) -> bool` - Checks if a Part contains a DataPart
- `is_file_part_bytes(part: FilePart) -> bool` - Checks if a FilePart uses FileWithBytes
- `is_file_part_uri(part: FilePart) -> bool` - Checks if a FilePart uses FileWithUri

**Usage Examples:**
```python
from solace_agent_mesh.common.a2a.message import create_agent_text_message, create_text_part, create_user_message

# Create a simple text message
message = create_agent_text_message(
    text="Hello, how can I help you?",
    task_id="task-123",
    context_id="context-456"
)

# Create a user message with multiple parts
text_part = create_text_part("Please analyze this data:")
data_part = create_data_part({"values": [1, 2, 3, 4, 5]})
user_message = create_user_message(
    parts=[text_part, data_part],
    task_id="task-123"
)
```

### protocol.py
**Purpose:** Provides helpers for A2A protocol-level concerns like topic construction and JSON-RPC
**Import:** `from solace_agent_mesh.common.a2a.protocol import get_agent_request_topic, create_send_message_request`

**Constants/Variables:**
- `A2A_VERSION: str` - Current A2A protocol version ("v1")
- `A2A_BASE_PATH: str` - Base path for A2A topics ("a2a/v1")

**Functions:**
- `get_a2a_base_topic(namespace: str) -> str` - Returns base topic prefix for A2A communication
- `get_discovery_topic(namespace: str) -> str` - Returns topic for agent card discovery
- `get_agent_request_topic(namespace: str, agent_name: str) -> str` - Returns topic for sending requests to specific agent
- `get_gateway_status_topic(namespace: str, gateway_id: str, task_id: str) -> str` - Returns topic for publishing status updates to gateway
- `get_gateway_response_topic(namespace: str, gateway_id: str, task_id: str) -> str` - Returns topic for publishing final response to gateway
- `get_gateway_status_subscription_topic(namespace: str, self_gateway_id: str) -> str` - Returns wildcard topic for gateway to receive status updates
- `get_gateway_response_subscription_topic(namespace: str, self_gateway_id: str) -> str` - Returns wildcard topic for gateway to receive responses
- `get_peer_agent_status_topic(namespace: str, delegating_agent_name: str, sub_task_id: str) -> str` - Returns topic for publishing status to delegating agent
- `get_agent_response_topic(namespace: str, delegating_agent_name: str, sub_task_id: str) -> str` - Returns topic for publishing response to delegating agent
- `get_agent_response_subscription_topic(namespace: str, self_agent_name: str) -> str` - Returns wildcard topic for agent to receive responses
- `get_agent_status_subscription_topic(namespace: str, self_agent_name: str) -> str` - Returns wildcard topic for agent to receive status updates
- `get_client_response_topic(namespace: str, client_id: str) -> str` - Returns topic for publishing response to client
- `get_client_status_topic(namespace: str, client_id: str, task_id: str) -> str` - Returns topic for publishing status to client
- `get_client_status_subscription_topic(namespace: str, client_id: str) -> str` - Returns wildcard topic for client to receive status
- `get_sam_events_topic(namespace: str, category: str, action: str) -> str` - Returns SAM system events topic
- `get_sam_events_subscription_topic(namespace: str, category: str) -> str` - Returns SAM system events subscription topic
- `create_send_message_request(message: Message, task_id: str, metadata: Optional[Dict[str, Any]] = None) -> SendMessageRequest` - Creates SendMessageRequest object
- `create_send_streaming_message_request(message: Message, task_id: str, metadata: Optional[Dict[str, Any]] = None) -> SendStreamingMessageRequest` - Creates SendStreamingMessageRequest object
- `create_success_response(result: Any, request_id: Optional[Union[str, int]]) -> JSONRPCResponse` - Creates successful JSON-RPC response
- `create_internal_error_response(message: str, request_id: Optional[Union[str, int]], data: Optional[Dict[str, Any]] = None) -> JSONRPCResponse` - Creates internal error response
- `create_invalid_request_error_response(message: str, request_id: Optional[Union[str, int]], data: Optional[Any] = None) -> JSONRPCResponse` - Creates invalid request error response
- `create_cancel_task_request(task_id: str) -> CancelTaskRequest` - Creates CancelTaskRequest object
- `get_request_id(request: A2ARequest) -> str | int` - Gets JSON-RPC request ID
- `get_request_method(request: A2ARequest) -> str` - Gets JSON-RPC method name
- `get_message_from_send_request(request: A2ARequest) -> Optional[Message]` - Gets Message from send request
- `

================================================================================

## Section 15: solace_agent_mesh/common/a2a_spec/a2a_spec_llm.txt

**Source file:** `solace_agent_mesh/common/a2a_spec/a2a_spec_llm.txt`

# DEVELOPER GUIDE: a2a_spec

## Quick Summary
The `a2a_spec` directory contains the complete Agent-to-Agent (A2A) communication specification for the Solace Agent Mesh. It includes the main JSON schema definition (`a2a.json`) that defines all data structures, request/response types, and error codes for agent communication, plus a `schemas/` subdirectory containing specialized validation schemas for various agent signals and progress updates. Together, these provide a comprehensive framework for validating and implementing compliant agent-to-agent communication.

## Files and Subdirectories Overview
- **Direct files:**
  - `a2a.json` - Complete JSON Schema specification for A2A protocol including all data types, requests, responses, and error definitions
  - `a2a_spec_llm.txt` - Developer guide documentation for the A2A specification
  - `a2a_spec_llm_detail.txt` - Concatenated detailed documentation from all subdirectories
- **Subdirectories:**
  - `schemas/` - JSON Schema definitions for agent communication signals (progress updates, tool invocations, LLM calls, artifact creation)

## Developer API Reference

### Direct Files

#### a2a.json
**Purpose:** Complete JSON Schema specification defining the Agent-to-Agent communication protocol
**Import:** This is a JSON Schema file, typically loaded for validation purposes

**Key Schema Definitions:**
- **AgentCard** - Self-describing manifest for agents with capabilities, skills, and endpoints
- **Message** - Individual messages in agent conversations with parts (text, files, data)
- **Task** - Stateful operations/conversations between clients and agents
- **A2ARequest/A2AResponse** - All supported JSON-RPC request and response types
- **Security Schemes** - OAuth2, API Key, mTLS, and other authentication methods
- **Error Types** - Standard JSON-RPC and A2A-specific error definitions

**Core Data Structures:**
```typescript
// Agent Card - describes agent capabilities
AgentCard {
  name: string
  description: string
  url: string
  skills: AgentSkill[]
  capabilities: AgentCapabilities
  security: SecurityRequirement[]
  // ... additional fields
}

// Message - conversation content
Message {
  messageId: string
  role: "user" | "agent"
  parts: Part[] // TextPart | FilePart | DataPart
  taskId?: string
  contextId?: string
}

// Task - stateful operation
Task {
  id: string
  contextId: string
  status: TaskStatus
  history?: Message[]
  artifacts?: Artifact[]
}
```

#### a2a_spec_llm.txt
**Purpose:** Developer documentation and usage guide for the A2A specification
**Import:** Documentation file for reference

#### a2a_spec_llm_detail.txt
**Purpose:** Comprehensive documentation combining all subdirectory guides
**Import:** Documentation file for reference

### Subdirectory APIs

#### schemas/
**Purpose:** Provides JSON Schema definitions for agent communication signals and progress updates
**Key Exports:** Schema definitions for progress tracking, tool invocations, LLM calls, and artifact creation
**Import Examples:**
```python
import json
from jsonschema import validate

# Load and use schemas for validation
with open('solace_agent_mesh/common/a2a_spec/schemas/agent_progress_update.json') as f:
    progress_schema = json.load(f)
```

**Available Schemas:**
- `agent_progress_update.json` - General progress status messages
- `artifact_creation_progress.json` - File/artifact creation tracking with chunked data and status
- `llm_invocation.json` - LLM model invocation signals with usage tracking
- `tool_invocation_start.json` - Tool execution start notifications
- `tool_result.json` - Tool execution completion results with optional LLM usage

## Complete Usage Guide

### 1. Loading and Using the A2A Schema

```python
import json
from jsonschema import validate, Draft7Validator

# Load the main A2A schema
with open('solace_agent_mesh/common/a2a_spec/a2a.json') as f:
    a2a_schema = json.load(f)

# Create validator for specific types
def validate_agent_card(card_data):
    """Validate an AgentCard against the schema"""
    card_schema = a2a_schema['definitions']['AgentCard']
    validate(instance=card_data, schema=card_schema)

def validate_message(message_data):
    """Validate a Message against the schema"""
    message_schema = a2a_schema['definitions']['Message']
    validate(instance=message_data, schema=message_schema)

def validate_request(request_data):
    """Validate an A2A request"""
    request_schema = a2a_schema['definitions']['A2ARequest']
    validate(instance=request_data, schema=request_schema)
```

### 2. Creating Valid A2A Data Structures

```python
# Create a valid Message
message = {
    "kind": "message",
    "messageId": "msg-123",
    "role": "user",
    "parts": [
        {
            "kind": "text",
            "text": "Hello, can you help me with a task?"
        }
    ]
}

# Create a SendMessage request
send_request = {
    "jsonrpc": "2.0",
    "id": "req-456",
    "method": "message/send",
    "params": {
        "message": message
    }
}

# Validate the request
validate_request(send_request)
```

### 3. Using Agent Communication Schemas

```python
import json
from jsonschema import validate

# Load and validate progress update
with open('solace_agent_mesh/common/a2a_spec/schemas/agent_progress_update.json') as f:
    progress_schema = json.load(f)

progress_update = {
    "type": "agent_progress_update",
    "status_text": "Processing your request..."
}
validate(instance=progress_update, schema=progress_schema)

# Load and validate tool invocation
with open('solace_agent_mesh/common/a2a_spec/schemas/tool_invocation_start.json') as f:
    tool_schema = json.load(f)

tool_invocation = {
    "type": "tool_invocation_start",
    "tool_name": "file_reader",
    "tool_args": {"filepath": "/data/file.txt"},
    "function_call_id": "call_123"
}
validate(instance=tool_invocation, schema=tool_schema)

# Load and validate tool result
with open('solace_agent_mesh/common/a2a_spec/schemas/tool_result.json') as f:
    result_schema = json.load(f)

tool_result = {
    "type": "tool_result",
    "tool_name": "file_reader",
    "result_data": {"content": "File contents...", "size": 1024},
    "function_call_id": "call_123"
}
validate(instance=tool_result, schema=result_schema)
```

### 4. Working with Agent Cards

```python
# Create a complete AgentCard
agent_card = {
    "name": "Document Processor",
    "description": "Agent that processes and analyzes documents",
    "url": "https://api.example.com/agent",
    "version": "1.0.0",
    "protocolVersion": "0.3.0",
    "capabilities": {
        "streaming": True,
        "pushNotifications": False,
        "stateTransitionHistory": True
    },
    "defaultInputModes": ["text/plain", "application/pdf"],
    "defaultOutputModes": ["text/plain", "application/json"],
    "skills": [
        {
            "id": "document-analysis",
            "name": "Document Analysis",
            "description": "Analyze and extract information from documents",
            "tags": ["document", "analysis", "extraction"]
        }
    ]
}

# Validate the agent card
validate_agent_card(agent_card)
```

### 5. Enhanced Artifact Creation Progress Tracking

```python
# Load artifact creation schema
with open('solace_agent_mesh/common/a2a_spec/schemas/artifact_creation_progress.json') as f:
    artifact_schema = json.load(f)

# Track artifact creation in progress with chunked data
artifact_progress = {
    "type": "artifact_creation_progress",
    "filename": "report.pdf",
    "description": "Monthly sales report",
    "status": "in-progress",
    "bytes_transferred": 1024,
    "artifact_chunk": "JVBERi0xLjQKJcOkw7zDtsO..."  # Base64 encoded chunk
}
validate(instance=artifact_progress, schema=artifact_schema)

# Track artifact completion
artifact_completed = {
    "type": "artifact_creation_progress",
    "filename": "report.pdf",
    "status": "completed",
    "bytes_transferred": 5120,
    "mime_type": "application/pdf"
}
validate(instance=artifact_completed, schema=artifact_schema)
```

### 6. LLM Invocation Tracking

```python
# Load LLM invocation schema
with open('solace_agent_mesh/common/a2a_spec/schemas/llm_invocation.json') as f:
    llm_schema = json.load(f)

# Track LLM calls with usage information
llm_invocation = {
    "type": "llm_invocation",
    "request": {
        "model": "gpt-4",
        "messages": [{"role": "user", "content": "Analyze this data"}],
        "temperature": 0.7
    },
    "usage": {
        "input_tokens": 150,
        "output_tokens": 75,
        "cached_input_tokens": 50,
        "model": "gpt-4"
    }
}
validate(instance=llm_invocation, schema=llm_schema)
```

### 7. Complete Request/Response Flow with Progress Tracking

```python
# 1. Create and send a message
message = {
    "kind": "message",
    "messageId": "msg-001",
    "role": "user",
    "parts": [{"kind": "text", "text": "Analyze this document"}]
}

request = {
    "jsonrpc": "2.0",
    "id": "req-001",
    "method": "message/send",
    "params": {
        "message": message,
        "configuration": {
            "blocking": False,
            "acceptedOutputModes": ["text/plain", "application/json"]
        }
    }
}

# 2. Send progress updates during processing
def send_progress_update(status_text):
    progress = {
        "type": "agent_progress_update",
        "status_text": status_text
    }
    # Validate and send progress update
    validate(instance=progress, schema=progress_schema)
    return progress

# 3. Track tool invocations
def track_tool_invocation(tool_name, args, call_id):
    invocation = {
        "type": "tool_invocation_start",
        "tool_name": tool_name,
        "tool_args": args,
        "function_call_id": call_id
    }
    validate(instance=invocation, schema=tool_schema)
    return invocation

# 4. Track tool results with LLM usage
def track_tool_result(tool_name, result_data, call_id, llm_usage=None):
    result = {
        "type": "tool_result",
        "tool_name": tool_name,
        "result_data": result_data,
        "function_call_id": call_id
    }
    if llm_usage:
        result["llm_usage"] = llm_usage
    validate(instance=result, schema=result_schema)
    return result
```

### 8. Comprehensive Schema Validation Utilities

```python
class A2AValidator:
    """Utility class for A2A schema validation"""
    
    def __init__(self, schema_dir='solace_agent_mesh/common/a2a_spec'):
        self.schema_dir = schema_dir
        self.main_schema = self._load_main_schema()
        self.signal_schemas = self._load_signal_schemas()
    
    def _load_main_schema(self):
        with open(f'{self.schema_dir}/a2a.json') as f:
            return json.load(f)
    
    def _load_signal_schemas(self):
        schemas = {}
        schema_files = [
            'agent_progress_update.json',
            'artifact_creation_progress.json',
            'llm_invocation.json',
            'tool_invocation_start.json',
            'tool_result.json'
        ]
        for filename in schema_files:
            with open(f'{self.schema_dir}/schemas/{filename}') as f:
                schema_name = filename.replace('.json', '')
                schemas[schema_name] = json.load(f)
        return schemas
    
    def validate_definition(self, data, definition_name):
        """Validate data against a specific A2A definition"""
        schema = self.main_schema['definitions'][definition_name]
        validate(instance=data, schema=schema)
    
    def validate_signal(self, data, signal_type):
        """Validate agent communication signal"""
        schema = self.signal_schemas[signal_type]
        validate(instance=data, schema=schema)
    
    def validate_a2a_message(self, message_data):
        """Validate a complete A2A message"""
        self.validate_definition(message_data, 'Message')
    
    def validate_agent_card(self, card_data):
        """Validate an agent card"""
        self.validate_definition(card_data, 'AgentCard')
    
    def validate_task(self, task_data):
        """Validate a task object"""
        self.validate_definition(task_data, 'Task')

# Usage example
validator = A2AValidator()

# Validate main A2A objects
validator.validate_agent_card(agent_card)
validator.validate_a2a_message(message)

# Validate communication signals
validator.validate_signal(progress_update, 'agent_progress_update')
validator.validate_signal(tool_invocation, 'tool_invocation_start')
validator.validate_signal(tool_result, 'tool_result')
validator.validate_signal(artifact_progress, 'artifact_creation_progress')
validator.validate_signal(llm_invocation, 'llm_invocation')
```

### 9. Error Handling with A2A Error Types

```python
# Create A2A-specific errors using the schema definitions
task_not_found_error = {
    "code": -32001,
    "message": "Task not found",
    "data": {"taskId": "task-123"}
}

content_type_error = {
    "code": -32005,
    "message": "Incompatible content types",
    "data": {"requested": "image/png", "supported": ["text/plain", "application/json"]}
}

# Create error response
error_response = {
    "jsonrpc": "2.0",
    "id": "req-456",
    "error": task_not_found_error
}

# Validate error response
validator.validate_definition(error_response, 'JSONRPCErrorResponse')
```

### 10. Working with Different Transport Protocols

```python
# Create agent card with multiple transport interfaces
agent_card_multi_transport = {
    "name": "Multi-Transport Agent",
    "description": "Agent supporting multiple transport protocols",
    "url": "https://api.example.com/jsonrpc",
    "preferredTransport": "JSONRPC",
    "additionalInterfaces": [
        {
            "url": "https://api.example.com/jsonrpc",
            "transport": "JSONRPC"
        },

================================================================================

## Section 16: solace_agent_mesh/common/a2a_spec/schemas/schemas_llm.txt

**Source file:** `solace_agent_mesh/common/a2a_spec/schemas/schemas_llm.txt`

# DEVELOPER GUIDE: schemas

## Quick Summary
This directory contains JSON Schema definitions for various agent-to-agent (A2A) communication signals in the Solace Agent Mesh. These schemas define the structure and validation rules for different types of progress updates, tool invocations, and LLM interactions that agents can send to each other.

## Files Overview
- `agent_progress_update.json` - Schema for general agent progress status messages
- `artifact_creation_progress.json` - Schema for tracking file/artifact creation progress with chunked data
- `llm_invocation.json` - Schema for LLM model invocation signals with usage tracking
- `tool_invocation_start.json` - Schema for tool execution start notifications
- `tool_result.json` - Schema for tool execution completion results with optional LLM usage

## Developer API Reference

### agent_progress_update.json
**Purpose:** Defines the schema for agent progress update signals that communicate human-readable status messages between agents.

**Import:** Load as JSON schema for validation
```python
import json
from jsonschema import validate
```

**Schema Structure:**
```json
{
  "type": "agent_progress_update",
  "status_text": "string"
}
```

**Properties:**
- `type: "agent_progress_update"` - Constant identifier for this signal type (required)
- `status_text: string` - Human-readable progress message (required)

**Usage Examples:**
```python
import json
from jsonschema import validate

# Load and use schema
with open('solace_agent_mesh/common/a2a_spec/schemas/agent_progress_update.json') as f:
    schema = json.load(f)

# Valid data example
data = {
    "type": "agent_progress_update",
    "status_text": "Analyzing the report..."
}
validate(instance=data, schema=schema)
```

### artifact_creation_progress.json
**Purpose:** Defines the schema for tracking progress during file or artifact creation operations with status tracking and chunked data transfer.

**Import:** Load as JSON schema for validation
```python
import json
from jsonschema import validate
```

**Schema Structure:**
```json
{
  "type": "artifact_creation_progress",
  "filename": "string",
  "description": "string",
  "status": "in-progress|completed|failed",
  "bytes_transferred": "integer",
  "artifact_chunk": "string",
  "mime_type": "string"
}
```

**Properties:**
- `type: "artifact_creation_progress"` - Constant identifier for this signal type (required)
- `filename: string` - Name of the artifact being created (required)
- `description: string` - Optional description of the artifact being created (optional)
- `status: string` - Status of artifact creation: "in-progress", "completed", or "failed" (required)
- `bytes_transferred: integer` - Number of bytes transferred so far (required)
- `artifact_chunk: string` - Chunk of artifact data transferred in this update (optional, only for 'in-progress')
- `mime_type: string` - MIME type of the artifact (optional, only for 'completed')

**Usage Examples:**
```python
import json
from jsonschema import validate

# Load and use schema
with open('solace_agent_mesh/common/a2a_spec/schemas/artifact_creation_progress.json') as f:
    schema = json.load(f)

# In-progress example
data = {
    "type": "artifact_creation_progress",
    "filename": "report.pdf",
    "description": "Monthly sales report",
    "status": "in-progress",
    "bytes_transferred": 1024,
    "artifact_chunk": "JVBERi0xLjQKJcOkw7zDtsO..."
}
validate(instance=data, schema=schema)

# Completed example
completed_data = {
    "type": "artifact_creation_progress",
    "filename": "report.pdf",
    "status": "completed",
    "bytes_transferred": 5120,
    "mime_type": "application/pdf"
}
validate(instance=completed_data, schema=schema)
```

### llm_invocation.json
**Purpose:** Defines the schema for LLM invocation signals that communicate when an agent is calling a language model, including token usage tracking.

**Import:** Load as JSON schema for validation
```python
import json
from jsonschema import validate
```

**Schema Structure:**
```json
{
  "type": "llm_invocation",
  "request": "object",
  "usage": {
    "input_tokens": "integer",
    "output_tokens": "integer",
    "cached_input_tokens": "integer",
    "model": "string"
  }
}
```

**Properties:**
- `type: "llm_invocation"` - Constant identifier for this signal type (required)
- `request: object` - Sanitized representation of the LlmRequest object sent to the model (required)
- `usage: object` - Token usage information for this LLM call (optional)
  - `input_tokens: integer` - Number of input/prompt tokens (required in usage)
  - `output_tokens: integer` - Number of output/completion tokens (required in usage)
  - `cached_input_tokens: integer` - Number of cached input tokens (optional)
  - `model: string` - Model identifier used for this call (required in usage)

**Usage Examples:**
```python
import json
from jsonschema import validate

# Load and use schema
with open('solace_agent_mesh/common/a2a_spec/schemas/llm_invocation.json') as f:
    schema = json.load(f)

# Valid data example with usage tracking
data = {
    "type": "llm_invocation",
    "request": {
        "model": "gpt-4",
        "messages": [{"role": "user", "content": "Analyze this data"}],
        "temperature": 0.7
    },
    "usage": {
        "input_tokens": 150,
        "output_tokens": 75,
        "cached_input_tokens": 50,
        "model": "gpt-4"
    }
}
validate(instance=data, schema=schema)
```

### tool_invocation_start.json
**Purpose:** Defines the schema for tool invocation start signals that notify when an agent begins executing a tool.

**Import:** Load as JSON schema for validation
```python
import json
from jsonschema import validate
```

**Schema Structure:**
```json
{
  "type": "tool_invocation_start",
  "tool_name": "string",
  "tool_args": "object",
  "function_call_id": "string"
}
```

**Properties:**
- `type: "tool_invocation_start"` - Constant identifier for this signal type (required)
- `tool_name: string` - Name of the tool being called (required)
- `tool_args: object` - Arguments passed to the tool (required)
- `function_call_id: string` - ID from the LLM's function call (required)

**Usage Examples:**
```python
import json
from jsonschema import validate

# Load and use schema
with open('solace_agent_mesh/common/a2a_spec/schemas/tool_invocation_start.json') as f:
    schema = json.load(f)

# Valid data example
data = {
    "type": "tool_invocation_start",
    "tool_name": "file_reader",
    "tool_args": {
        "filepath": "/path/to/file.txt",
        "encoding": "utf-8"
    },
    "function_call_id": "call_abc123"
}
validate(instance=data, schema=schema)
```

### tool_result.json
**Purpose:** Defines the schema for tool execution result signals that communicate the completion and results of tool invocations, with optional LLM usage tracking.

**Import:** Load as JSON schema for validation
```python
import json
from jsonschema import validate
```

**Schema Structure:**
```json
{
  "type": "tool_result",
  "tool_name": "string",
  "result_data": "any",
  "function_call_id": "string",
  "llm_usage": {
    "input_tokens": "integer",
    "output_tokens": "integer",
    "cached_input_tokens": "integer",
    "model": "string"
  }
}
```

**Properties:**
- `type: "tool_result"` - Constant identifier for this signal type (required)
- `tool_name: string` - Name of the tool that was called (required)
- `result_data: any` - The data returned by the tool (required, can be any type)
- `function_call_id: string` - ID from the LLM's function call that this result corresponds to (required)
- `llm_usage: object` - Token usage if this tool made LLM calls (optional)
  - `input_tokens: integer` - Total input tokens used by tool's LLM calls (required in llm_usage)
  - `output_tokens: integer` - Total output tokens used by tool's LLM calls (required in llm_usage)
  - `cached_input_tokens: integer` - Number of cached input tokens (optional)
  - `model: string` - Model identifier(s) used by the tool (required in llm_usage)

**Usage Examples:**
```python
import json
from jsonschema import validate

# Load and use schema
with open('solace_agent_mesh/common/a2a_spec/schemas/tool_result.json') as f:
    schema = json.load(f)

# Valid data example with LLM usage
data = {
    "type": "tool_result",
    "tool_name": "web_search",
    "result_data": {
        "results": ["Result 1", "Result 2"],
        "count": 2
    },
    "function_call_id": "call_abc123",
    "llm_usage": {
        "input_tokens": 200,
        "output_tokens": 100,
        "model": "gpt-4"
    }
}
validate(instance=data, schema=schema)
```

**Common Usage Pattern:**
```python
import json
from jsonschema import validate
from pathlib import Path
from typing import Dict, Any

def validate_a2a_signal(signal_data: Dict[str, Any], schema_name: str) -> bool:
    """Validate A2A signal data against its schema."""
    schema_path = Path(f"solace_agent_mesh/common/a2a_spec/schemas/{schema_name}.json")
    
    with open(schema_path) as f:
        schema = json.load(f)
    
    try:
        validate(instance=signal_data, schema=schema)
        return True
    except Exception as e:
        print(f"Validation failed: {e}")
        return False

def load_schema(schema_name: str) -> Dict[str, Any]:
    """Load a specific A2A signal schema."""
    schema_path = Path(f"solace_agent_mesh/common/a2a_spec/schemas/{schema_name}.json")
    with open(schema_path) as f:
        return json.load(f)

# Example usage
progress_data = {
    "type": "agent_progress_update",
    "status_text": "Processing request..."
}

if validate_a2a_signal(progress_data, "agent_progress_update"):
    print("Signal is valid!")

# Load all schemas for batch validation
schemas = {
    "agent_progress": load_schema("agent_progress_update"),
    "artifact_progress": load_schema("artifact_creation_progress"),
    "llm_invocation": load_schema("llm_invocation"),
    "tool_start": load_schema("tool_invocation_start"),
    "tool_result": load_schema("tool_result")
}
```

================================================================================

## Section 17: solace_agent_mesh/common/common_llm.txt

**Source file:** `solace_agent_mesh/common/common_llm.txt`

# DEVELOPER GUIDE: common

## Quick Summary
The `common` directory provides the foundational infrastructure for Agent-to-Agent (A2A) communication within the Solace Agent Mesh. It establishes the core protocol, data types, and message translation logic that underpins all interactions between AI agents and gateways.

The architecture is designed for clarity and extensibility. Core, low-level definitions are located in **direct files**:
- `types.py` defines the canonical data structures (e.g., `Message`, `Task`, `AgentCard`).
- `a2a_protocol.py` handles the construction of Solace topics and the translation between A2A and Google ADK message formats.
- `agent_registry.py` provides a simple, thread-safe mechanism for discovering and tracking available agents.

This foundation is then leveraged by specialized **subdirectories**, which provide higher-level, ready-to-use components:
- `client/`: A complete client library for discovering and interacting with remote agents.
- `server/`: A stand-alone server implementation for building A2A-compliant agents.
- `middleware/`: A pluggable framework for customizing configuration and feature access.
- `services/`: A factory-based system for integrating identity and other external data sources.
- `utils/`: A collection of cross-cutting utilities for caching, logging, and dynamic content processing.

Together, these components form a cohesive ecosystem, enabling developers to either build new agents from scratch using the `server` components or interact with existing agents using the `client` library, all while relying on the same underlying protocol and types.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Package initialization file.
  - `a2a_protocol.py`: Handles A2A topic construction and translation between A2A and ADK message formats.
  - `agent_registry.py`: A thread-safe registry for managing discovered agent cards.
  - `constants.py`: Common constants used across the system.
  - `data_parts.py`: Pydantic models for structured data payloads used in A2A DataPart objects.
  - `exceptions.py`: Custom exceptions for Solace Agent Mesh.
  - `types.py`: Contains all Pydantic models for A2A protocol messages, tasks, and data structures.
- **Subdirectories:**
  - `a2a/`: Comprehensive abstraction layer providing helper functions for creating, consuming, and translating A2A protocol objects.
  - `a2a_spec/`: Complete JSON Schema specification for the A2A protocol.
  - `client/`: Provides a high-level client for discovering and communicating with remote A2A agents.
  - `middleware/`: A pluggable framework for configuration resolution and system extensibility.
  - `sac/`: Base component framework for Solace Agent Mesh implementations in the Solace AI Connector.
  - `sam_events/`: System-level event messaging for session lifecycle, agent health, and configuration changes.
  - `server/`: A complete A2A server implementation with JSON-RPC support and task management.
  - `services/`: Provides shared services like identity management using a factory pattern.
  - `utils/`: Contains common utility functions and an embedded expression processing system.

## Developer API Reference

### Direct Files

#### a2a_protocol.py
**Purpose:** Provides the core functions for constructing Solace topics according to the A2A specification and for translating messages between the A2A format and the Google ADK format.
**Import:** `from solace_agent_mesh.common.a2a_protocol import get_agent_request_topic, translate_a2a_to_adk_content`

**Classes/Functions/Constants:**
- **Constants**:
  - `A2A_VERSION: str`: The current version of the A2A protocol (e.g., "v1").
  - `A2A_BASE_PATH: str`: The base path used in all A2A topics (e.g., "a2a/v1").
- **Topic Construction Functions**:
  - `get_a2a_base_topic(namespace: str) -> str`: Returns the base topic prefix for all A2A communication.
  - `get_discovery_topic(namespace: str) -> str`: Returns the topic for agent card discovery.
  - `get_agent_request_topic(namespace: str, agent_name: str) -> str`: Returns the topic for sending requests to a specific agent.
  - `get_gateway_status_topic(namespace: str, gateway_id: str, task_id: str) -> str`: Returns the topic for an agent to publish status updates to a gateway.
  - `get_gateway_response_topic(namespace: str, gateway_id: str, task_id: str) -> str`: Returns the topic for an agent to publish final responses to a gateway.
  - `get_client_response_topic(namespace: str, client_id: str) -> str`: Returns the topic for publishing final responses to a specific client.
  - `get_client_status_topic(namespace: str, client_id: str, task_id: str) -> str`: Returns the topic for publishing status updates to a specific client.
- **Message Translation Functions**:
  - `translate_a2a_to_adk_content(a2a_message: A2AMessage, log_identifier: str) -> adk_types.Content`: Translates an A2A `Message` object into the Google ADK `Content` format.
  - `format_adk_event_as_a2a(...) -> Tuple[Optional[JSONRPCResponse], ...]`: Translates an ADK `Event` into an A2A `JSONRPCResponse` containing a `TaskStatusUpdateEvent`.
  - `format_and_route_adk_event(...) -> Tuple[Optional[Dict], Optional[str], ...]`: A higher-level wrapper that formats an ADK event and determines the correct Solace topic to publish it to.

#### agent_registry.py
**Purpose:** Provides a simple, thread-safe, in-memory store for discovered `AgentCard` objects. This is useful for components that need to keep track of available agents in the network.
**Import:** `from solace_agent_mesh.common.agent_registry import AgentRegistry`

**Classes/Functions/Constants:**
- **`AgentRegistry`**: A thread-safe class for storing and managing agent cards.
  - `add_or_update_agent(self, agent_card: AgentCard) -> bool`: Adds a new agent or updates an existing one, returns True if new.
  - `get_agent(self, agent_name: str) -> Optional[AgentCard]`: Retrieves an agent card by its unique name.
  - `get_agent_names(self) -> List[str]`: Returns a sorted list of all discovered agent names.
  - `get_last_seen(self, agent_name: str) -> Optional[float]`: Returns the timestamp when the agent was last seen.
  - `check_ttl_expired(self, agent_name: str, ttl_seconds: int) -> Tuple[bool, int]`: Checks if an agent's TTL has expired.
  - `remove_agent(self, agent_name: str) -> bool`: Removes an agent from the registry.
  - `clear(self)`: Clears all agents from the registry.

#### constants.py
**Purpose:** Defines common constants used throughout the Solace Agent Mesh system.
**Import:** `from solace_agent_mesh.common.constants import DEFAULT_COMMUNICATION_TIMEOUT`

**Classes/Functions/Constants:**
- `DEFAULT_COMMUNICATION_TIMEOUT: int`: Default timeout for communication operations (600 seconds / 10 minutes).
- `HEALTH_CHECK_TTL_SECONDS: int`: Time after which a health check is considered stale (60 seconds).
- `HEALTH_CHECK_INTERVAL_SECONDS: int`: Interval between health checks (10 seconds).
- `TEXT_ARTIFACT_CONTEXT_MAX_LENGTH_CAPACITY: int`: Maximum number of characters that can be loaded from a text artifact (200,000).
- `TEXT_ARTIFACT_CONTEXT_DEFAULT_LENGTH: int`: Default number of characters to load from a text artifact (100,000).

#### data_parts.py
**Purpose:** Defines Pydantic models for structured data payloads used in A2A DataPart objects, corresponding to JSON schemas for agent communication signals.
**Import:** `from solace_agent_mesh.common.data_parts import ToolInvocationStartData, LlmInvocationData`

**Classes/Functions/Constants:**
- **`ToolInvocationStartData`**: Data model for tool invocation start signals.
  - `type: Literal["tool_invocation_start"]`: The constant type identifier.
  - `tool_name: str`: The name of the tool being called.
  - `tool_args: Dict[str, Any]`: The arguments passed to the tool.
  - `function_call_id: str`: The ID from the LLM's function call.
- **`LlmInvocationData`**: Data model for LLM invocation signals.
  - `type: Literal["llm_invocation"]`: The constant type identifier.
  - `request: Dict[str, Any]`: A sanitized representation of the LlmRequest object.
  - `usage: Optional[Dict[str, Any]]`: Token usage information for this LLM call.
- **`AgentProgressUpdateData`**: Data model for agent progress update signals.
  - `type: Literal["agent_progress_update"]`: The constant type identifier.
  - `status_text: str`: A human-readable progress message.
- **`ArtifactCreationProgressData`**: Data model for artifact creation progress signals.
  - `type: Literal["artifact_creation_progress"]`: The constant type identifier.
  - `filename: str`: The name of the artifact being created.
  - `status: Literal["in-progress", "completed", "failed"]`: The status of the artifact creation.
  - `bytes_transferred: int`: The number of bytes transferred so far.
  - `description: Optional[str]`: An optional description of the artifact being created.
  - `artifact_chunk: Optional[str]`: The chunk of artifact data that was transferred in this progress update.
  - `mime_type: Optional[str]`: The MIME type of the artifact (for completed status).
- **`ToolResultData`**: Data model for tool execution result signals.
  - `type: Literal["tool_result"]`: The constant type identifier.
  - `tool_name: str`: The name of the tool that was called.
  - `result_data: Any`: The data returned by the tool.
  - `function_call_id: str`: The ID from the LLM's function call.
  - `llm_usage: Optional[Dict[str, Any]]`: Token usage if this tool made LLM calls.

#### exceptions.py
**Purpose:** Defines custom exceptions specific to the Solace Agent Mesh system.
**Import:** `from solace_agent_mesh.common.exceptions import MessageSizeExceededError`

**Classes/Functions/Constants:**
- **`MessageSizeExceededError(Exception)`**: Raised when a message exceeds the maximum allowed size.
  - `__init__(self, actual_size: int, max_size: int, message: str = None)`: Initialize with size information.
  - `actual_size: int`: The actual size of the message in bytes.
  - `max_size: int`: The maximum allowed size in bytes.

#### types.py
**Purpose:** Defines all the Pydantic data models that constitute the A2A protocol. These types ensure data consistency and provide validation across all components.
**Import:** `from solace_agent_mesh.common.types import Message, Task, AgentCard, JSONRPCRequest, TaskState`

**Classes/Functions/Constants:**
- **Core Data Structures**:
  - `Message`: Represents a message from a user or agent, containing a list of `Part` objects.
  - `Part`: A discriminated union of `TextPart`, `FilePart`, and `DataPart`.
  - `Task`: The central object representing a complete task, including its ID, status, history, and artifacts.
  - `TaskStatus`: Describes the current state of a task (e.g., `WORKING`, `COMPLETED`).
  - `TaskState(Enum)`: An enumeration of all possible task states.
  - `AgentCard`: A comprehensive description of an agent's identity, capabilities, and skills.
  - `Artifact`: Represents a task output, such as a generated file or structured data.
- **JSON-RPC Structures**:
  - `JSONRPCRequest`: The base model for all JSON-RPC requests.
  - `JSONRPCResponse`: The base model for all JSON-RPC responses.
  - `SendTaskRequest`, `GetTaskRequest`, etc.: Specific request types inheriting from `JSONRPCRequest`.
- **Error Structures**:
  - `JSONRPCError`: The base model for errors.
  - `InternalError`, `TaskNotFoundError`, etc.: Specific error types inheriting from `JSONRPCError`.

### Subdirectory APIs

#### a2a/
**Purpose:** Comprehensive abstraction layer providing helper functions for creating, consuming, and translating A2A protocol objects
**Key Exports:** Helper functions for messages, tasks, artifacts, events, and protocol operations
**Import Examples:**
```python
from solace_agent_mesh.common.a2a import create_agent_text_message, create_initial_task, translate_a2a_to_adk_content
from solace_agent_mesh.common.a2a.message import create_text_part, get_text_from_message
from solace_agent_mesh.common.a2a.protocol import get_agent_request_topic, create_send_message_request
```

#### a2a_spec/
**Purpose:** Contains the complete Agent-to-Agent (A2A) communication specification including JSON schema definitions
**Key Exports:** JSON Schema specifications for A2A protocol and agent communication signals
**Import Examples:**
```python
import json
from jsonschema import validate

# Load main A2A schema
with open('solace_agent_mesh/common/a2a_spec/a2a.json') as f:
    a2a_schema = json.load(f)
```

#### client/
**Purpose:** Provides a high-level, asynchronous client library for discovering and interacting with remote A2A agents.
**Key Exports:** `A2AClient`, `A2ACardResolver`
**Import Examples:**
```python
from solace_agent_mesh.common.client import A2AClient, A2ACardResolver
```

#### middleware/
**Purpose:** A pluggable middleware framework for customizing system behavior, such as resolving user-specific configurations and feature flags.
**Key Exports:** `ConfigResolver`, `MiddlewareRegistry`
**Import Examples:**
```python
from solace_agent_mesh.common.middleware import ConfigResolver, MiddlewareRegistry
```

#### sac/
**Purpose:** Base component framework for Solace Agent Mesh implementations in the Solace AI Connector with async operations management
**Key Exports:** `SamComponentBase`
**Import Examples:**
```python
from solace_agent_mesh.common.sac.sam_component_base import SamComponentBase
```

#### sam_events/
**Purpose:** System-level event messaging for session lifecycle, agent health, and configuration changes separate from A2A task communication
**Key Exports:** `SamEventService`, `SamEvent`, `SessionDeletedEvent`
**Import Examples:**
```python
from solace_agent_mesh.common.sam_events import SamEventService, SamEvent, SessionDeletedEvent
```

#### server/
**Purpose:** A complete, stand-alone server for building A2A-compliant agents, handling HTTP requests, JSON-RPC, and task lifecycle management.
**Key Exports:** `A2AServer`, `TaskManager`, `InMemoryTaskManager`
**Import Examples:**
```python
from solace_agent_mesh.common.server import A2AServer, TaskManager, InMemoryTaskManager
```

#### services/
**Purpose:** A factory-based system for integrating external data sources for identity, employee information, and more.
**Key Exports:** `BaseIdentityService`, `create_identity_service`
**Import Examples:**
```python
from solace_agent_mesh.common.services.identity_service import create_identity_service, BaseIdentityService
```

#### utils/
**Purpose:** A collection of cross-cutting utilities for caching, logging, MIME type handling, and dynamic content processing.
**Key Exports:** `InMemoryCache`, `is_text_based_mime_type`, `resolve_emb

================================================================================

## Section 18: solace_agent_mesh/common/middleware/middleware_llm.txt

**Source file:** `solace_agent_mesh/common/middleware/middleware_llm.txt`

# DEVELOPER GUIDE: middleware

## Quick Summary
The `middleware` directory provides a pluggable framework for system components that can be extended or replaced at runtime. It offers a registry system to dynamically bind custom implementations for core functionalities like configuration resolution. The default implementations provide permissive behavior, making them suitable for development and testing environments where all features are enabled by default.

## Files Overview
- `__init__.py`: Exposes the main public classes of the middleware package for easy importing.
- `config_resolver.py`: Defines the default, permissive configuration resolution middleware.
- `registry.py`: Provides the `MiddlewareRegistry` for dynamically binding custom middleware implementations.

## Developer API Reference

### __init__.py
**Purpose:** This file serves as the entry point to the `middleware` package, exporting the primary public interfaces for developers to use.

**Import:** `from solace_agent_mesh.common.middleware import ConfigResolver, MiddlewareRegistry`

**Usage Examples:**
```python
# Import the main classes directly from the middleware package
from solace_agent_mesh.common.middleware import ConfigResolver, MiddlewareRegistry

# Now you can use ConfigResolver and MiddlewareRegistry
print(ConfigResolver)
print(MiddlewareRegistry)
```

### config_resolver.py
**Purpose:** This file provides a pluggable interface for resolving user-specific configuration and determining feature availability. The default `ConfigResolver` class is permissive, allowing all operations and enabling all features, which is ideal for development or simple deployments.

**Import:** `from solace_agent_mesh.common.middleware import ConfigResolver`

**Classes:**
- `ConfigResolver()` - A class containing static methods to resolve user-specific configuration and determine feature availability. This default implementation is permissive.
  - `resolve_user_config(user_identity: Any, gateway_context: Dict[str, Any], base_config: Dict[str, Any]) -> Dict[str, Any]` - (async) Resolves user-specific configuration. The default implementation returns the `base_config` unchanged.
  - `is_feature_enabled(user_config: Dict[str, Any], feature_descriptor: Dict[str, Any], context: Dict[str, Any]) -> bool` - Checks if a feature is enabled for a user. The default implementation always returns `True`.
  - `validate_operation_config(user_config: Dict[str, Any], operation_spec: Dict[str, Any], validation_context: Dict[str, Any]) -> Dict[str, Any]` - Validates if an operation is allowed for a user. The default implementation always returns a dictionary with `{'valid': True}`.
  - `filter_available_options(user_config: Dict[str, Any], available_options: List[Dict[str, Any]], filter_context: Dict[str, Any]) -> List[Dict[str, Any]]` - Filters a list of options based on user permissions. The default implementation returns the original `available_options` list.

**Usage Examples:**
```python
import asyncio
from solace_agent_mesh.common.middleware import ConfigResolver

async def main():
    # Example user identity and base configuration
    user_id = "test-user@example.com"
    base_conf = {"api_key": "default_key", "allowed_models": ["gpt-3.5-turbo"]}

    # 1. Resolve user configuration (default implementation returns base_conf)
    user_config = await ConfigResolver.resolve_user_config(
        user_identity=user_id,
        gateway_context={"gateway_id": "gw-1"},
        base_config=base_conf
    )
    print(f"Resolved User Config: {user_config}")

    # 2. Check if a feature is enabled (default is always True)
    feature_desc = {"feature_type": "ai_tool", "function_name": "code_interpreter"}
    is_enabled = ConfigResolver.is_feature_enabled(
        user_config=user_config,
        feature_descriptor=feature_desc,
        context={}
    )
    print(f"Is Feature Enabled: {is_enabled}")

    # 3. Validate an operation (default is always valid)
    op_spec = {"operation_type": "model_inference", "model": "gpt-4"}
    validation = ConfigResolver.validate_operation_config(
        user_config=user_config,
        operation_spec=op_spec,
        validation_context={}
    )
    print(f"Operation Validation: {validation}")

    # 4. Filter available options (default returns all options)
    all_models = [
        {"name": "gpt-3.5-turbo", "provider": "openai"},
        {"name": "gpt-4", "provider": "openai"},
    ]
    available_models = ConfigResolver.filter_available_options(
        user_config=user_config,
        available_options=all_models,
        filter_context={"type": "language_model"}
    )
    print(f"Filtered Options: {available_models}")

if __name__ == "__main__":
    asyncio.run(main())
```

### registry.py
**Purpose:** This file provides the `MiddlewareRegistry`, a static class that allows developers to dynamically bind, or "plug in," their own custom middleware implementations at runtime. This is the core of the pluggable system.

**Import:** `from solace_agent_mesh.common.middleware import MiddlewareRegistry`

**Classes:**
- `MiddlewareRegistry()` - A registry for managing middleware implementations. All methods are class methods.
  - `bind_config_resolver(resolver_class: Type)` - Binds a custom class that implements the `ConfigResolver` interface. This new class will be used for all subsequent configuration resolution calls.
  - `get_config_resolver() -> Type` - Returns the currently bound `ConfigResolver` class. If no custom resolver has been bound, it returns the default `ConfigResolver`.
  - `register_initialization_callback(callback: callable)` - Registers a function to be executed when `initialize_middleware()` is called. Useful for setting up custom middleware components at application startup.
  - `initialize_middleware()` - Executes all registered initialization callbacks. This should be called once during application startup.
  - `reset_bindings()` - Resets all bindings back to their defaults. This is primarily useful for testing environments.
  - `get_registry_status() -> Dict[str, Any]` - Returns a dictionary containing the current status of the registry, such as which resolver is bound.

**Usage Examples:**
```python
import asyncio
from typing import Any, Dict, List
from solace_agent_mesh.common.middleware import MiddlewareRegistry, ConfigResolver

# 1. Define a custom ConfigResolver implementation
class MyCustomConfigResolver:
    """A custom resolver that only allows 'admin' users to use 'gpt-4'."""
    @staticmethod
    async def resolve_user_config(user_identity: Any, gateway_context: Dict[str, Any], base_config: Dict[str, Any]) -> Dict[str, Any]:
        if user_identity == "admin":
            return {"role": "admin", "allowed_models": ["gpt-4", "gpt-3.5-turbo"]}
        return {"role": "user", "allowed_models": ["gpt-3.5-turbo"]}

    @staticmethod
    def validate_operation_config(user_config: Dict, operation_spec: Dict, validation_context: Dict) -> Dict:
        model = operation_spec.get("model")
        if model and model not in user_config.get("allowed_models", []):
            return {"valid": False, "reason": f"Model '{model}' not allowed for this user."}
        return {"valid": True}
    
    # Inherit other methods from the default for simplicity
    is_feature_enabled = ConfigResolver.is_feature_enabled
    filter_available_options = ConfigResolver.filter_available_options

# 2. Define an initialization callback
def setup_custom_logging():
    print("Custom middleware initialization logic is running!")

# 3. Bind the custom components
MiddlewareRegistry.bind_config_resolver(MyCustomConfigResolver)
MiddlewareRegistry.register_initialization_callback(setup_custom_logging)

# 4. Initialize the middleware (e.g., at application startup)
print("--- Initializing Middleware ---")
MiddlewareRegistry.initialize_middleware()
print("--- Initialization Complete ---")

# 5. Use the middleware system
async def check_permissions():
    # The registry will now use MyCustomConfigResolver automatically
    CurrentResolver = MiddlewareRegistry.get_config_resolver()
    print(f"Current resolver is: {CurrentResolver.__name__}")

    # Check an admin user
    admin_config = await CurrentResolver.resolve_user_config("admin", {}, {})
    validation_result = CurrentResolver.validate_operation_config(
        admin_config, {"model": "gpt-4"}, {}
    )
    print(f"Admin validation for gpt-4: {validation_result}")

    # Check a regular user
    user_config = await CurrentResolver.resolve_user_config("user", {}, {})
    validation_result = CurrentResolver.validate_operation_config(
        user_config, {"model": "gpt-4"}, {}
    )
    print(f"User validation for gpt-4: {validation_result}")

# Run the example
asyncio.run(check_permissions())

# 6. Check status and reset (useful for testing)
print(f"\nRegistry Status: {MiddlewareRegistry.get_registry_status()}")
MiddlewareRegistry.reset_bindings()
print(f"Registry Status after reset: {MiddlewareRegistry.get_registry_status()}")
```

================================================================================

## Section 19: solace_agent_mesh/common/sac/sac_llm.txt

**Source file:** `solace_agent_mesh/common/sac/sac_llm.txt`

# DEVELOPER GUIDE: sac

## Quick Summary
The `sac` directory provides the base component framework for Solace Agent Mesh (SAM) implementations in the Solace AI Connector. It offers a standardized foundation for building high-level SAM components like Agents and Gateways with built-in async operations management and message publishing capabilities.

## Files Overview
- `__init__.py` - Empty package initialization file
- `sam_component_base.py` - Abstract base class providing async thread management and A2A message publishing for SAM components

## Developer API Reference

### sam_component_base.py
**Purpose:** Provides an abstract base class for SAM components with managed asyncio event loops and message publishing
**Import:** `from solace_agent_mesh.common.sac.sam_component_base import SamComponentBase`

**Classes:**
- `SamComponentBase(info: Dict[str, Any], **kwargs: Any)` - Abstract base class for high-level SAM components (Agents, Gateways)
  - `publish_a2a_message(payload: Dict, topic: str, user_properties: Optional[Dict] = None) -> None` - Publishes A2A messages with size validation
  - `run() -> None` - Starts the component's dedicated async thread
  - `cleanup() -> None` - Cleans up resources including async thread and loop
  - `get_async_loop() -> Optional[asyncio.AbstractEventLoop]` - Returns the dedicated asyncio event loop
  - `_async_setup_and_run() -> None` - Abstract method for subclasses to implement main async logic
  - `_pre_async_cleanup() -> None` - Abstract method for cleanup before async loop stops
  - `namespace: str` - The configured namespace for the component
  - `max_message_size_bytes: int` - Maximum allowed message size in bytes

**Usage Examples:**
```python
from solace_agent_mesh.common.sac.sam_component_base import SamComponentBase
from typing import Dict, Any
import asyncio

class MyAgent(SamComponentBase):
    def __init__(self, info: Dict[str, Any], **kwargs: Any):
        super().__init__(info, **kwargs)
        # Additional initialization
    
    async def _async_setup_and_run(self) -> None:
        """Implement your main async logic here"""
        while not self.stop_signal.is_set():
            # Your async operations
            await asyncio.sleep(1)
    
    def _pre_async_cleanup(self) -> None:
        """Cleanup before async loop stops"""
        # Your cleanup logic
        pass

# Usage
config = {
    "namespace": "my_namespace",
    "max_message_size_bytes": 1048576  # 1MB
}
agent = MyAgent(config)

# Publish a message
payload = {"message": "Hello World"}
agent.publish_a2a_message(
    payload=payload,
    topic="sam/agents/my_agent/response",
    user_properties={"correlation_id": "123"}
)

# Start the component
agent.run()

# Later, cleanup
agent.cleanup()
```

================================================================================

## Section 20: solace_agent_mesh/common/sam_events/sam_events_llm.txt

**Source file:** `solace_agent_mesh/common/sam_events/sam_events_llm.txt`

# DEVELOPER GUIDE: sam_events

## Quick Summary
The `sam_events` directory provides system-level event messaging for Solace Agent Mesh (SAM). It enables clean separation between agent-to-agent (A2A) task communication and system events like session lifecycle, agent health, and configuration changes.

## Files Overview
- `__init__.py` - Package initialization and public API exports
- `event_service.py` - Core event service implementation with publishing/subscription capabilities

## Developer API Reference

### __init__.py
**Purpose:** Package entry point that exports the main classes for SAM event handling
**Import:** `from solace_agent_mesh.common.sam_events import SamEventService, SamEvent, SessionDeletedEvent`

### event_service.py
**Purpose:** Implements the core event messaging service for system-level events in SAM
**Import:** `from solace_agent_mesh.common.sam_events.event_service import SamEventService, SamEvent, SessionDeletedEvent`

**Classes:**

- `SamEvent(event_type: str, event_id: str, timestamp: str, source_component: str, namespace: str, data: Dict[str, Any])` - Base class for all SAM system events
  - `create(event_type: str, source_component: str, namespace: str, data: Dict[str, Any]) -> SamEvent` - Create a new event with auto-generated ID and timestamp
  - `to_dict() -> Dict[str, Any]` - Convert event to dictionary for messaging
  - `event_type: str` - Type of event (e.g., "session.deleted")
  - `event_id: str` - Unique identifier for the event
  - `timestamp: str` - ISO format timestamp when event was created
  - `source_component: str` - Component that generated the event
  - `namespace: str` - SAM namespace
  - `data: Dict[str, Any]` - Event-specific data payload

- `SessionDeletedEvent(SamEvent)` - Specialized event for session deletion notifications
  - `create(namespace: str, source_component: str, session_id: str, user_id: str, agent_id: str, gateway_id: str) -> SessionDeletedEvent` - Create a session deleted event

- `SamEventService(namespace: str, component_name: str, publish_func: Callable[[str, Dict, Optional[Dict]], None])` - Service for publishing and subscribing to SAM system events
  - `publish_event(event: SamEvent) -> bool` - Publish a system event
  - `publish_session_deleted(session_id: str, user_id: str, agent_id: str, gateway_id: str) -> bool` - Convenience method to publish session deleted event
  - `subscribe_to_events(event_type: str, handler: Callable[[SamEvent], None]) -> bool` - Subscribe to events of a specific type
  - `handle_incoming_event(topic: str, payload: Dict[str, Any]) -> None` - Handle incoming events from messaging system
  - `namespace: str` - The SAM namespace
  - `component_name: str` - Name of the component using this service

**Functions:**

- `SamEventService.get_event_topic(namespace: str, event_type: str) -> str` - Get the topic for a specific event type

**Usage Examples:**

```python
# Basic event service setup
from solace_agent_mesh.common.sam_events import SamEventService, SamEvent, SessionDeletedEvent

# Initialize the event service
def my_publish_func(topic: str, payload: dict, headers: dict = None):
    # Your A2A publishing implementation
    pass

event_service = SamEventService(
    namespace="my_namespace",
    component_name="my_component", 
    publish_func=my_publish_func
)

# Create and publish a custom event
custom_event = SamEvent.create(
    event_type="agent.health_check",
    source_component="health_monitor",
    namespace="my_namespace",
    data={"status": "healthy", "cpu_usage": 45.2}
)
success = event_service.publish_event(custom_event)

# Publish a session deleted event (convenience method)
success = event_service.publish_session_deleted(
    session_id="sess_123",
    user_id="user_456", 
    agent_id="agent_789",
    gateway_id="gateway_001"
)

# Subscribe to events
def handle_session_deleted(event: SamEvent):
    session_id = event.data["session_id"]
    print(f"Session {session_id} was deleted")

event_service.subscribe_to_events("session.deleted", handle_session_deleted)

# Handle incoming events (typically called by your messaging infrastructure)
incoming_payload = {
    "event_type": "session.deleted",
    "event_id": "evt_123",
    "timestamp": "2024-01-01T12:00:00Z",
    "source_component": "gateway",
    "namespace": "my_namespace",
    "data": {"session_id": "sess_123", "user_id": "user_456"}
}
event_service.handle_incoming_event("sam/events/session/deleted", incoming_payload)

# Get topic for an event type
topic = SamEventService.get_event_topic("my_namespace", "session.deleted")
print(topic)  # Returns the proper SAM events topic
```

================================================================================

## Section 21: solace_agent_mesh/common/services/providers/providers_llm.txt

**Source file:** `solace_agent_mesh/common/services/providers/providers_llm.txt`

## Quick Summary
This directory contains concrete implementations (providers) for the abstract services defined in the parent `services` package. These providers offer specific ways to fulfill service contracts, such as sourcing user identity information from a local file.

## Files Overview
- `__init__.py` - Package initialization file marking the directory as a Python package
- `local_file_identity_service.py` - File-based identity service implementation that reads user data from local JSON files

## Developer API Reference

### __init__.py
**Purpose:** Initializes the providers package
**Import:** `from solace_agent_mesh.common.services import providers`

This file contains no public classes or functions - it serves only as package documentation.

### local_file_identity_service.py
**Purpose:** Provides a file-based identity service that reads user profiles from a local JSON file, ideal for development, testing, or small-scale deployments
**Import:** `from solace_agent_mesh.common.services.providers.local_file_identity_service import LocalFileIdentityService`

**Classes:**
- `LocalFileIdentityService(config: Dict[str, Any], component: Optional[SamComponentBase] = None)` - Identity service that sources user data from a local JSON file
  - `async get_user_profile(auth_claims: Dict[str, Any]) -> Optional[Dict[str, Any]]` - Looks up a user profile using the lookup key from auth claims
  - `async search_users(query: str, limit: int = 10) -> List[Dict[str, Any]]` - Performs case-insensitive search on user names and emails
  - `file_path: str` - Path to the JSON file containing user data
  - `lookup_key: str` - Key used to identify users (defaults to "id")
  - `all_users: List[Dict[str, Any]]` - Complete list of user profiles loaded from file
  - `user_index: Dict[str, Dict[str, Any]]` - In-memory index mapping lookup keys to user profiles

**Usage Examples:**
```python
import asyncio
import json
from typing import Dict, Any
from solace_agent_mesh.common.services.providers.local_file_identity_service import LocalFileIdentityService

# Create sample users.json file
users_data = [
    {
        "id": "jdoe",
        "email": "jane.doe@example.com", 
        "name": "Jane Doe",
        "title": "Senior Engineer",
        "manager_id": "ssmith"
    },
    {
        "id": "ssmith",
        "email": "sam.smith@example.com",
        "name": "Sam Smith", 
        "title": "Engineering Manager"
    }
]

with open("users.json", "w") as f:
    json.dump(users_data, f)

async def main():
    # Initialize the service
    config = {
        "file_path": "users.json",
        "lookup_key": "id"  # Optional, defaults to "id"
    }
    
    identity_service = LocalFileIdentityService(config)
    
    # Get user profile by ID
    auth_claims = {"id": "jdoe"}
    profile = await identity_service.get_user_profile(auth_claims)
    print(f"User profile: {profile}")
    
    # Search for users
    results = await identity_service.search_users("jane", limit=5)
    print(f"Search results: {results}")
    
    # Handle missing user
    missing = await identity_service.get_user_profile({"id": "nonexistent"})
    print(f"Missing user: {missing}")  # Returns None

asyncio.run(main())
```

================================================================================

## Section 22: solace_agent_mesh/common/services/services_llm.txt

**Source file:** `solace_agent_mesh/common/services/services_llm.txt`

# DEVELOPER GUIDE: services

## Quick Summary
The `services` directory provides a modular and extensible framework for integrating external data sources related to identity and employee information into the Solace AI Connector. It is built on a provider pattern, defining abstract base classes (`BaseIdentityService`, `BaseEmployeeService`) that establish a clear contract for what data and functionality a service must provide.

The core architecture revolves around factory functions (`create_identity_service`, `create_employee_service`) that instantiate specific service providers based on a configuration dictionary. This allows the application to remain decoupled from the concrete implementations. The `providers/` subdirectory contains concrete implementations, including a built-in file-based identity service, while external providers can be dynamically loaded as plugins through Python's entry points system.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Marks the directory as a Python package with shared, reusable services
  - `employee_service.py`: Defines the abstract contract and factory for employee data services
  - `identity_service.py`: Defines the abstract contract and factory for user identity services
- **Subdirectories:**
  - `providers/`: Contains concrete implementations of the service contracts, including a file-based identity provider

## Developer API Reference

### Direct Files

#### employee_service.py
**Purpose:** Defines the abstract base class (`BaseEmployeeService`) that all employee service providers must implement, and a factory function (`create_employee_service`) to instantiate them. It enforces a canonical schema for employee data to ensure consistency across different providers.
**Import:** `from solace_agent_mesh.common.services.employee_service import BaseEmployeeService, create_employee_service`

**Classes/Functions/Constants:**
- **`class BaseEmployeeService(ABC)`**: The abstract base class for employee service providers.
    - **`__init__(self, config: Dict[str, Any])`**: Initializes the service, setting up configuration and an optional in-memory cache.
    - **`async def get_employee_dataframe(self) -> pd.DataFrame`**: (Abstract) Returns the entire employee directory as a pandas DataFrame.
    - **`async def get_employee_profile(self, employee_id: str) -> Optional[Dict[str, Any]]`**: (Abstract) Fetches the profile for a single employee, conforming to the canonical schema.
    - **`async def get_time_off_data(self, employee_id: str) -> List[Dict[str, Any]]`**: (Abstract) Retrieves a list of time-off entries for an employee.
    - **`async def get_employee_profile_picture(self, employee_id: str) -> Optional[str]`**: (Abstract) Fetches an employee's profile picture as a data URI string.
- **`def create_employee_service(config: Optional[Dict[str, Any]]) -> Optional[BaseEmployeeService]`**: A factory function that dynamically loads and instantiates an employee service provider based on the `type` specified in the configuration. It primarily uses Python's entry points to find and load external plugins.

#### identity_service.py
**Purpose:** Defines the abstract base class (`BaseIdentityService`) for identity providers and a factory function (`create_identity_service`) to create instances of them. This service is used for user lookups and profile enrichment.
**Import:** `from solace_agent_mesh.common.services.identity_service import BaseIdentityService, create_identity_service`

**Classes/Functions/Constants:**
- **`class BaseIdentityService(ABC)`**: The abstract base class for identity service providers.
    - **`__init__(self, config: Dict[str, Any], component: Optional[SamComponentBase] = None)`**: Initializes the service, setting up configuration and an optional in-memory cache.
    - **`async def get_user_profile(self, auth_claims: Dict[str, Any]) -> Optional[Dict[str, Any]]`**: (Abstract) Fetches additional profile details for an authenticated user based on claims.
    - **`async def search_users(self, query: str, limit: int = 10) -> List[Dict[str, Any]]`**: (Abstract) Searches for users based on a query string (e.g., for autocomplete).
- **`def create_identity_service(config: Optional[Dict[str, Any]], component: Optional[SamComponentBase] = None) -> Optional[BaseIdentityService]`**: A factory function that instantiates an identity service provider. It has special handling for the built-in `local_file` provider and uses Python entry points for all other provider types.

### Subdirectory APIs

#### providers/
**Purpose:** Contains concrete implementations of the abstract service classes, providing specific ways to fulfill service contracts such as sourcing user identity information from local files
**Key Exports:** `LocalFileIdentityService`
**Import Examples:**
```python
from solace_agent_mesh.common.services.providers.local_file_identity_service import LocalFileIdentityService
```

## Complete Usage Guide

### 1. Using Service Factories (Recommended Approach)
The factories are the primary way to create and use services. They abstract away the specific implementation details and handle plugin loading.

**Example: Creating Identity and Employee Services**

```python
import asyncio
from solace_agent_mesh.common.services.identity_service import create_identity_service
from solace_agent_mesh.common.services.employee_service import create_employee_service

async def main():
    # --- Identity Service Example (using built-in provider) ---
    identity_config = {
        "type": "local_file",
        "file_path": "path/to/your/users.json",
        "lookup_key": "email",  # Key to use for lookups from auth_claims
        "cache_ttl_seconds": 3600
    }
    identity_service = create_identity_service(identity_config)

    if identity_service:
        print("Identity Service created.")
        # Fetch a user profile
        auth_claims = {"email": "jane.doe@example.com"}
        user_profile = await identity_service.get_user_profile(auth_claims)
        print(f"User Profile: {user_profile}")

        # Search for users
        search_results = await identity_service.search_users("Jane")
        print(f"Search Results: {search_results}")

    # --- Employee Service Example (using external plugin) ---
    # The 'type' must match the name of a registered plugin entry point
    employee_config = {
        "type": "bamboohr_plugin",
        "api_key": "your-secret-api-key",
        "subdomain": "your-company",
        "cache_ttl_seconds": 7200
    }
    employee_service = create_employee_service(employee_config)

    if employee_service:
        print("\nEmployee Service created.")
        # Get a detailed employee profile
        employee_profile = await employee_service.get_employee_profile("jane.doe@example.com")
        print(f"Employee Profile: {employee_profile}")

        # Get time off data
        time_off = await employee_service.get_time_off_data("jane.doe@example.com")
        print(f"Time Off Data: {time_off}")

        # Get employee directory as DataFrame
        df = await employee_service.get_employee_dataframe()
        print(f"Employee Directory Shape: {df.shape}")

# Run the example
asyncio.run(main())
```

### 2. Direct Provider Instantiation
While factories are preferred, you can instantiate providers from the `providers/` directory directly. This is useful for testing or when you know you will always use a specific built-in provider.

**Example: Direct Use of LocalFileIdentityService**

```python
import asyncio
import json
from solace_agent_mesh.common.services.providers.local_file_identity_service import LocalFileIdentityService

async def main():
    # First, create a sample users.json file
    users_data = [
        {
            "id": "jdoe",
            "email": "jane.doe@example.com", 
            "name": "Jane Doe",
            "title": "Senior Engineer",
            "manager_id": "ssmith"
        },
        {
            "id": "ssmith",
            "email": "sam.smith@example.com",
            "name": "Sam Smith", 
            "title": "Engineering Manager"
        }
    ]

    with open("users.json", "w") as f:
        json.dump(users_data, f)

    # Configuration does not need a 'type' key for direct instantiation
    config = {
        "file_path": "users.json",
        "lookup_key": "id",
        "cache_ttl_seconds": 1800
    }

    # Instantiate the class directly
    local_service = LocalFileIdentityService(config)
    print("LocalFileIdentityService created directly")

    # Get user profile by ID
    auth_claims = {"id": "jdoe"}
    profile = await local_service.get_user_profile(auth_claims)
    print(f"User profile: {profile}")
    
    # Search for users
    results = await local_service.search_users("jane", limit=5)
    print(f"Search results: {results}")

asyncio.run(main())
```

### 3. Creating Custom Service Providers
To create your own service provider, inherit from the appropriate base class and implement all abstract methods.

**Example: Custom Employee Service Provider**

```python
import pandas as pd
from typing import Any, Dict, List, Optional
from solace_agent_mesh.common.services.employee_service import BaseEmployeeService

class CustomEmployeeService(BaseEmployeeService):
    """Custom employee service that connects to your HR system."""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.api_endpoint = config.get("api_endpoint")
        self.api_key = config.get("api_key")
    
    async def get_employee_dataframe(self) -> pd.DataFrame:
        """Fetch all employees and return as DataFrame."""
        # Your implementation here
        # This should return a DataFrame with canonical schema columns:
        # id, displayName, workEmail, jobTitle, department, location, supervisorId, hireDate, mobilePhone
        employees_data = [
            {
                "id": "jdoe@company.com",
                "displayName": "Jane Doe",
                "workEmail": "jdoe@company.com",
                "jobTitle": "Software Engineer",
                "department": "Engineering",
                "location": "San Francisco",
                "supervisorId": "manager@company.com",
                "hireDate": "2023-01-15",
                "mobilePhone": "+1-555-0123"
            }
        ]
        return pd.DataFrame(employees_data)
    
    async def get_employee_profile(self, employee_id: str) -> Optional[Dict[str, Any]]:
        """Get single employee profile."""
        # Your implementation here
        return {
            "id": employee_id,
            "displayName": "Jane Doe",
            "workEmail": employee_id,
            "jobTitle": "Software Engineer"
        }
    
    async def get_time_off_data(self, employee_id: str) -> List[Dict[str, Any]]:
        """Get employee time off data."""
        # Your implementation here
        return [
            {
                'start': '2025-07-04',
                'end': '2025-07-04',
                'type': 'Holiday',
                'amount': 'full_day'
            }
        ]
    
    async def get_employee_profile_picture(self, employee_id: str) -> Optional[str]:
        """Get employee profile picture as data URI."""
        # Your implementation here
        return None  # or return "data:image/jpeg;base64,..."

# Usage
async def use_custom_service():
    config = {
        "api_endpoint": "https://your-hr-api.com",
        "api_key": "your-api-key",
        "cache_ttl_seconds": 3600
    }
    
    service = CustomEmployeeService(config)
    profile = await service.get_employee_profile("jdoe@company.com")
    print(f"Custom service profile: {profile}")
```

### 4. Working with Both Services Together
Often you'll want to use both identity and employee services together for comprehensive user information.

**Example: Combined Service Usage**

```python
import asyncio
from solace_agent_mesh.common.services.identity_service import create_identity_service
from solace_agent_mesh.common.services.employee_service import create_employee_service

async def get_complete_user_info(user_email: str):
    """Get comprehensive user information from both services."""
    
    # Configure services
    identity_config = {
        "type": "local_file",
        "file_path": "users.json",
        "lookup_key": "email"
    }
    
    employee_config = {
        "type": "your_hr_plugin",
        "api_key": "your-key"
    }
    
    # Create services
    identity_service = create_identity_service(identity_config)
    employee_service = create_employee_service(employee_config)
    
    # Gather information
    user_info = {}
    
    if identity_service:
        auth_claims = {"email": user_email}
        identity_profile = await identity_service.get_user_profile(auth_claims)
        if identity_profile:
            user_info.update(identity_profile)
    
    if employee_service:
        employee_profile = await employee_service.get_employee_profile(user_email)
        if employee_profile:
            user_info.update(employee_profile)
            
        # Get additional employee data
        time_off = await employee_service.get_time_off_data(user_email)
        user_info["time_off"] = time_off
        
        profile_pic = await employee_service.get_employee_profile_picture(user_email)
        if profile_pic:
            user_info["profile_picture"] = profile_pic
    
    return user_info

# Usage
async def main():
    complete_info = await get_complete_user_info("jane.doe@example.com")
    print(f"Complete user information: {complete_info}")

asyncio.run(main())
```

### 5. Using the Built-in LocalFileIdentityService
The `providers/` subdirectory includes a ready-to-use file-based identity service that's perfect for development and testing.

**Example: Setting up LocalFileIdentityService with Factory**

```python
import asyncio
import json
from solace_agent_mesh.common.services.identity_service import create_identity_service

async def setup_file_based_identity():
    # Create sample users.json file
    users_data = [
        {
            "id": "jdoe",
            "email": "jane.doe@example.com", 
            "name": "Jane Doe",
            "title": "Senior Engineer",
            "manager_id": "ssmith"
        },
        {
            "id": "ssmith",
            "email": "sam.smith@example.com",
            "name": "Sam Smith", 
            "title": "Engineering Manager"
        }
    ]

    with open("users.json", "w") as f:
        json.dump(users_data, f)

    # Use factory to create the service
    config = {
        "type": "local_file",  # This triggers the built-in provider
        "file_path": "users.json",
        "lookup_key": "email",  # Use email for lookups
        "cache_ttl_seconds": 3600
    }
    
    identity_service = create_identity_service(config)
    
    # Test the service
    auth_claims = {"email": "jane.doe@example.com"}
    profile = await identity_service.get_user_profile(auth_claims)
    print(f"Profile found: {profile}")
    
    # Search functionality
    search_results = await identity_service.search_users("jane")
    print(f"Search results: {search_results}")

asyncio.run(setup_file_based_identity())
```

### 6. Advanced Usage: Custom Identity Service with Component Integration

```python
import asyncio
from typing import Any, Dict, List, Optional
from solace_agent

================================================================================

## Section 23: solace_agent_mesh/common/utils/embeds/embeds_llm.txt

**Source file:** `solace_agent_mesh/common/utils/embeds/embeds_llm.txt`

# DEVELOPER GUIDE: embeds

## Quick Summary
The `embeds` directory provides a comprehensive system for finding, parsing, and resolving embedded expressions within strings. These expressions use `«...»` syntax and can represent dynamic values like mathematical calculations, datetimes, UUIDs, or content from stored artifacts. The system supports multi-step data transformation pipelines, recursive embed resolution, and includes safety features like depth and size limits. It's designed as a core component for dynamic content generation and data processing in agent workflows.

## Files Overview
- `__init__.py` - Main public entry point exporting key functions and constants
- `constants.py` - Defines embed syntax (delimiters, separators), regex patterns, and type classifications
- `converter.py` - Data format conversion and serialization functions
- `evaluators.py` - Specific evaluation logic for simple embed types (math, datetime, uuid, etc.)
- `modifiers.py` - Data transformation functions that can be chained together (jsonpath, slice, grep, etc.)
- `resolver.py` - Core orchestration engine handling embed resolution, modifier chains, and recursion
- `types.py` - DataFormat enum for tracking data types during transformations

## Developer API Reference

### __init__.py
**Purpose:** Main public entry point that exports the most commonly used functions and constants from other modules.

**Import:** `from solace_agent_mesh.common.utils.embeds import resolve_embeds_recursively_in_string, evaluate_embed, EMBED_REGEX`

**Functions:**
- `evaluate_embed(embed_type: str, expression: str, format_spec: Optional[str], context: Dict[str, Any], log_identifier: str, config: Optional[Dict] = None, current_depth: int = 0, visited_artifacts: Optional[Set[Tuple[str, int]]] = None) -> Union[Tuple[str, Optional[str], int], Tuple[None, str, Any]]` - Evaluates a single parsed embed expression
- `resolve_embeds_in_string(text: str, context: Any, resolver_func: Callable, types_to_resolve: Set[str], log_identifier: str = "[EmbedUtil]", config: Optional[Dict[str, Any]] = None) -> Tuple[str, int, List[Tuple[int, Any]]]` - Resolves embeds in a string for a single pass (non-recursive)
- `resolve_embeds_recursively_in_string(text: str, context: Any, resolver_func: Callable, types_to_resolve: Set[str], log_identifier: str, config: Optional[Dict], max_depth: int, current_depth: int = 0, visited_artifacts: Optional[Set[Tuple[str, int]]] = None, accumulated_size: int = 0, max_total_size: int = -1) -> str` - Recursively resolves all embeds in a string with depth and size limits

**Constants/Variables:**
- `EMBED_DELIMITER_OPEN: str` - Opening delimiter (`«`)
- `EMBED_DELIMITER_CLOSE: str` - Closing delimiter (`»`)
- `EMBED_TYPE_SEPARATOR: str` - Type/expression separator (`:`)
- `EMBED_FORMAT_SEPARATOR: str` - Format specifier separator (`|`)
- `EMBED_CHAIN_DELIMITER: str` - Modifier chain separator (`>>>`)
- `EMBED_REGEX: re.Pattern` - Compiled regex for finding embeds
- `EARLY_EMBED_TYPES: Set[str]` - Types resolved in initial pass
- `LATE_EMBED_TYPES: Set[str]` - Types resolved in subsequent pass

**Usage Examples:**
```python
from solace_agent_mesh.common.utils.embeds import resolve_embeds_recursively_in_string, evaluate_embed, EMBED_REGEX

# Basic embed resolution
context = {
    "artifact_service": my_artifact_service,
    "session_context": {"app_name": "myapp", "user_id": "user123", "session_id": "sess456"}
}

text = "The result is «math:10 * 1.15 | .2f» and ID is «uuid:new»"
resolved = await resolve_embeds_recursively_in_string(
    text=text,
    context=context,
    resolver_func=evaluate_embed,
    types_to_resolve={"math", "uuid"},
    log_identifier="[MyApp]",
    config={},
    max_depth=5
)
```

### constants.py
**Purpose:** Defines all static constants governing embed syntax and classification.

**Import:** `from solace_agent_mesh.common.utils.embeds.constants import EMBED_REGEX, EARLY_EMBED_TYPES`

**Constants/Variables:**
- `EMBED_DELIMITER_OPEN: str` - Opening delimiter (`«`)
- `EMBED_DELIMITER_CLOSE: str` - Closing delimiter (`»`)
- `EMBED_TYPE_SEPARATOR: str` - Type/expression separator (`:`)
- `EMBED_FORMAT_SEPARATOR: str` - Format specifier separator (`|`)
- `EMBED_CHAIN_DELIMITER: str` - Modifier chain separator (`>>>`)
- `EMBED_REGEX: re.Pattern` - Compiled regex with capture groups for type, expression, and format
- `EARLY_EMBED_TYPES: Set[str]` - Simple embed types resolved first (`math`, `datetime`, `uuid`, `artifact_meta`, `status_update`)
- `LATE_EMBED_TYPES: Set[str]` - Complex embed types resolved later (`artifact_content`)
- `TEXT_CONTAINER_MIME_TYPES: Set[str]` - MIME types considered text-based

**Usage Examples:**
```python
from solace_agent_mesh.common.utils.embeds.constants import EMBED_REGEX

text = "Price: «math:10 * 1.15 | .2f» ID: «uuid:new»"
for match in EMBED_REGEX.finditer(text):
    embed_type = match.group(1)      # "math" or "uuid"
    expression = match.group(2)      # "10 * 1.15 " or "new"
    format_spec = match.group(3)     # " .2f" or None
    print(f"Type: {embed_type}, Expr: '{expression}', Format: '{format_spec}'")
```

### converter.py
**Purpose:** Provides data conversion between different formats and serialization to final string representations.

**Import:** `from solace_agent_mesh.common.utils.embeds.converter import convert_data, serialize_data`

**Functions:**
- `convert_data(current_data: Any, current_format: Optional[DataFormat], target_format: DataFormat, log_id: str = "[Converter]", original_mime_type: Optional[str] = None) -> Tuple[Any, DataFormat, Optional[str]]` - Converts data between DataFormat types using MIME type hints
- `serialize_data(data: Any, data_format: Optional[DataFormat], target_string_format: Optional[str], original_mime_type: Optional[str], log_id: str = "[Serializer]") -> Tuple[str, Optional[str]]` - Serializes data to final string format (text, json, csv, datauri, or Python format specs)

**Usage Examples:**
```python
from solace_agent_mesh.common.utils.embeds.converter import convert_data, serialize_data
from solace_agent_mesh.common.utils.embeds.types import DataFormat

# Convert CSV bytes to list of dictionaries
csv_bytes = b"id,name\n1,Alice\n2,Bob"
list_data, new_format, err = convert_data(
    current_data=csv_bytes,
    current_format=DataFormat.BYTES,
    target_format=DataFormat.LIST_OF_DICTS,
    original_mime_type="text/csv"
)

# Serialize to pretty JSON
json_str, err = serialize_data(
    data=list_data,
    data_format=DataFormat.LIST_OF_DICTS,
    target_string_format="json_pretty",
    original_mime_type=None
)
```

### evaluators.py
**Purpose:** Contains evaluation logic for simple embed types and the evaluator registry.

**Import:** `from solace_agent_mesh.common.utils.embeds.evaluators import EMBED_EVALUATORS`

**Functions:**
- `_evaluate_math_embed(expression: str, context: Any, log_identifier: str, format_spec: Optional[str] = None) -> Tuple[str, Optional[str], int]` - Evaluates mathematical expressions using asteval
- `_evaluate_datetime_embed(expression: str, context: Any, log_identifier: str, format_spec: Optional[str] = None) -> Tuple[str, Optional[str], int]` - Formats current datetime
- `_evaluate_uuid_embed(expression: str, context: Any, log_identifier: str, format_spec: Optional[str] = None) -> Tuple[str, Optional[str], int]` - Generates UUID4 strings
- `_evaluate_artifact_meta_embed(expression: str, context: Dict[str, Any], log_identifier: str, format_spec: Optional[str] = None) -> Tuple[str, Optional[str], int]` - Loads and formats artifact metadata
- `_evaluate_artifact_content_embed(expression: str, context: Any, log_identifier: str, config: Optional[Dict] = None) -> Tuple[Optional[bytes], Optional[str], Optional[str]]` - Loads raw artifact content

**Constants/Variables:**
- `EMBED_EVALUATORS: Dict[str, Callable]` - Registry mapping embed types to evaluator functions
- `MATH_SAFE_SYMBOLS: Dict[str, Any]` - Safe mathematical functions and constants for math embeds

**Usage Examples:**
```python
from solace_agent_mesh.common.utils.embeds.evaluators import EMBED_EVALUATORS

# Math evaluation
result, error, size = EMBED_EVALUATORS["math"]("2 + 3 * 4", {}, "[Test]", ".2f")
# result: "14.00", error: None, size: 5

# DateTime formatting  
result, error, size = EMBED_EVALUATORS["datetime"]("%Y-%m-%d", {}, "[Test]")
# result: "2024-01-15", error: None, size: 10
```

### modifiers.py
**Purpose:** Implements data transformation functions that can be chained together in artifact_content embeds.

**Import:** `from solace_agent_mesh.common.utils.embeds.modifiers import MODIFIER_DEFINITIONS, _parse_modifier_chain`

**Functions:**
- `_apply_jsonpath(current_data: Any, expression: str, mime_type: Optional[str], log_id: str) -> Tuple[Any, Optional[str], Optional[str]]` - Applies JSONPath expressions to JSON data
- `_apply_select_cols(current_data: List[Dict], cols_str: str, mime_type: Optional[str], log_id: str) -> Tuple[Any, Optional[str], Optional[str]]` - Selects specific columns from tabular data
- `_apply_filter_rows_eq(current_data: List[Dict], filter_spec: str, mime_type: Optional[str], log_id: str) -> Tuple[Any, Optional[str], Optional[str]]` - Filters rows by column value equality
- `_apply_slice_rows(current_data: List[Dict], slice_spec: str, mime_type: Optional[str], log_id: str) -> Tuple[Any, Optional[str], Optional[str]]` - Slices rows using Python slice notation
- `_apply_slice_lines(current_data: str, slice_spec: str, mime_type: Optional[str], log_id: str) -> Tuple[Any, Optional[str], Optional[str]]` - Slices text lines
- `_apply_grep(current_data: str, pattern: str, mime_type: Optional[str], log_id: str) -> Tuple[Any, Optional[str], Optional[str]]` - Filters lines matching regex pattern
- `_apply_head(current_data: str, n_str: str, mime_type: Optional[str], log_id: str) -> Tuple[Any, Optional[str], Optional[str]]` - Returns first N lines
- `_apply_tail(current_data: str, n_str: str, mime_type: Optional[str], log_id: str) -> Tuple[Any, Optional[str], Optional[str]]` - Returns last N lines
- `_apply_template(current_data: Any, template_spec: str, mime_type: Optional[str], log_id: str, context: Any) -> Tuple[Any, Optional[str], Optional[str]]` - Applies Mustache templates from artifacts
- `_parse_modifier_chain(expression: str) -> Tuple[str, List[Tuple[str, str]], Optional[str]]` - Parses artifact_content expression into components

**Constants/Variables:**
- `MODIFIER_IMPLEMENTATIONS: Dict[str, Callable]` - Registry of modifier functions
- `MODIFIER_DEFINITIONS: Dict[str, Dict[str, Any]]` - Modifier metadata including accepted/produced formats

**Usage Examples:**
```python
from solace_agent_mesh.common.utils.embeds.modifiers import _parse_modifier_chain

# Parse a complex artifact_content expression
expression = "data.csv:1 >>> select_cols:name,age >>> filter_rows_eq:age:25 >>> format:json"
artifact_spec, modifiers, output_format = _parse_modifier_chain(expression)
# artifact_spec: "data.csv:1"
# modifiers: [("select_cols", "name,age"), ("filter_rows_eq", "age:25")]
# output_format: "json"
```

### resolver.py
**Purpose:** Core orchestration engine that handles the complete embed resolution process including modifier chains and recursion.

**Import:** `from solace_agent_mesh.common.utils.embeds.resolver import resolve_embeds_in_string, evaluate_embed`

**Functions:**
- `resolve_embeds_in_string(text: str, context: Any, resolver_func: Callable, types_to_resolve: Set[str], log_identifier: str = "[EmbedUtil]", config: Optional[Dict[str, Any]] = None) -> Tuple[str, int, List[Tuple[int, Any]]]` - Single-pass embed resolution with buffering support
- `resolve_embeds_recursively_in_string(text: str, context: Any, resolver_func: Callable, types_to_resolve: Set[str], log_identifier: str, config: Optional[Dict], max_depth: int, current_depth: int = 0, visited_artifacts: Optional[Set[Tuple[str, int]]] = None, accumulated_size: int = 0, max_total_size: int = -1) -> str` - Recursive embed resolution with safety limits
- `evaluate_embed(embed_type: str, expression: str, format_spec: Optional[str], context: Dict[str, Any], log_identifier: str, config: Optional[Dict] = None, current_depth: int = 0, visited_artifacts: Optional[Set[Tuple[str, int]]] = None) -> Union[Tuple[str, Optional[str], int], Tuple[None, str, Any]]` - Main embed evaluation dispatcher

**Usage Examples:**
```python
from solace_agent_mesh.common.utils.embeds.resolver import resolve_embeds_in_string, evaluate_embed

# Single-pass resolution
text = "Result: «math:2+3» and «uuid:new»"
context = {"artifact_service": service, "session_context": session_ctx}

resolved_text, processed_index, signals = await resolve_embeds_in_string(
    text=text,
    context=context,
    resolver_func=evaluate_embed,
    types_to_resolve={"math", "uuid"},
    log_identifier="[MyApp]",
    config={}
)

# Complex artifact content with modifiers
result, error, size = await evaluate_embed(
    embed_type="artifact_content",
    expression="sales.csv >>> select_cols:product,revenue >>> format:json",
    format_spec=None,
    context=context,
    log_identifier="[Sales]"
)
```

### types.py

================================================================================

## Section 24: solace_agent_mesh/common/utils/utils_llm.txt

**Source file:** `solace_agent_mesh/common/utils/utils_llm.txt`

# DEVELOPER GUIDE: utils

## Quick Summary
The `utils` directory provides essential utility functions and tools for the Solace Agent Mesh system. It contains both direct utility files for common operations (MIME type handling, caching, message validation, authentication) and a sophisticated `embeds` subdirectory that implements a dynamic expression evaluation system. The utilities work together to provide platform compatibility, security features, data processing capabilities, and dynamic content generation for agent workflows.

## Files and Subdirectories Overview

### Direct Files:
- **`__init__.py`** - Main entry point exporting commonly used utilities like MIME type checking
- **`artifact_utils.py`** - Utilities for working with ADK artifacts, including version resolution
- **`asyncio_macos_fix.py`** - Automatic fix for asyncio subprocess issues on macOS
- **`in_memory_cache.py`** - Thread-safe singleton cache with TTL support
- **`initializer.py`** - Enterprise feature initialization and configuration loading
- **`log_formatters.py`** - Custom logging formatters for platforms like Datadog
- **`message_utils.py`** - Message size calculation and validation utilities
- **`mime_helpers.py`** - MIME type classification and file extension utilities
- **`push_notification_auth.py`** - JWT-based authentication for push notifications
- **`pydantic_utils.py`** - Pydantic BaseModel with dict-like access for configuration
- **`type_utils.py`** - Robust type checking utilities for development environments

### Subdirectories:
- **`embeds/`** - Dynamic expression evaluation system using `«...»` syntax for mathematical calculations, datetime formatting, UUID generation, and artifact content processing

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Main entry point for the utils package, exporting the most commonly used utility functions
**Import:** `from solace_agent_mesh.common.utils import is_text_based_mime_type`

**Functions:**
- `is_text_based_mime_type(mime_type: Optional[str]) -> bool` - Checks if a MIME type represents text-based content

#### artifact_utils.py
**Purpose:** Common utility functions for working with ADK artifacts
**Import:** `from solace_agent_mesh.common.utils.artifact_utils import get_latest_artifact_version`

**Functions:**
- `get_latest_artifact_version(artifact_service: BaseArtifactService, app_name: str, user_id: str, session_id: str, filename: str) -> Optional[int]` - Resolves the latest version number for a given artifact

#### asyncio_macos_fix.py
**Purpose:** Automatic fix for asyncio subprocess creation issues on macOS (imported for side effects)
**Import:** `from solace_agent_mesh.common.utils import asyncio_macos_fix`

**Functions:**
- `apply_macos_asyncio_fix() -> bool` - Applies the asyncio fix for macOS subprocess support
- `ensure_asyncio_compatibility() -> bool` - Ensures asyncio compatibility for subprocess creation

#### in_memory_cache.py
**Purpose:** Thread-safe singleton in-memory cache with TTL support
**Import:** `from solace_agent_mesh.common.utils.in_memory_cache import InMemoryCache`

**Classes:**
- **`InMemoryCache`** - Singleton cache class
  - `set(key: str, value: Any, ttl: Optional[int] = None) -> None` - Store value with optional TTL
  - `get(key: str, default: Any = None) -> Any` - Retrieve value or default
  - `delete(key: str) -> bool` - Delete specific key
  - `clear() -> bool` - Clear all cached data

#### initializer.py
**Purpose:** Handles initialization of enterprise features if available
**Import:** `from solace_agent_mesh.common.utils.initializer import initialize`

**Functions:**
- `initialize() -> None` - Initializes enterprise features using SAM_AUTHORIZATION_CONFIG environment variable

#### log_formatters.py
**Purpose:** Custom logging formatters for structured output
**Import:** `from solace_agent_mesh.common.utils.log_formatters import DatadogJsonFormatter`

**Classes:**
- **`DatadogJsonFormatter(logging.Formatter)`** - JSON formatter with Datadog-compatible attributes including trace IDs

#### message_utils.py
**Purpose:** Message size calculation and validation utilities
**Import:** `from solace_agent_mesh.common.utils.message_utils import calculate_message_size, validate_message_size`

**Functions:**
- `calculate_message_size(payload: Dict[str, Any]) -> int` - Calculate exact message size using JSON + UTF-8 encoding
- `validate_message_size(payload: Dict[str, Any], max_size_bytes: int, component_identifier: str = "Unknown") -> Tuple[bool, int]` - Validate message doesn't exceed size limits

**Constants:**
- `MAX_UTF8_BYTES_PER_CHARACTER: int` - Maximum UTF-8 bytes per character (4)

#### mime_helpers.py
**Purpose:** MIME type classification and file extension utilities
**Import:** `from solace_agent_mesh.common.utils.mime_helpers import is_text_based_mime_type, get_extension_for_mime_type, is_text_based_file`

**Functions:**
- `is_text_based_mime_type(mime_type: Optional[str]) -> bool` - Check if MIME type is text-based
- `is_text_based_file(mime_type: Optional[str], content_bytes: Optional[bytes] = None) -> bool` - Determine if file is text-based using MIME type and content analysis
- `get_extension_for_mime_type(mime_type: Optional[str], default_extension: str = ".dat") -> str` - Get file extension for MIME type

**Constants:**
- `TEXT_CONTAINER_MIME_TYPES: Set[str]` - Set of non-text/* MIME types that contain text

#### push_notification_auth.py
**Purpose:** JWT-based authentication for push notifications with request integrity verification
**Import:** `from solace_agent_mesh.common.utils.push_notification_auth import PushNotificationSenderAuth, PushNotificationReceiverAuth`

**Classes:**
- **`PushNotificationSenderAuth`** - Handles sending authenticated notifications
  - `generate_jwk() -> None` - Generate RSA key pair for signing
  - `handle_jwks_endpoint(request: Request) -> JSONResponse` - Serve public keys endpoint
  - `send_push_notification(url: str, data: dict[str, Any]) -> None` - Send authenticated notification
  - `verify_push_notification_url(url: str) -> bool` - Verify notification URL
- **`PushNotificationReceiverAuth`** - Handles receiving and verifying notifications
  - `load_jwks(jwks_url: str) -> None` - Load public keys from JWKS endpoint
  - `verify_push_notification(request: Request) -> bool` - Verify notification authenticity

#### pydantic_utils.py
**Purpose:** Provides a Pydantic BaseModel for SAM configuration with dict-like access
**Import:** `from solace_agent_mesh.common.utils.pydantic_utils import SamConfigBase`

**Classes:**
- **`SamConfigBase(BaseModel)`** - Pydantic BaseModel with dict-like access
  - `model_validate_and_clean(cls: Type[T], obj: Any) -> T` - Validates dict after removing None values
  - `get(key: str, default: Any = None) -> Any` - Dict-like .get() method
  - `__getitem__(key: str) -> Any` - Dict-like ['key'] access
  - `__setitem__(key: str, value: Any)` - Dict-like ['key'] = value assignment
  - `__contains__(key: str) -> bool` - Dict-like 'in' support
  - `keys()`, `values()`, `items()`, `__iter__()` - Dict-like iteration methods
  - `pop(key: str, default: Any = None) -> Any` - Dict-like .pop() method

#### type_utils.py
**Purpose:** Utilities for robust type checking, especially in development environments
**Import:** `from solace_agent_mesh.common.utils.type_utils import is_subclass_by_name`

**Functions:**
- `is_subclass_by_name(cls_to_check: type, base_class_name: str) -> bool` - Checks if a class is a subclass by looking for the base class name in the MRO

### Subdirectory APIs

#### embeds/
**Purpose:** Comprehensive dynamic expression evaluation system using `«...»` syntax for mathematical calculations, datetime formatting, UUID generation, and artifact content processing with transformation pipelines
**Key Exports:** Main resolution functions, evaluator registry, modifier system, and type constants
**Import Examples:**
```python
from solace_agent_mesh.common.utils.embeds import resolve_embeds_recursively_in_string, evaluate_embed, EMBED_REGEX
from solace_agent_mesh.common.utils.embeds.constants import EARLY_EMBED_TYPES, LATE_EMBED_TYPES
from solace_agent_mesh.common.utils.embeds.types import DataFormat
```

## Complete Usage Guide

### 1. Basic Utility Operations

```python
# Import commonly used utilities
from solace_agent_mesh.common.utils import is_text_based_mime_type
from solace_agent_mesh.common.utils.in_memory_cache import InMemoryCache
from solace_agent_mesh.common.utils.message_utils import validate_message_size, calculate_message_size
from solace_agent_mesh.common.utils.mime_helpers import get_extension_for_mime_type, is_text_based_file

# MIME type checking
if is_text_based_mime_type("application/json"):
    print("JSON is text-based")

# File analysis with content
with open("data.bin", "rb") as f:
    content = f.read()
if is_text_based_file("application/octet-stream", content):
    print("File contains text despite binary MIME type")

# Singleton cache usage
cache = InMemoryCache()
cache.set("user_session", {"user_id": "123", "role": "admin"}, ttl=3600)  # 1 hour TTL
session_data = cache.get("user_session", {})

# Message size validation
payload = {"message": "Hello world", "data": [1, 2, 3], "metadata": {"timestamp": "2024-01-15"}}
is_valid, size = validate_message_size(payload, max_size_bytes=1024, component_identifier="MessageProcessor")
if not is_valid:
    print(f"Message too large: {size} bytes exceeds 1024 byte limit")

# Get appropriate file extension
extension = get_extension_for_mime_type("image/png")  # Returns ".png"
filename = f"image_{uuid.uuid4()}{extension}"
```

### 2. Configuration and Type Utilities

```python
from solace_agent_mesh.common.utils.pydantic_utils import SamConfigBase
from solace_agent_mesh.common.utils.type_utils import is_subclass_by_name
from pydantic import Field
from typing import Optional

# Define configuration with Pydantic validation and dict-like access
class AgentConfig(SamConfigBase):
    name: str
    timeout: int = 30
    debug: bool = False
    api_key: Optional[str] = None

# Load config from YAML/dict with None value cleaning
config_dict = {
    "name": "my_agent",
    "timeout": None,  # Will use default value of 30
    "debug": True,
    "api_key": None   # Will use default value of None
}

config = AgentConfig.model_validate_and_clean(config_dict)

# Use both Pydantic and dict-style access
print(config.name)              # Pydantic style: "my_agent"
print(config["timeout"])        # Dict style: 30 (default applied)
print(config.get("debug", False))  # Dict .get(): True

# Check if field was explicitly set
if "api_key" in config:
    print("API key was provided")
else:
    print("API key not provided, using default")

# Robust type checking for development
class BaseAgent:
    pass

class MyAgent(BaseAgent):
    pass

# This works even if BaseAgent is loaded from different paths
if is_subclass_by_name(MyAgent, "BaseAgent"):
    print("MyAgent is a BaseAgent subclass")
```

### 3. Platform Compatibility and System Initialization

```python
# Early in application startup - import for side effects
from solace_agent_mesh.common.utils import asyncio_macos_fix  # Auto-applies macOS fix
from solace_agent_mesh.common.utils.initializer import initialize

# Initialize enterprise features if available
try:
    initialize()
    print("Enterprise features initialized")
except Exception as e:
    print(f"Running in community mode: {e}")

# Now asyncio subprocess creation works reliably on macOS
import asyncio

async def run_command(cmd: str):
    process = await asyncio.create_subprocess_exec(
        *cmd.split(),
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )
    stdout, stderr = await process.communicate()
    return stdout.decode(), stderr.decode(), process.returncode

# This will work on macOS without NotImplementedError
result = await run_command("echo Hello World")
```

### 4. Structured Logging Setup

```python
import logging
import os
from solace_agent_mesh.common.utils.log_formatters import DatadogJsonFormatter

# Configure structured JSON logging
logger = logging.getLogger("my_application")
handler = logging.StreamHandler()
handler.setFormatter(DatadogJsonFormatter())
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# Set service name for Datadog
os.environ["SERVICE_NAME"] = "my_agent_service"

# Log with structured data - automatically includes trace IDs if available
logger.info("User action completed", extra={
    "user_id": "user123",
    "action": "file_upload",
    "file_size": 1024,
    "dd.trace_id": "abc123"  # Will be included in JSON output
})

# Output will be JSON with timestamp, level, service, code location, etc.
```

### 5. Secure Push Notification System

```python
from solace_agent_mesh.common.utils.push_notification_auth import (
    PushNotificationSenderAuth, 
    PushNotificationReceiverAuth
)
from starlette.applications import Starlette
from starlette.requests import Request
from starlette.responses import Response, JSONResponse

# Sender setup and usage
sender_auth = PushNotificationSenderAuth()
sender_auth.generate_jwk()  # Generate RSA key pair

async def notify_clients(event_data: dict):
    client_urls = ["https://client1.example.com/webhook", "https://client2.example.com/webhook"]
    
    for url in client_urls:
        # Verify URL accepts notifications
        if await sender_auth.verify_push_notification_url(url):
            # Send authenticated notification
            await sender_auth.send_push_notification(url, {
                "event": "data_updated",
                "timestamp": "2024-01-15T10:30:00Z",
                "data": event_data
            })
        else:
            print(f"Failed to verify URL: {url}")

# Receiver setup
app = Starlette()
receiver_auth = PushNotificationReceiverAuth()

# Load sender's public keys
await receiver_auth.load_jwks("https://sender.example.com/.well-known/jwks.json")

@app.route("/webhook", methods=["POST"])
async def webhook_handler(request: Request):
    try:
        # Verify JWT signature and request integrity
        if await receiver_auth.verify_push_notification(request):
            data = await request.json()
            # Process authenticated notification
            print(f"Received verified notification: {data}")
            return Response

================================================================================

## Section 25: solace_agent_mesh/core_a2a/core_a2a_llm.txt

**Source file:** `solace_agent_mesh/core_a2a/core_a2a_llm.txt`

# DEVELOPER GUIDE: core_a2a

## Quick Summary
The `core_a2a` directory provides a reusable service layer for core Agent-to-Agent (A2A) interactions. It handles task submission (both regular and streaming), task cancellation, and agent discovery processing while being decoupled from specific gateway implementations and SAC messaging details.

## Files Overview
- `__init__.py` - Package initialization file for the core A2A service layer
- `service.py` - Main service class that encapsulates A2A protocol logic and agent registry operations

## Developer API Reference

### __init__.py
**Purpose:** Package initialization for the core A2A service layer
**Import:** `import solace_agent_mesh.core_a2a`

No public classes, functions, or constants defined.

### service.py
**Purpose:** Provides the main CoreA2AService class for handling A2A protocol operations
**Import:** `from solace_agent_mesh.core_a2a.service import CoreA2AService`

**Classes:**
- `CoreA2AService(agent_registry: AgentRegistry, namespace: str)` - Main service class for A2A operations
  - `submit_task(agent_name: str, a2a_message: A2AMessage, session_id: str, client_id: str, reply_to_topic: str, user_id: str = "default_user", a2a_user_config: Optional[Dict[str, Any]] = None, metadata_override: Optional[Dict[str, Any]] = None) -> Tuple[str, Dict, Dict]` - Constructs topic, payload, and user properties for non-streaming task requests
  - `submit_streaming_task(agent_name: str, a2a_message: A2AMessage, session_id: str, client_id: str, reply_to_topic: str, status_to_topic: str, user_id: str = "default_user", a2a_user_config: Optional[Dict[str, Any]] = None, metadata_override: Optional[Dict[str, Any]] = None) -> Tuple[str, Dict, Dict]` - Constructs topic, payload, and user properties for streaming task requests
  - `cancel_task(agent_name: str, task_id: str, client_id: str, user_id: str = "default_user") -> Tuple[str, Dict, Dict]` - Constructs topic, payload, and user properties for task cancellation
  - `get_agent(agent_name: str) -> Optional[AgentCard]` - Retrieves a specific agent card by name from the registry
  - `get_all_agents() -> List[AgentCard]` - Retrieves all currently discovered agent cards from the registry
  - `process_discovery_message(agent_card: AgentCard)` - Processes an incoming agent card discovery message
  - `agent_registry: AgentRegistry` - The shared agent registry instance
  - `namespace: str` - The namespace string
  - `log_identifier: str` - Identifier used for logging

**Functions:**
None (all functionality is encapsulated in the CoreA2AService class)

**Constants/Variables:**
None

**Usage Examples:**
```python
# Import required dependencies
from solace_agent_mesh.core_a2a.service import CoreA2AService
from solace_agent_mesh.common.agent_registry import AgentRegistry
from a2a.types import A2AMessage, AgentCard

# Initialize the service
agent_registry = AgentRegistry()
namespace = "my_NAMESPACE"
service = CoreA2AService(agent_registry, namespace)

# Submit a regular task
message = A2AMessage(parts=[{"type": "text", "content": "Hello"}])
topic, payload, user_props = service.submit_task(
    agent_name="my_agent",
    a2a_message=message,
    session_id="session_123",
    client_id="client_456",
    reply_to_topic="responses/client_456",
    user_id="user_789"
)

# Submit a streaming task
topic, payload, user_props = service.submit_streaming_task(
    agent_name="my_agent",
    a2a_message=message,
    session_id="session_123",
    client_id="client_456",
    reply_to_topic="responses/client_456",
    status_to_topic="status/client_456",
    user_id="user_789"
)

# Cancel a task
topic, payload, user_props = service.cancel_task(
    agent_name="my_agent",
    task_id="task-abc123",
    client_id="client_456"
)

# Get agent information
agent = service.get_agent("my_agent")
all_agents = service.get_all_agents()

# Process discovery message
agent_card = AgentCard(name="new_agent", description="A new agent")
service.process_discovery_message(agent_card)
```

================================================================================

## Section 26: solace_agent_mesh/gateway/base/base_llm.txt

**Source file:** `solace_agent_mesh/gateway/base/base_llm.txt`

# DEVELOPER GUIDE: base

## Quick Summary
The `base` directory provides foundational abstract classes for building Gateway implementations within the Solace AI Connector. It establishes a framework for handling common gateway tasks such as application configuration, Solace broker integration, A2A (Agent-to-Agent) message protocol handling, and managing the lifecycle of requests from external platforms. Developers should subclass `BaseGatewayApp` and `BaseGatewayComponent` to create new gateways.

## Files Overview
- `__init__.py` - Marks the directory as a Python package
- `app.py` - Contains the base application class that handles configuration, schema merging, and broker setup
- `component.py` - Contains the core logic class for processing A2A messages and integrating with external platforms
- `task_context.py` - Provides a thread-safe manager for mapping A2A task IDs to their original request context

## Developer API Reference

### __init__.py
**Purpose:** Initializes the `gateway.base` Python package
**Import:** `from solace_agent_mesh.gateway.base import ...`

---

### app.py
**Purpose:** Provides the base application class for gateway implementations with automated configuration schema merging, Solace broker setup, and component instantiation
**Import:** `from solace_agent_mesh.gateway.base.app import BaseGatewayApp, BaseGatewayComponent`

**Classes:**
- `BaseGatewayComponent(ComponentBase)` - Base marker class for gateway components
- `BaseGatewayApp(app_info: Dict[str, Any], **kwargs)` - Main application class to be subclassed for new gateways
  - `_get_gateway_component_class(self) -> Type[BaseGatewayComponent]` - **[Abstract Method]** Must return the specific gateway component class
  - `namespace: str` - Absolute topic prefix for A2A communication (e.g., 'myorg/dev')
  - `gateway_id: str` - Unique ID for this gateway instance (auto-generated if not provided)
  - `artifact_service_config: Dict` - Configuration for the shared ADK Artifact Service
  - `enable_embed_resolution: bool` - Flag to enable/disable late-stage 'artifact_content' embed resolution
  - `gateway_max_artifact_resolve_size_bytes: int` - Maximum size for resolving artifacts (default: 104857600)
  - `gateway_recursive_embed_depth: int` - Maximum depth for recursive embed resolution (default: 12)
  - `artifact_handling_mode: str` - How gateway handles file parts: "reference", "embed", or "passthrough"
  - `gateway_max_message_size_bytes: int` - Maximum message size in bytes (default: 10MB)

**Constants/Variables:**
- `BASE_GATEWAY_APP_SCHEMA: Dict[str, List[Dict[str, Any]]]` - Base configuration schema automatically merged with subclass parameters
- `SPECIFIC_APP_SCHEMA_PARAMS_ATTRIBUTE_NAME: str` - Class attribute name ("SPECIFIC_APP_SCHEMA_PARAMS") for subclass-specific config parameters

**Usage Examples:**
```python
from typing import Type, List, Dict, Any
from solace_agent_mesh.gateway.base.app import BaseGatewayApp, BaseGatewayComponent

class MyGatewayComponent(BaseGatewayComponent):
    # Implementation details...
    pass

class MyGatewayApp(BaseGatewayApp):
    """Custom gateway application for My Platform."""
    
    # Define additional configuration parameters
    SPECIFIC_APP_SCHEMA_PARAMS: List[Dict[str, Any]] = [
        {
            "name": "my_platform_api_key",
            "required": True,
            "type": "string",
            "description": "API key for connecting to My Platform."
        }
    ]

    def _get_gateway_component_class(self) -> Type[BaseGatewayComponent]:
        return MyGatewayComponent

# Usage in YAML config:
# app_config:
#   namespace: "myorg/prod"
#   gateway_id: "my-gateway-instance-01"
#   artifact_service:
#     type: "local_file"
#     base_path: "/data/artifacts"
#   my_platform_api_key: "secret-key-here"
```

---

### component.py
**Purpose:** Provides the abstract base class for gateway components containing core A2A protocol logic, service management, and external platform integration interface
**Import:** `from solace_agent_mesh.gateway.base.component import BaseGatewayComponent`

**Classes:**
- `BaseGatewayComponent(resolve_artifact_uris_in_gateway: bool = True, **kwargs: Any)` - Abstract base class for gateway components
  - **Public Methods:**
    - `get_config(self, key: str, default: Any = None) -> Any` - Retrieves configuration from nested app_config or component_config
    - `authenticate_and_enrich_user(self, external_event_data: Any) -> Optional[Dict[str, Any]]` - Orchestrates user authentication and identity enrichment
    - `submit_a2a_task(self, target_agent_name: str, a2a_parts: List[ContentPart], external_request_context: Dict[str, Any], user_identity: Any, is_streaming: bool = True, api_version: str = "v2") -> str` - Submits task to target agent, returns task_id
  - **Abstract Methods (Must be Implemented):**
    - `_extract_initial_claims(self, external_event_data: Any) -> Optional[Dict[str, Any]]` - Extract identity claims from platform event (must return dict with 'id' key)
    - `_start_listener(self) -> None` - Start external platform listener (e.g., web server, WebSocket)
    - `_stop_listener(self) -> None` - Stop external platform listener
    - `_translate_external_input(self, external_event: Any) -> Tuple[str, List[ContentPart], Dict[str, Any]]` - Convert external event to A2A format: (target_agent_name, a2a_parts, context)
    - `_send_update_to_external(self, external_request_context: Dict[str, Any], event_data: Union[TaskStatusUpdateEvent, TaskArtifactUpdateEvent], is_final_chunk_of_update: bool) -> None` - Send streaming update to external platform
    - `_send_final_response_to_external(self, external_request_context: Dict[str, Any], task_data: Task) -> None` - Send final response to external platform
    - `_send_error_to_external(self, external_request_context: Dict[str, Any], error_data: JSONRPCError) -> None` - Send error to external platform
  - **Properties:**
    - `namespace: str` - A2A communication namespace
    - `gateway_id: str` - Unique gateway instance ID
    - `agent_registry: AgentRegistry` - Registry for discovered agents
    - `core_a2a_service: CoreA2AService` - Core A2A protocol service
    - `shared_artifact_service: Optional[BaseArtifactService]` - Artifact service instance
    - `task_context_manager: TaskContextManager` - Thread-safe task context storage
    - `identity_service: Optional[BaseIdentityService]` - Identity enrichment service

**Usage Examples:**
```python
from typing import Any, Dict, List, Optional, Tuple, Union
from solace_agent_mesh.gateway.base.component import BaseGatewayComponent
from solace_agent_mesh.common.a2a.types import ContentPart
from a2a.types import TextPart, Task, TaskStatusUpdateEvent, TaskArtifactUpdateEvent, JSONRPCError

class MyGatewayComponent(BaseGatewayComponent):
    
    async def _extract_initial_claims(self, external_event_data: Any) -> Optional[Dict[str, Any]]:
        """Extract user identity from platform-specific event."""
        # Example for HTTP request
        if hasattr(external_event_data, 'headers'):
            user_id = external_event_data.headers.get('X-User-ID')
            if user_id:
                return {"id": user_id, "source": "http_header"}
        return None
    
    def _start_listener(self) -> None:
        """Start your platform listener (web server, etc.)."""
        # Example: Start FastAPI server, WebSocket connection, etc.
        pass
    
    def _stop_listener(self) -> None:
        """Stop your platform listener."""
        pass
    
    async def _translate_external_input(self, external_event: Any) -> Tuple[str, List[ContentPart], Dict[str, Any]]:
        """Convert external event to A2A format."""
        # Example translation
        target_agent = "my-agent"
        message_text = getattr(external_event, 'message', 'Hello')
        a2a_parts = [TextPart(text=message_text)]
        context = {
            "platform": "my_platform",
            "user_id_for_artifacts": "user123",
            "a2a_session_id": "session456"
        }
        return target_agent, a2a_parts, context
    
    async def _send_update_to_external(self, external_request_context: Dict[str, Any], 
                                     event_data: Union[TaskStatusUpdateEvent, TaskArtifactUpdateEvent], 
                                     is_final_chunk_of_update: bool) -> None:
        """Send streaming update back to external platform."""
        # Extract text from event and send to your platform
        pass
    
    async def _send_final_response_to_external(self, external_request_context: Dict[str, Any], 
                                             task_data: Task) -> None:
        """Send final response back to external platform."""
        # Extract final result and send to your platform
        pass
    
    async def _send_error_to_external(self, external_request_context: Dict[str, Any], 
                                     error_data: JSONRPCError) -> None:
        """Send error back to external platform."""
        # Send error message to your platform
        pass

# Usage in your handler:
async def handle_external_request(request):
    # Authenticate user
    user_identity = await component.authenticate_and_enrich_user(request)
    if not user_identity:
        return "Authentication failed"
    
    # Translate request
    target_agent, a2a_parts, context = await component._translate_external_input(request)
    
    # Submit to A2A system
    task_id = await component.submit_a2a_task(
        target_agent_name=target_agent,
        a2a_parts=a2a_parts,
        external_request_context=context,
        user_identity=user_identity,
        is_streaming=True
    )
    
    return f"Task submitted: {task_id}"
```

---

### task_context.py
**Purpose:** Provides thread-safe storage for mapping A2A task IDs to their original external request context
**Import:** `from solace_agent_mesh.gateway.base.task_context import TaskContextManager`

**Classes:**
- `TaskContextManager()` - Thread-safe context storage manager
  - `store_context(self, task_id: str, context_data: Dict[str, Any]) -> None` - Store context for a task ID
  - `get_context(self, task_id: str) -> Optional[Dict[str, Any]]` - Retrieve context for a task ID
  - `remove_context(self, task_id: str) -> Optional[Dict[str, Any]]` - Remove and return context for a task ID
  - `clear_all_contexts_for_testing(self) -> None` - Clear all contexts (testing only)

**Usage Examples:**
```python
from solace_agent_mesh.gateway.base.task_context import TaskContextManager

# Initialize manager
context_manager = TaskContextManager()

# Store context when submitting task
task_id = "gdk-task-abc123"
context = {
    "platform": "slack",
    "channel_id": "C1234567890",
    "thread_ts": "1234567890.123456",
    "user_identity": {"id": "user123", "name": "John Doe"}
}
context_manager.store_context(task_id, context)

# Retrieve context when processing response
retrieved_context = context_manager.get_context(task_id)
if retrieved_context:
    channel_id = retrieved_context["channel_id"]
    # Send response back to Slack channel

# Clean up when task is complete
context_manager.remove_context(task_id)
```

================================================================================

## Section 27: solace_agent_mesh/gateway/gateway_llm.txt

**Source file:** `solace_agent_mesh/gateway/gateway_llm.txt`

# DEVELOPER GUIDE: gateway

## Quick Summary
The `gateway` directory provides a comprehensive framework for building gateways that connect external platforms (Slack, HTTP/SSE web interfaces) to the Solace AI Connector's A2A (Agent-to-Agent) messaging system. The architecture consists of a foundational `base` module that defines abstract classes for gateway implementations, and specific gateway implementations like `slack` for Slack integration and `http_sse` for web-based interfaces. The framework handles authentication, message translation between external formats and A2A protocol, real-time streaming updates, and manages the complete lifecycle of requests from external platforms to AI agents.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Standard Python package initializer
  - `gateway_llm.txt`: Documentation or configuration file for LLM-related gateway functionality
  - `gateway_llm_detail.txt`: Comprehensive documentation combining all gateway module summaries

- **Subdirectories:**
  - `base/`: Foundational abstract classes and utilities for building gateway implementations
  - `http_sse/`: HTTP/Server-Sent Events gateway for web-based user interfaces

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Initializes the `gateway` Python package
**Import:** `from solace_agent_mesh.gateway import ...`

**Classes/Functions/Constants:**
This file is empty and contains no direct exports.

#### gateway_llm.txt
**Purpose:** Documentation or configuration file for LLM-related gateway functionality
**Import:** Not applicable (text/documentation file)

**Content:** This appears to be a documentation or configuration file rather than executable code.

#### gateway_llm_detail.txt
**Purpose:** Comprehensive documentation combining all individual LLM summary files from the gateway directory tree
**Import:** Not applicable (text/documentation file)

**Content:** Contains concatenated developer guides for all gateway subdirectories and components.

### Subdirectory APIs

#### base/
**Purpose:** Provides foundational abstract classes for building Gateway implementations
**Key Exports:** `BaseGatewayApp`, `BaseGatewayComponent`, `TaskContextManager`
**Import Examples:**
```python
from solace_agent_mesh.gateway.base.app import BaseGatewayApp
from solace_agent_mesh.gateway.base.component import BaseGatewayComponent
from solace_agent_mesh.gateway.base.task_context import TaskContextManager
```

#### http_sse/
**Purpose:** HTTP/Server-Sent Events gateway for web-based user interfaces with real-time streaming
**Key Exports:** `WebUIBackendApp`, `WebUIBackendComponent`, `SSEManager`, `SessionManager`, routers, services
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.app import WebUIBackendApp
from solace_agent_mesh.gateway.http_sse.component import WebUIBackendComponent
from solace_agent_mesh.gateway.http_sse.sse_manager import SSEManager
from solace_agent_mesh.gateway.http_sse.dependencies import get_sse_manager, get_session_manager
```

## Complete Usage Guide

### 1. Creating a Custom Gateway Implementation

```python
from typing import Type, List, Dict, Any, Optional, Tuple, Union
from solace_agent_mesh.gateway.base.app import BaseGatewayApp
from solace_agent_mesh.gateway.base.component import BaseGatewayComponent
from solace_agent_mesh.common.a2a.types import ContentPart, TextPart
from a2a.types import Task, TaskStatusUpdateEvent, TaskArtifactUpdateEvent, JSONRPCError

# Step 1: Define your gateway app class
class MyCustomGatewayApp(BaseGatewayApp):
    """Custom gateway for My Platform integration."""
    
    # Define platform-specific configuration parameters
    SPECIFIC_APP_SCHEMA_PARAMS: List[Dict[str, Any]] = [
        {
            "name": "my_platform_api_key",
            "required": True,
            "type": "string",
            "description": "API key for My Platform"
        },
        {
            "name": "my_platform_webhook_url",
            "required": False,
            "type": "string",
            "description": "Webhook URL for receiving events"
        },
        {
            "name": "default_agent_name",
            "required": False,
            "type": "string",
            "default": "assistant",
            "description": "Default agent to route messages to"
        }
    ]

    def _get_gateway_component_class(self) -> Type[BaseGatewayComponent]:
        return MyCustomGatewayComponent

# Step 2: Implement your gateway component
class MyCustomGatewayComponent(BaseGatewayComponent):
    """Component implementing My Platform integration logic."""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.api_key = self.get_config("my_platform_api_key")
        self.webhook_url = self.get_config("my_platform_webhook_url")
        self.default_agent = self.get_config("default_agent_name", "assistant")
        self.platform_client = None  # Initialize your platform client
    
    async def _extract_initial_claims(self, external_event_data: Any) -> Optional[Dict[str, Any]]:
        """Extract user identity from platform event."""
        # Example: Extract user ID from your platform's event structure
        if hasattr(external_event_data, 'user_id'):
            return {
                "id": external_event_data.user_id,
                "platform": "my_platform",
                "username": getattr(external_event_data, 'username', None)
            }
        return None
    
    def _start_listener(self) -> None:
        """Start your platform's event listener."""
        # Example: Start webhook server, WebSocket connection, etc.
        print(f"Starting My Platform listener on {self.webhook_url}")
        # Initialize your platform client/listener here
    
    def _stop_listener(self) -> None:
        """Stop your platform's event listener."""
        print("Stopping My Platform listener")
        # Clean up platform client/listener here
    
    async def _translate_external_input(self, external_event: Any) -> Tuple[str, List[ContentPart], Dict[str, Any]]:
        """Convert platform event to A2A format."""
        # Extract message content
        message_text = getattr(external_event, 'message', '')
        
        # Determine target agent (could be extracted from message or use default)
        target_agent = getattr(external_event, 'target_agent', self.default_agent)
        
        # Create A2A content parts
        a2a_parts = [TextPart(text=message_text)]
        
        # Create context for tracking this request
        context = {
            "platform": "my_platform",
            "event_id": getattr(external_event, 'id', ''),
            "channel_id": getattr(external_event, 'channel_id', ''),
            "user_id_for_artifacts": getattr(external_event, 'user_id', ''),
            "a2a_session_id": f"my_platform_{getattr(external_event, 'session_id', '')}"
        }
        
        return target_agent, a2a_parts, context
    
    async def _send_update_to_external(self, 
                                     external_request_context: Dict[str, Any], 
                                     event_data: Union[TaskStatusUpdateEvent, TaskArtifactUpdateEvent], 
                                     is_final_chunk_of_update: bool) -> None:
        """Send streaming update to your platform."""
        channel_id = external_request_context.get("channel_id")
        
        # Extract text content from the event
        if hasattr(event_data, 'text_delta'):
            text_content = event_data.text_delta
        elif hasattr(event_data, 'content'):
            text_content = str(event_data.content)
        else:
            text_content = "Update received"
        
        # Send to your platform (example)
        await self._send_to_platform(channel_id, text_content, is_partial=not is_final_chunk_of_update)
    
    async def _send_final_response_to_external(self, 
                                             external_request_context: Dict[str, Any], 
                                             task_data: Task) -> None:
        """Send final response to your platform."""
        channel_id = external_request_context.get("channel_id")
        
        # Extract final response from task data
        final_response = "Task completed"
        if task_data.result and hasattr(task_data.result, 'content'):
            final_response = str(task_data.result.content)
        
        await self._send_to_platform(channel_id, final_response, is_final=True)
    
    async def _send_error_to_external(self, 
                                     external_request_context: Dict[str, Any], 
                                     error_data: JSONRPCError) -> None:
        """Send error to your platform."""
        channel_id = external_request_context.get("channel_id")
        error_message = f"Error: {error_data.message}"
        await self._send_to_platform(channel_id, error_message, is_error=True)
    
    async def _send_to_platform(self, channel_id: str, message: str, **kwargs):
        """Helper method to send messages to your platform."""
        # Implement your platform's message sending logic here
        print(f"Sending to {channel_id}: {message}")

# Step 3: Usage
if __name__ == "__main__":
    config = {
        "name": "my-custom-gateway",
        "namespace": "/myorg/prod",
        "gateway_id": "my-gateway-01",
        "my_platform_api_key": "your-api-key",
        "my_platform_webhook_url": "https://my-webhook.example.com",
        "default_agent_name": "my-assistant",
        "solace_config": {
            "broker_url": "tcp://localhost:55555",
            "vpn_name": "default",
            "username": "default",
            "password": "default"
        }
    }
    
    app = MyCustomGatewayApp(app_info=config)
    app.run()
```

### 2. Using the HTTP/SSE Gateway for Web Interfaces

```python
from solace_agent_mesh.gateway.http_sse.app import WebUIBackendApp
from fastapi import APIRouter, Depends, Request
from solace_agent_mesh.gateway.http_sse.dependencies import (
    get_sse_manager, get_session_manager, get_core_a2a_service
)

# Configure web UI gateway
webui_config = {
    "name": "my-webui",
    "session_secret_key": "your-secret-key",
    "fastapi_host": "0.0.0.0",
    "fastapi_port": 8000,
    "namespace": "/myorg/prod",
    "gateway_id": "webui-01",
    "cors_allowed_origins": ["http://localhost:3000"],
    "frontend_welcome_message": "Welcome to AI Assistant!",
    "frontend_bot_name": "Assistant",
    "frontend_enable_file_upload": True,
    "frontend_enable_agent_selection": True,
    
    # Database for session persistence
    "session_service": {
        "type": "sql",
        "database_url": "sqlite:///./sessions.db"
    },
    
    # A2A system configuration
    "solace_config": {
        "broker_url": "tcp://localhost:55555",
        "vpn_name": "default",
        "username": "default",
        "password": "default"
    }
}

# Create custom router for additional endpoints
custom_router = APIRouter(prefix="/api/custom")

@custom_router.get("/my-endpoint")
async def my_custom_endpoint(
    request: Request,
    sse_manager = Depends(get_sse_manager),
    session_manager = Depends(get_session_manager)
):
    """Custom endpoint with access to gateway services."""
    user_id = session_manager.get_a2a_client_id(request)
    return {"user_id": user_id, "message": "Custom endpoint response"}

# Create and run the web UI gateway
webui_app = WebUIBackendApp(app_info=webui_config)
webui_app.run()
```

### 3. Working with Task Context and Session Management

```python
from solace_agent_mesh.gateway.base.task_context import TaskContextManager
from solace_agent_mesh.gateway.http_sse.session_manager import SessionManager

# Task context management (used internally by gateways)
context_manager = TaskContextManager()

# Store context when submitting a task
task_id = "task-123"
context = {
    "platform": "http_sse",
    "session_id": "session-456",
    "user_id": "user-789",
    "client_id": "client-abc"
}
context_manager.store_context(task_id, context)

# Retrieve context when processing response
retrieved_context = context_manager.get_context(task_id)
if retrieved_context:
    # Send response back to original platform
    session_id = retrieved_context["session_id"]

# Session management for web interfaces
session_manager = SessionManager(
    secret_key="your-secret-key",
    app_config={"session_timeout": 3600}
)

# In a FastAPI endpoint
@app.get("/api/session-info")
async def get_session_info(request: Request):
    # Get A2A client ID for this web session
    client_id = session_manager.get_a2a_client_id(request)
    
    # Ensure we have an A2A session
    session_id = session_manager.ensure_a2a_session(request)
    
    return {
        "client_id": client_id,
        "session_id": session_id
    }
```

### 4. Real-time Streaming with Server-Sent Events

```python
import asyncio
import httpx
import json
from solace_agent_mesh.gateway.http_sse.sse_manager import SSEManager
from solace_agent_mesh.gateway.http_sse.sse_event_buffer import SSEEventBuffer

# Server-side SSE management
sse_buffer = SSEEventBuffer(max_queue_size=100, max_age_seconds=300)
sse_manager = SSEManager(max_queue_size=100, event_buffer=sse_buffer)

# Create SSE connection for a task
task_id = "task-123"
sse_queue = sse_manager.create_sse_connection(task_id)

# Send events to connected clients
sse_manager.send_event(
    task_id=task_id,
    event_data={"message": "Task started", "progress": 0},
    event_type="task_update"
)

# Client-side SSE consumption
async def listen_to_task_events(task_id: str):
    async with httpx.AsyncClient() as client:
        async with client.stream(
            "GET", 
            f"http://localhost:8000/api/v1/sse/subscribe/{task_id}",
            headers={"Accept": "text/event-stream"}
        ) as response:
            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    event_data = line[6:]  # Remove "data: " prefix
                    try:
                        parsed_data = json.loads(event_data)
                        print(f"Received event: {parsed_data}")
                    except json.JSONDecodeError:
                        print(f"Received raw data: {event_data}")
```

### 5. Database

================================================================================

## Section 28: solace_agent_mesh/gateway/http_sse/alembic/alembic_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/alembic/alembic_llm.txt`

# DEVELOPER GUIDE: alembic

## Quick Summary
This directory contains Alembic database migration configuration and version files for the HTTP SSE gateway. It provides database schema management capabilities, including initial table creation, performance optimization through indexing, timestamp format standardization, and task management features with token usage tracking. The directory consists of the main Alembic environment configuration (`env.py`) and a versions subdirectory containing sequential migration files that handle schema evolution over time.

## Files and Subdirectories Overview
- **Direct files:**
  - `env.py` - Alembic environment configuration for running migrations in offline/online modes

- **Subdirectories:**
  - `versions/` - Contains sequential database migration files for schema evolution and task management

## Developer API Reference

### Direct Files

#### env.py
**Purpose:** Alembic environment configuration that handles migration execution in both offline and online modes with proper model registration
**Import:** This is an Alembic configuration file - not directly imported by application code

**Functions:**
- `run_migrations_offline() -> None` - Executes migrations without database connection (generates SQL scripts)
- `run_migrations_online() -> None` - Executes migrations with live database connection and proper URL handling

**Constants/Variables:**
- `config` - Alembic Config object providing access to .ini file values
- `target_metadata` - SQLAlchemy metadata from repository Base class for autogenerate support

### Subdirectory APIs

#### versions/
**Purpose:** Contains sequential Alembic migration files that define database schema changes including core tables, indexes, timestamp modernization, task management, and performance optimization
**Key Exports:** Migration functions for complete schema evolution (upgrade/downgrade operations)
**Import Examples:**
```python
# These are migration files executed by Alembic CLI, not directly imported
# Access via Alembic commands:
# alembic upgrade head
# alembic downgrade base
```

**Available Migrations:**
- `d5b3f8f2e9a0` - Initial database schema (sessions and chat_messages tables)
- `b1c2d3e4f5g6` - Performance indexes for query optimization
- `f6e7d8c9b0a1` - Timestamp conversion to epoch milliseconds
- `98882922fa59` - Task management tables (tasks, task_events, feedback, chat_tasks)
- `20251015_session_idx` - Optimized composite indexes for better query performance

## Complete Usage Guide

### 1. Setting Up Alembic Environment

```python
# The env.py automatically imports all repository models for metadata
from solace_agent_mesh.gateway.http_sse.repository.models.base import Base
from solace_agent_mesh.gateway.http_sse.repository.models.task_model import TaskModel
from solace_agent_mesh.gateway.http_sse.repository.models.task_event_model import TaskEventModel
from solace_agent_mesh.gateway.http_sse.repository.models.feedback_model import FeedbackModel

target_metadata = Base.metadata
```

### 2. Running Migrations

```bash
# Check current migration status
alembic current

# Run all pending migrations to latest
alembic upgrade head

# Run specific migration
alembic upgrade d5b3f8f2e9a0

# Rollback to previous migration
alembic downgrade -1

# Rollback to specific migration
alembic downgrade b1c2d3e4f5g6

# Rollback all migrations
alembic downgrade base

# View migration history
alembic history
```

### 3. Complete Migration Sequence and Schema Evolution

```bash
# Step 1: Create initial database schema
alembic upgrade d5b3f8f2e9a0
# Creates: sessions table, chat_messages table with relationships

# Step 2: Add performance indexes
alembic upgrade b1c2d3e4f5g6
# Adds: indexes on user_id, timestamps, composite fields

# Step 3: Modernize timestamp format
alembic upgrade f6e7d8c9b0a1
# Converts: datetime columns to epoch milliseconds
# Renames: columns for consistency (created_at → created_time)

# Step 4: Add task management features
alembic upgrade 98882922fa59
# Creates: tasks, task_events, feedback, chat_tasks tables
# Replaces: chat_messages with chat_tasks for better task tracking

# Step 5: Add optimized performance indexes
alembic upgrade 20251015_session_idx
# Adds: composite indexes for optimal query patterns
```

### 4. Working with Different Database Engines

```python
# The env.py handles multiple database types automatically
# Configure database URL in alembic.ini or environment:

# PostgreSQL
# sqlalchemy.url = postgresql://user:pass@localhost/dbname

# SQLite
# sqlalchemy.url = sqlite:///./database.db

# MySQL
# sqlalchemy.url = mysql://user:pass@localhost/dbname
```

### 5. Integration with Repository Layer

```python
# The migrations work with the repository models
from solace_agent_mesh.gateway.http_sse.repository.models.base import Base
from solace_agent_mesh.gateway.http_sse.repository.models.task_model import TaskModel
from solace_agent_mesh.gateway.http_sse.repository.models.task_event_model import TaskEventModel
from solace_agent_mesh.gateway.http_sse.repository.models.feedback_model import FeedbackModel

# After running all migrations, your models will have the updated schema:
# - All timestamp fields use epoch milliseconds
# - Proper indexes for performance
# - Standardized column names
# - Complete task management functionality
# - Optimized composite indexes for query performance
```

### 6. Offline Migration Generation

```bash
# Generate SQL scripts without executing (useful for production deployments)
# This uses run_migrations_offline() function from env.py

# Generate SQL for specific migration
alembic upgrade d5b3f8f2e9a0 --sql

# Generate SQL for all pending migrations
alembic upgrade head --sql

# Generate SQL for performance optimization
alembic upgrade 20251015_session_idx --sql
```

### 7. Common Development Patterns

```bash
# Development workflow:
# 1. Make model changes in repository
# 2. Generate new migration
alembic revision --autogenerate -m "description of changes"

# 3. Review generated migration file
# 4. Test migration
alembic upgrade head

# 5. Test rollback
alembic downgrade -1

# Production deployment:
# 1. Generate SQL scripts
alembic upgrade head --sql > migration.sql

# 2. Review and execute SQL manually in production
```

### 8. Database Schema After All Migrations

```sql
-- Final schema structure after all migrations:

-- Core tables with epoch millisecond timestamps:
-- sessions table:
--   id (String, Primary Key)
--   name (String)
--   user_id (String, Indexed)
--   agent_id (String)
--   created_time (BigInteger, epoch ms)
--   updated_time (BigInteger, epoch ms)

-- chat_tasks table (replaces chat_messages):
--   id (String, Primary Key)
--   session_id (String, Foreign Key to sessions.id)
--   user_id (String)
--   user_message (Text)
--   message_bubbles (Text, JSON)
--   task_metadata (Text, JSON)
--   created_time (BigInteger, epoch ms)
--   updated_time (BigInteger, epoch ms)

-- Task management tables:
-- tasks table:
--   id (String, Primary Key)
--   user_id (String, Indexed)
--   start_time (BigInteger, epoch ms)
--   end_time (BigInteger, epoch ms)
--   status (String)
--   initial_request_text (Text)
--   total_input_tokens (Integer)
--   total_output_tokens (Integer)
--   total_cached_input_tokens (Integer)
--   token_usage_details (Text, JSON)

-- task_events table:
--   id (String, Primary Key)
--   task_id (String, Foreign Key to tasks.id)
--   user_id (String)
--   created_time (BigInteger, epoch ms)
--   topic (String)
--   direction (String)
--   payload (Text)

-- feedback table:
--   id (String, Primary Key)
--   session_id (String, Foreign Key to sessions.id)
--   task_id (String, Foreign Key to tasks.id)
--   user_id (String)
--   rating (Integer)
--   comment (Text)
--   created_time (BigInteger, epoch ms)

-- Optimized performance indexes:
--   ix_sessions_user_id
--   ix_sessions_user_updated (composite: user_id, updated_time)
--   ix_chat_tasks_session_user_created (composite: session_id, user_id, created_time)
--   ix_tasks_user_start_time (composite: user_id, start_time)
--   ix_task_events_task_created (composite: task_id, created_time)
--   ix_feedback_task_id
--   ix_feedback_user_id
--   ix_feedback_created_time
```

### 9. Cross-Platform Timestamp Handling

```python
# The f6e7d8c9b0a1 migration handles database-specific timestamp conversion:

# SQLite: Uses table recreation approach
# - Creates new tables with epoch millisecond columns
# - Migrates data with timestamp conversion
# - Drops old tables and renames new ones

# PostgreSQL/MySQL: Uses ALTER COLUMN approach
# - Directly modifies column types
# - Converts existing data in place
# - More efficient for large datasets
```

### 10. Performance Optimization Features

```python
# The migrations include comprehensive performance optimizations:

# Single-column indexes for basic filtering:
# - user_id columns for user-specific queries
# - timestamp columns for time-based filtering

# Composite indexes for complex queries:
# - (user_id, updated_time) for recent user sessions
# - (session_id, user_id, created_time) for session chat history
# - (task_id, created_time) for task event chronology
# - (user_id, start_time) for user task history

# Usage example after all migrations:
from solace_agent_mesh.gateway.http_sse.repository.models.task_model import TaskModel

# Efficient queries using optimized indexes:
# Get recent user sessions (uses ix_sessions_user_updated)
recent_sessions = session.query(SessionModel)\
    .filter_by(user_id="user123")\
    .order_by(SessionModel.updated_time.desc())\
    .limit(10)

# Get task events chronologically (uses ix_task_events_task_created)
task_events = session.query(TaskEventModel)\
    .filter_by(task_id="task456")\
    .order_by(TaskEventModel.created_time)\
    .all()
```

### 11. Task Management Integration

```python
# After running all migrations, the complete task management system is available:

from solace_agent_mesh.gateway.http_sse.repository.models.task_model import TaskModel
from solace_agent_mesh.gateway.http_sse.repository.models.task_event_model import TaskEventModel
from solace_agent_mesh.gateway.http_sse.repository.models.feedback_model import FeedbackModel

# Create a new task with token tracking
task = TaskModel(
    id="task_123",
    user_id="user_456",
    start_time=1634567890000,  # epoch milliseconds
    status="in_progress",
    initial_request_text="User's initial request",
    total_input_tokens=150,
    total_output_tokens=300,
    total_cached_input_tokens=50,
    token_usage_details='{"model": "gpt-4", "breakdown": {...}}'
)

# Add task events for tracking
event = TaskEventModel(
    id="event_789",
    task_id="task_123",
    user_id="user_456",
    created_time=1634567891000,
    topic="ai_response",
    direction="outbound",
    payload='{"response": "AI generated response"}'
)

# Collect user feedback
feedback = FeedbackModel(
    id="feedback_101",
    task_id="task_123",
    user_id="user_456",
    rating=5,
    comment="Excellent response quality",
    created_time=1634567892000
)
```

This Alembic configuration provides a comprehensive database migration system that handles schema evolution, performance optimization, cross-database compatibility, complete task management functionality, and optimized query patterns for the HTTP SSE gateway component.

================================================================================

## Section 29: solace_agent_mesh/gateway/http_sse/alembic/versions/versions_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/alembic/versions/versions_llm.txt`

# DEVELOPER GUIDE: versions

## Quick Summary
This directory contains Alembic database migration files for the HTTP SSE gateway. These migrations handle the evolution of the database schema, including initial table creation, performance optimization through indexing, timestamp format standardization, and task management features.

## Files Overview
- `20250910_d5b3f8f2e9a0_create_initial_database.py` - Creates the initial database schema with sessions and chat_messages tables
- `20250911_b1c2d3e4f5g6_add_database_indexes.py` - Adds performance indexes for common query patterns
- `20250916_f6e7d8c9b0a1_convert_timestamps_to_epoch_and_align_columns.py` - Converts datetime columns to epoch milliseconds and standardizes column names
- `20251006_98882922fa59_add_tasks_events_feedback_chat_tasks.py` - Adds task management tables and replaces chat_messages with chat_tasks
- `20251015_add_session_performance_indexes.py` - Adds optimized composite indexes for better query performance
- `versions_llm.txt` - LLM-generated documentation for the versions directory

## Developer API Reference

### 20250910_d5b3f8f2e9a0_create_initial_database.py
**Purpose:** Initial database migration that creates the core tables for session and message management
**Import:** This is an Alembic migration file - not directly imported

**Functions:**
- `upgrade() -> None` - Creates sessions and chat_messages tables with proper relationships and foreign key constraints
- `downgrade() -> None` - Drops all created tables (chat_messages first, then sessions)

**Constants/Variables:**
- `revision: str` - Migration identifier "d5b3f8f2e9a0"
- `down_revision: Union[str, None]` - Previous migration (None for initial migration)
- `branch_labels: Union[str, Sequence[str], None]` - Branch labels (None)
- `depends_on: Union[str, Sequence[str], None]` - Dependencies (None)

**Usage Examples:**
```bash
# Run this migration
alembic upgrade d5b3f8f2e9a0

# Rollback this migration
alembic downgrade base
```

### 20250911_b1c2d3e4f5g6_add_database_indexes.py
**Purpose:** Performance optimization migration that adds indexes for efficient querying
**Import:** This is an Alembic migration file - not directly imported

**Functions:**
- `upgrade() -> None` - Creates indexes on user_id, timestamps, agent_id, and composite fields for optimal query performance
- `downgrade() -> None` - Removes all created indexes in reverse order

**Constants/Variables:**
- `revision: str` - Migration identifier "b1c2d3e4f5g6"
- `down_revision: Union[str, None]` - Previous migration "d5b3f8f2e9a0"

**Usage Examples:**
```bash
# Run this migration
alembic upgrade b1c2d3e4f5g6

# Rollback this migration
alembic downgrade d5b3f8f2e9a0
```

### 20250916_f6e7d8c9b0a1_convert_timestamps_to_epoch_and_align_columns.py
**Purpose:** Schema modernization migration that converts datetime columns to epoch milliseconds for cross-platform compatibility
**Import:** This is an Alembic migration file - not directly imported

**Functions:**
- `upgrade() -> None` - Converts datetime columns to epoch milliseconds and renames columns (created_at → created_time, updated_at → updated_time)
- `downgrade() -> None` - Reverts back to datetime columns with original names
- `_upgrade_sqlite(current_time_ms: int) -> None` - SQLite-specific upgrade logic using table recreation
- `_upgrade_standard_sql(current_time_ms: int) -> None` - PostgreSQL/MySQL upgrade logic using ALTER COLUMN
- `_downgrade_sqlite() -> None` - SQLite-specific downgrade logic
- `_downgrade_standard_sql() -> None` - PostgreSQL/MySQL downgrade logic
- `_create_updated_indexes() -> None` - Creates indexes on new timestamp columns
- `_create_indexes_safe(index_name: str, table_name: str, columns: list) -> None` - Safely creates indexes (ignores if exists)
- `_drop_index_safe(index_name: str, table_name: str) -> None` - Safely drops indexes (ignores if not exists)

**Constants/Variables:**
- `revision: str` - Migration identifier "f6e7d8c9b0a1"
- `down_revision: str | None` - Previous migration "b1c2d3e4f5g6"

**Usage Examples:**
```bash
# Run this migration
alembic upgrade f6e7d8c9b0a1

# Rollback this migration
alembic downgrade b1c2d3e4f5g6
```

### 20251006_98882922fa59_add_tasks_events_feedback_chat_tasks.py
**Purpose:** Major schema update that adds task management functionality and replaces chat_messages with chat_tasks
**Import:** This is an Alembic migration file - not directly imported

**Functions:**
- `upgrade() -> None` - Creates tasks, task_events, feedback, and chat_tasks tables; drops old chat_messages table and indexes
- `downgrade() -> None` - Recreates chat_messages table and drops all task-related tables

**Constants/Variables:**
- `revision: str` - Migration identifier "98882922fa59"
- `down_revision: Union[str, Sequence[str], None]` - Previous migration "f6e7d8c9b0a1"

**Usage Examples:**
```bash
# Run this migration
alembic upgrade 98882922fa59

# Rollback this migration
alembic downgrade f6e7d8c9b0a1
```

### 20251015_add_session_performance_indexes.py
**Purpose:** Performance optimization migration that adds composite indexes for optimal query patterns
**Import:** This is an Alembic migration file - not directly imported

**Functions:**
- `upgrade() -> None` - Creates optimized composite indexes for user sessions, chat tasks, and task events; removes unused text index
- `downgrade() -> None` - Removes performance indexes and recreates the original text index

**Constants/Variables:**
- `revision: str` - Migration identifier "20251015_session_idx"
- `down_revision: str | Sequence[str] | None` - Previous migration "98882922fa59"

**Usage Examples:**
```bash
# Run this migration
alembic upgrade 20251015_session_idx

# Rollback this migration
alembic downgrade 98882922fa59

# Run all migrations to latest
alembic upgrade head

# Check current migration status
alembic current

# View migration history
alembic history

# Generate new migration
alembic revision --autogenerate -m "description"
```

**Final Database Schema After All Migrations:**
```sql
-- Core tables with epoch millisecond timestamps:
-- sessions: id, name, user_id, agent_id, created_time, updated_time
-- chat_tasks: id, session_id, user_id, user_message, message_bubbles, task_metadata, created_time, updated_time

-- Task management tables:
-- tasks: id, user_id, start_time, end_time, status, initial_request_text,
--        total_input_tokens, total_output_tokens, total_cached_input_tokens, token_usage_details
-- task_events: id, task_id, user_id, created_time, topic, direction, payload
-- feedback: id, session_id, task_id, user_id, rating, comment, created_time

-- Performance indexes:
-- ix_sessions_user_id, ix_sessions_user_updated
-- ix_chat_tasks_session_user_created
-- ix_tasks_user_start_time, ix_task_events_task_created
-- ix_feedback_task_id, ix_feedback_user_id, ix_feedback_created_time
```

================================================================================

## Section 30: solace_agent_mesh/gateway/http_sse/components/components_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/components/components_llm.txt`

# DEVELOPER GUIDE: components

## Quick Summary
This directory contains SAC (Solace AI Connector) components for the HTTP SSE (Server-Sent Events) gateway. These components forward messages from Solace broker inputs to internal Python queues, enabling real-time visualization and task logging in web-based user interfaces.

## Files Overview
- `__init__.py` - Makes the `VisualizationForwarderComponent` class directly importable from the components package
- `components_llm.txt` - Developer guide documentation for this directory
- `task_logger_forwarder.py` - SAC component that forwards messages to a task logging queue
- `visualization_forwarder_component.py` - SAC component that forwards messages to a visualization queue

## Developer API Reference

### __init__.py
**Purpose:** Exposes the public components of this directory for easy importing
**Import:** `from solace_agent_mesh.gateway.http_sse.components import VisualizationForwarderComponent`

**Exports:**
- `VisualizationForwarderComponent` - The main component class for forwarding messages to a visualization queue

### task_logger_forwarder.py
**Purpose:** A SAC component that forwards messages from a BrokerInput to a target queue for task logging
**Import:** `from solace_agent_mesh.gateway.http_sse.components.task_logger_forwarder import TaskLoggerForwarderComponent`

**Classes:**
- `TaskLoggerForwarderComponent(**kwargs: Any)` - A component that forwards messages to a task logging queue, initialized with configuration parameters including `target_queue_ref`
  - `invoke(message: SolaceMessage, data: Dict[str, Any]) -> None` - Core method called by SAC framework for each incoming message; formats data and places it onto the target queue
  - `target_queue: queue.Queue` - The queue instance where messages are forwarded

**Constants/Variables:**
- `info: Dict` - Metadata dictionary required by SAC framework describing component configuration, input schema, and purpose

**Usage Examples:**
```python
import queue
from solace_agent_mesh.gateway.http_sse.components.task_logger_forwarder import TaskLoggerForwarderComponent
from solace_ai_connector.common.message import Message as SolaceMessage

# 1. Create a target queue for task logging
task_logging_queue = queue.Queue()

# 2. Instantiate the component with target queue reference
task_forwarder = TaskLoggerForwarderComponent(
    name="task_logger",
    target_queue_ref=task_logging_queue
)

# 3. The invoke method is called automatically by SAC framework
# when messages arrive from connected BrokerInput component

# 4. Consume forwarded messages from the queue
if not task_logging_queue.empty():
    forwarded_data = task_logging_queue.get()
    print(f"Task Topic: {forwarded_data['topic']}")
    print(f"Task Payload: {forwarded_data['payload']}")
    print(f"User Properties: {forwarded_data['user_properties']}")
```

### visualization_forwarder_component.py
**Purpose:** A SAC component that forwards messages from a BrokerInput to a target queue for visualization
**Import:** `from solace_agent_mesh.gateway.http_sse.components.visualization_forwarder_component import VisualizationForwarderComponent`

**Classes:**
- `VisualizationForwarderComponent(**kwargs: Any)` - A component that forwards messages to a visualization queue, initialized with configuration parameters including `target_queue_ref`
  - `invoke(message: SolaceMessage, data: Dict[str, Any]) -> None` - Core method called by SAC framework for each incoming message; formats data and places it onto the target queue
  - `target_queue: queue.Queue` - The queue instance where messages are forwarded

**Constants/Variables:**
- `info: Dict` - Metadata dictionary required by SAC framework describing component configuration, input schema, and purpose

**Usage Examples:**
```python
import queue
from solace_agent_mesh.gateway.http_sse.components import VisualizationForwarderComponent
from solace_ai_connector.common.message import Message as SolaceMessage

# 1. Create a target queue that will receive the forwarded messages
visualization_queue = queue.Queue()

# 2. Instantiate the component with target queue reference
forwarder = VisualizationForwarderComponent(
    name="my_forwarder",
    target_queue_ref=visualization_queue
)

# 3. The invoke method is called automatically by SAC framework
# when messages arrive from connected BrokerInput component

# 4. Consume forwarded messages from the queue
if not visualization_queue.empty():
    forwarded_data = visualization_queue.get()
    print(f"Topic: {forwarded_data['topic']}")
    print(f"Payload: {forwarded_data['payload']}")
    print(f"User Properties: {forwarded_data['user_properties']}")
    
# Expected structure of forwarded_data:
# {
#     "topic": "some/broker/topic",
#     "payload": {"key": "value"},
#     "user_properties": {"prop1": "value1"},
#     "_original_broker_message": <SolaceMessage object>
# }
```

================================================================================

## Section 31: solace_agent_mesh/gateway/http_sse/http_sse_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/http_sse_llm.txt`

# DEVELOPER GUIDE: http_sse

## Quick Summary
The `http_sse` directory implements a complete HTTP/SSE (Server-Sent Events) gateway for the A2A (Agent-to-Agent) system. It serves as a bridge between web-based user interfaces and the backend A2A messaging fabric, providing real-time communication capabilities through HTTP REST APIs and Server-Sent Events streaming.

The architecture centers around the `WebUIBackendComponent`, a custom Solace AI Connector (SAC) component that hosts an embedded FastAPI web server. This component manages shared resources including the `SSEManager` for real-time updates, `SessionManager` for user sessions, and `AgentRegistry` for agent discovery. The system provides comprehensive functionality including session management, task logging, data retention, feedback collection, and A2A message visualization.

Subdirectories organize functionality by layer: `routers/` defines REST API endpoints, `services/` contains business logic, `repository/` handles data persistence, `components/` provides specialized SAC components, and `shared/` contains common utilities. The `dependencies.py` file uses FastAPI's dependency injection to provide clean separation between the web layer and core messaging components.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Standard Python package initializer
  - `alembic.ini`: Alembic database migration configuration
  - `app.py`: Main SAC `WebUIBackendApp` class defining configuration schema and component creation
  - `component.py`: Core SAC component hosting FastAPI server and managing shared resources
  - `dependencies.py`: FastAPI dependency injectors for accessing shared resources
  - `main.py`: FastAPI application instance with middleware, routing, and exception handling
  - `session_manager.py`: Web user session management and A2A identity mapping
  - `sse_manager.py`: Server-Sent Event connection management for real-time streaming
  - `sse_event_buffer.py`: Thread-safe buffer for early SSE events before client connection
- **Subdirectories:**
  - `alembic/`: Database migration configuration and version files
  - `components/`: Specialized SAC components for message forwarding and visualization
  - `repository/`: Data access layer with Repository pattern and SQLAlchemy ORM models
  - `routers/`: FastAPI router modules defining REST API endpoints
  - `services/`: Business logic layer for domain-specific operations
  - `shared/`: Common utilities, constants, enums, and exception handling
  - `utils/`: Utility functions for creating .stim file structures from task data

## Developer API Reference

### Direct Files

#### app.py
**Purpose:** Defines the main SAC application class with configuration schema for the HTTP/SSE gateway
**Import:** `from solace_agent_mesh.gateway.http_sse.app import WebUIBackendApp`

**Classes/Functions/Constants:**
- **`WebUIBackendApp(BaseGatewayApp)`**: Main application class extending BaseGatewayApp with WebUI-specific configuration
  - `get_component() -> WebUIBackendComponent | None`: Retrieves the running component instance
  - `_get_gateway_component_class() -> type[BaseGatewayComponent]`: Returns WebUIBackendComponent class
- **`SPECIFIC_APP_SCHEMA_PARAMS: List[Dict[str, Any]]`**: Configuration parameters including session_secret_key, FastAPI settings, frontend configuration, database settings, and feature flags

#### component.py
**Purpose:** Core SAC component hosting FastAPI server and managing all shared resources and A2A logic
**Import:** `from solace_agent_mesh.gateway.http_sse.component import WebUIBackendComponent`

**Classes/Functions/Constants:**
- **`WebUIBackendComponent(BaseGatewayComponent)`**: Main component class implementing the gateway functionality
  - **Public Accessor Methods:**
    - `get_sse_manager() -> SSEManager`: Returns SSE manager for real-time updates
    - `get_session_manager() -> SessionManager`: Returns session manager
    - `get_agent_registry() -> AgentRegistry`: Returns agent registry
    - `get_core_a2a_service() -> CoreA2AService`: Returns core A2A service
    - `get_shared_artifact_service() -> BaseArtifactService | None`: Returns artifact service
    - `get_namespace() -> str`: Returns A2A namespace
    - `get_gateway_id() -> str`: Returns unique gateway identifier
  - **Core Methods:**
    - `publish_a2a(topic: str, payload: dict, user_properties: dict | None = None)`: Publishes A2A messages
  - **GDK Implementation Methods:**
    - `_start_listener()`: Starts FastAPI server
    - `_stop_listener()`: Stops FastAPI server
    - `_translate_external_input(...)`: Converts HTTP requests to A2A messages
    - `_send_update_to_external(...)`: Sends intermediate updates via SSE
    - `_send_final_response_to_external(...)`: Sends final responses via SSE
    - `_send_error_to_external(...)`: Sends error notifications via SSE

#### dependencies.py
**Purpose:** FastAPI dependency injectors providing access to shared resources
**Import:** `from solace_agent_mesh.gateway.http_sse.dependencies import get_sac_component, get_agent_registry, get_sse_manager, get_user_id`

**Functions:**
- `get_sac_component() -> WebUIBackendComponent`: Returns main component instance
- `get_agent_registry() -> AgentRegistry`: Returns agent registry
- `get_sse_manager() -> SSEManager`: Returns SSE manager
- `get_session_manager() -> SessionManager`: Returns session manager
- `get_user_id(request: Request) -> str`: Returns current user identity
- `get_publish_a2a_func() -> PublishFunc`: Returns A2A publishing function
- `get_core_a2a_service() -> CoreA2AService`: Returns core A2A service
- `get_shared_artifact_service() -> BaseArtifactService | None`: Returns artifact service
- `get_db() -> Generator[Session, None, None]`: Returns database session
- `ValidatedUserConfig(required_scopes: list[str])`: Dependency class for scope validation

#### main.py
**Purpose:** FastAPI application instance with middleware, routing, and exception handling
**Import:** `from solace_agent_mesh.gateway.http_sse.main import app, setup_dependencies`

**Classes/Functions/Constants:**
- **`app: FastAPI`**: Main FastAPI application instance
- **`setup_dependencies(component: WebUIBackendComponent, database_url: str = None)`**: Configures middleware, routers, and dependency injection
- **Exception Handlers:**
  - `http_exception_handler()`: Handles HTTP exceptions with format detection
  - `validation_exception_handler()`: Handles Pydantic validation errors
  - `generic_exception_handler()`: Handles unexpected exceptions

#### session_manager.py
**Purpose:** Manages web user sessions and mapping to A2A Client IDs
**Import:** `from solace_agent_mesh.gateway.http_sse.session_manager import SessionManager`

**Classes/Functions/Constants:**
- **`SessionManager(secret_key: str, app_config: Dict[str, Any])`**: Session management class
  - `get_a2a_client_id(request: Request) -> str | None`: Returns A2A client ID
  - `start_new_a2a_session(request: Request) -> str`: Creates new A2A session
  - `ensure_a2a_session(request: Request) -> str`: Ensures session exists
  - `store_auth_tokens(request: Request, access_token: str, refresh_token: str | None)`: Stores auth tokens
  - `get_access_token(request: Request) -> str | None`: Retrieves access token
  - `dep_get_client_id() -> Callable`: Returns FastAPI dependency callable

#### sse_manager.py
**Purpose:** Manages Server-Sent Event connections for streaming task updates
**Import:** `from solace_agent_mesh.gateway.http_sse.sse_manager import SSEManager`

**Classes/Functions/Constants:**
- **`SSEManager(max_queue_size: int, event_buffer: SSEEventBuffer)`**: SSE connection manager
  - `create_sse_connection(task_id: str) -> asyncio.Queue`: Creates SSE connection queue
  - `send_event(task_id: str, event_data: Dict[str, Any], event_type: str)`: Sends event to connections
  - `close_all_for_task(task_id: str)`: Closes connections for specific task
  - `close_all()`: Closes all active connections

#### sse_event_buffer.py
**Purpose:** Thread-safe buffer for holding early SSE events before client connection
**Import:** `from solace_agent_mesh.gateway.http_sse.sse_event_buffer import SSEEventBuffer`

**Classes/Functions/Constants:**
- **`SSEEventBuffer(max_queue_size: int, max_age_seconds: int)`**: Event buffering system
  - `buffer_event(task_id: str, event: Dict[str, Any])`: Buffers event for task
  - `get_and_remove_buffer(task_id: str) -> Optional[List[Dict[str, Any]]]`: Retrieves and removes buffer
  - `cleanup_stale_buffers()`: Removes old buffers

### Subdirectory APIs

#### alembic/
**Purpose:** Database migration configuration and version files for schema management
**Key Exports:** Migration functions for schema evolution (upgrade/downgrade operations)
**Import Examples:**
```python
# These are migration files executed by Alembic CLI, not directly imported
# Access via Alembic commands:
# alembic upgrade head
# alembic downgrade base
```

#### components/
**Purpose:** Specialized SAC components for message forwarding and visualization
**Key Exports:** `VisualizationForwarderComponent`, `TaskLoggerForwarderComponent`
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.components import VisualizationForwarderComponent
from solace_agent_mesh.gateway.http_sse.components.task_logger_forwarder import TaskLoggerForwarderComponent
```

#### repository/
**Purpose:** Data access layer implementing Repository pattern with SQLAlchemy ORM models
**Key Exports:** Repository interfaces, implementations, domain entities, and SQLAlchemy models
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository import (
    ISessionRepository, ITaskRepository, SessionRepository, TaskRepository,
    Session, Task, SessionModel, TaskModel, Base
)
```

#### routers/
**Purpose:** FastAPI router modules defining REST API endpoints
**Key Exports:** Router instances for agents, tasks, SSE, artifacts, auth, config, sessions, people, users, visualization
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.routers import agents, tasks, sse, artifacts
from solace_agent_mesh.gateway.http_sse.routers.tasks import CancelTaskApiPayload
```

#### services/
**Purpose:** Business logic layer for domain-specific operations
**Key Exports:** `AgentCardService`, `TaskService`, `PeopleService`, `SessionService`, `FeedbackService`, `TaskLoggerService`
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.services.agent_card_service import AgentCardService
from solace_agent_mesh.gateway.http_sse.services.task_service import TaskService
from solace_agent_mesh.gateway.http_sse.services.people_service import PeopleService
```

#### shared/
**Purpose:** Common utilities, constants, enums, and exception handling
**Key Exports:** Authentication utilities, timestamp functions, enums, exception handlers, and type definitions
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.shared import get_current_user, now_epoch_ms
from solace_agent_mesh.gateway.http_sse.shared.enums import SenderType, TaskStatus
from solace_agent_mesh.gateway.http_sse.shared.types import UserId, SessionId, PaginationInfo
```

#### utils/
**Purpose:** Utility functions for creating .stim file structures from task data
**Key Exports:** `create_stim_from_task_data`
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.utils.stim_utils import create_stim_from_task_data
```

## Complete Usage Guide

### 1. Setting Up the Gateway Application

```python
from solace_agent_mesh.gateway.http_sse.app import WebUIBackendApp

# Create the gateway app with configuration
app_config = {
    "name": "my-webui-gateway",
    "session_secret_key": "your-secret-key-here",
    "fastapi_host": "0.0.0.0",
    "fastapi_port": 8000,
    "namespace": "/my-namespace",
    "gateway_id": "webui-gateway-01",
    "cors_allowed_origins": ["http://localhost:3000"],
    "frontend_welcome_message": "Welcome to my A2A system!",
    "frontend_bot_name": "My Assistant",
    # Database configuration for persistence
    "session_service": {
        "type": "sql",
        "database_url": "sqlite:///./sessions.db"
    },
    # Task logging configuration
    "task_logging": {
        "enabled": True,
        "log_status_updates": True,
        "log_artifact_events": True
    },
    # Data retention configuration
    "data_retention": {
        "enabled": True,
        "task_retention_days": 90,
        "cleanup_interval_hours": 24
    }
}

# Initialize and run the app
webui_app = WebUIBackendApp(app_info=app_config)
webui_app.run()
```

### 2. Using Dependencies in Custom Routers

```python
from fastapi import APIRouter, Depends
from solace_agent_mesh.gateway.http_sse.dependencies import (
    get_agent_registry,
    get_user_id,
    get_publish_a2a_func,
    get_core_a2a_service,
    get_sse_manager,
    ValidatedUserConfig
)
from solace_agent_mesh.common.agent_registry import AgentRegistry

router = APIRouter()

@router.get("/my-custom-endpoint")
async def my_custom_endpoint(
    user_id: str = Depends(get_user_id),
    agent_registry: AgentRegistry = Depends(get_agent_registry),
    publish_func = Depends(get_publish_a2a_func),
    user_config: dict = Depends(ValidatedUserConfig(["custom:endpoint:access"]))
):
    # Access discovered agents
    agents = agent_registry.get_all_agents()
    
    # Publish a message to the A2A fabric
    publish_func(
        topic=f"/my-namespace/a2a/v1/agent/request/some-agent",
        payload={"method": "custom/request", "params": {"user": user_id}},
        user_properties={"clientId": user_id}
    )
    
    return {"agents": len(agents), "user": user_id}
```

### 3. Working with Sessions and Tasks

```python
from fastapi import Depends
from sqlalchemy.orm import Session
from solace_agent_mesh.gateway.http_sse.dependencies import (
    get_db, get_session_business_service_optional
)
from solace_agent_mesh.gateway.http_sse.services.session_service import SessionService
from solace_agent_mesh.gateway.http_sse.shared.enums import SenderType

@router.post("/sessions/{session_id}/tasks")
async def save_task_to_session(
    session_id: str,
    task_data: dict,
    user_id: str = Depends(get_user_id),
    db: Session = Depends(get_db),
    session_service: SessionService = Depends(get_session_business_service_optional)
):
    if session_service and db

================================================================================

## Section 32: solace_agent_mesh/gateway/http_sse/repository/entities/entities_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/repository/entities/entities_llm.txt`

# DEVELOPER GUIDE: entities

## Quick Summary
The entities directory contains domain entities for the repository layer, providing core business objects for managing chat sessions, tasks, feedback, and events with built-in validation and business logic.

## Files Overview
- `__init__.py` - Exports the main domain entities (ChatTask, Feedback, Session, Task, TaskEvent)
- `chat_task.py` - ChatTask entity for managing chat conversations with JSON validation
- `feedback.py` - Feedback entity for user ratings and comments on tasks
- `session.py` - Session entity with name management and access control
- `task.py` - Task entity for tracking user tasks with token usage metrics
- `task_event.py` - TaskEvent entity for tracking events related to tasks

## Developer API Reference

### __init__.py
**Purpose:** Provides centralized imports for all domain entities
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.entities import ChatTask, Feedback, Session, Task, TaskEvent`

### chat_task.py
**Purpose:** Defines the ChatTask domain entity for managing chat conversations with JSON validation
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.entities import ChatTask`

**Classes:**
- `ChatTask(id: str, session_id: str, user_id: str, message_bubbles: str, created_time: int, user_message: str | None = None, task_metadata: str | None = None, updated_time: int | None = None)` - ChatTask domain entity with business logic
  - `add_feedback(feedback_type: str, feedback_text: str | None = None) -> None` - Add or update feedback for this task
  - `get_feedback() -> dict[str, Any] | None` - Get feedback for this task
  - `id: str` - Unique task identifier
  - `session_id: str` - Associated session identifier
  - `user_id: str` - User who owns the task
  - `user_message: str | None` - Optional user message
  - `message_bubbles: str` - JSON string containing message bubbles (must be non-empty JSON array)
  - `task_metadata: str | None` - Optional JSON string for task metadata
  - `created_time: int` - Task creation timestamp
  - `updated_time: int | None` - Last update timestamp

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.entities import ChatTask
import json

# Create a chat task
message_bubbles = json.dumps([
    {"type": "user", "content": "Hello"},
    {"type": "agent", "content": "Hi there!"}
])

chat_task = ChatTask(
    id="chat_123",
    session_id="session_456",
    user_id="user_789",
    user_message="Hello",
    message_bubbles=message_bubbles,
    created_time=1640995200000
)

# Add feedback
chat_task.add_feedback("positive", "Great response!")

# Get feedback
feedback = chat_task.get_feedback()
if feedback:
    print(f"Feedback type: {feedback['type']}")
```

### feedback.py
**Purpose:** Defines the Feedback domain entity for user ratings and comments
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.entities import Feedback`

**Classes:**
- `Feedback(id: str, session_id: str, task_id: str, user_id: str, rating: str, created_time: int, comment: str | None = None)` - Feedback domain entity
  - `id: str` - Unique feedback identifier
  - `session_id: str` - Associated session identifier
  - `task_id: str` - Associated task identifier
  - `user_id: str` - User who provided feedback
  - `rating: str` - User rating
  - `comment: str | None` - Optional feedback comment
  - `created_time: int` - Feedback creation timestamp

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.entities import Feedback

# Create feedback
feedback = Feedback(
    id="feedback_123",
    session_id="session_456",
    task_id="task_789",
    user_id="user_123",
    rating="5",
    comment="Great service!",
    created_time=1640995200000
)
```

### session.py
**Purpose:** Defines the Session domain entity with business logic for chat sessions
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.entities import Session`

**Classes:**
- `Session(id: SessionId, user_id: UserId, created_time: int, name: str | None = None, agent_id: AgentId | None = None, updated_time: int | None = None)` - Session domain entity with business logic
  - `update_name(new_name: str) -> None` - Updates session name with validation and sets updated_time
  - `mark_activity() -> None` - Marks session as having recent activity by updating timestamp
  - `can_be_deleted_by_user(user_id: UserId) -> bool` - Checks if user can delete this session
  - `can_be_accessed_by_user(user_id: UserId) -> bool` - Checks if user can access this session
  - `id: SessionId` - Unique session identifier
  - `user_id: UserId` - Owner user identifier
  - `name: str | None` - Optional session name
  - `agent_id: AgentId | None` - Optional associated agent identifier
  - `created_time: int` - Session creation timestamp
  - `updated_time: int | None` - Last update timestamp

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.entities import Session

# Create a new session
session = Session(
    id="session_123",
    user_id="user_456",
    name="Customer Support Chat",
    agent_id="agent_789",
    created_time=1640995200000
)

# Update session name
session.update_name("Updated Chat Name")

# Mark activity
session.mark_activity()

# Check permissions
if session.can_be_accessed_by_user("user_456"):
    print("User can access this session")
```

### task.py
**Purpose:** Defines the Task domain entity for tracking user tasks with token usage metrics
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.entities import Task`

**Classes:**
- `Task(id: str, user_id: str, start_time: int, end_time: int | None = None, status: str | None = None, initial_request_text: str | None = None, total_input_tokens: int | None = None, total_output_tokens: int | None = None, total_cached_input_tokens: int | None = None, token_usage_details: dict | None = None)` - Task domain entity with token usage tracking
  - `id: str` - Unique task identifier
  - `user_id: str` - User who owns the task
  - `start_time: int` - Task start timestamp
  - `end_time: int | None` - Optional task end timestamp
  - `status: str | None` - Optional task status
  - `initial_request_text: str | None` - Optional initial request text
  - `total_input_tokens: int | None` - Total input tokens used
  - `total_output_tokens: int | None` - Total output tokens generated
  - `total_cached_input_tokens: int | None` - Total cached input tokens used
  - `token_usage_details: dict | None` - Detailed token usage information

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.entities import Task

# Create a task
task = Task(
    id="task_123",
    user_id="user_456",
    start_time=1640995200000,
    status="in_progress",
    initial_request_text="Help me with my order"
)

# Task with token usage tracking
task_with_tokens = Task(
    id="task_124",
    user_id="user_456",
    start_time=1640995200000,
    end_time=1640995800000,
    status="completed",
    total_input_tokens=150,
    total_output_tokens=300,
    total_cached_input_tokens=50,
    token_usage_details={"model": "gpt-4", "cost": 0.05}
)
```

### task_event.py
**Purpose:** Defines the TaskEvent domain entity for tracking events related to tasks
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.entities import TaskEvent`

**Classes:**
- `TaskEvent(id: str, task_id: str, created_time: int, topic: str, direction: str, payload: dict[str, Any], user_id: str | None = None)` - TaskEvent domain entity
  - `id: str` - Unique event identifier
  - `task_id: str` - Associated task identifier
  - `user_id: str | None` - Optional user identifier
  - `created_time: int` - Event creation timestamp
  - `topic: str` - Event topic
  - `direction: str` - Event direction
  - `payload: dict[str, Any]` - Event payload data

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.entities import TaskEvent

# Create a task event
event = TaskEvent(
    id="event_123",
    task_id="task_456",
    user_id="user_789",
    created_time=1640995200000,
    topic="task.status.changed",
    direction="outbound",
    payload={"status": "completed", "result": "success"}
)

# Event without user
system_event = TaskEvent(
    id="event_124",
    task_id="task_456",
    created_time=1640995200000,
    topic="task.system.notification",
    direction="inbound",
    payload={"message": "Task processing started"}
)
```

================================================================================

## Section 33: solace_agent_mesh/gateway/http_sse/repository/models/models_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/repository/models/models_llm.txt`

## Quick Summary
This directory contains SQLAlchemy ORM models and Pydantic schemas for database persistence in the HTTP SSE gateway. It provides models for managing chat sessions, tasks, task events, and user feedback with proper relationships and database schema definitions.

## Files Overview
- `__init__.py` - Package initialization exposing all SQLAlchemy and Pydantic models
- `base.py` - SQLAlchemy declarative base configuration
- `chat_task_model.py` - ChatTaskModel for storing chat tasks with session relationships
- `feedback_model.py` - FeedbackModel for storing user feedback on tasks
- `session_model.py` - SessionModel and Pydantic schemas for managing chat sessions
- `task_event_model.py` - TaskEventModel for storing A2A task events with task relationships
- `task_model.py` - TaskModel for managing tasks with event relationships and token usage tracking

## Developer API Reference

### __init__.py
**Purpose:** Package entry point that exposes all SQLAlchemy models and Pydantic schemas
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.models import Base, ChatTaskModel, FeedbackModel, SessionModel, CreateSessionModel, UpdateSessionModel, TaskEventModel, TaskModel`

**Constants/Variables:**
- `__all__: List[str]` - Public API exports including all models and schemas

### base.py
**Purpose:** Provides the SQLAlchemy declarative base for all models
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.models.base import Base`

**Constants/Variables:**
- `Base: DeclarativeMeta` - SQLAlchemy declarative base class for all models

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.models.base import Base
from sqlalchemy import create_engine

# Create all tables
engine = create_engine("sqlite:///example.db")
Base.metadata.create_all(engine)
```

### chat_task_model.py
**Purpose:** SQLAlchemy model for storing chat tasks with session relationships
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.models.chat_task_model import ChatTaskModel`

**Classes:**
- `ChatTaskModel(Base)` - SQLAlchemy model for chat tasks
  - `id: Column[String]` - Primary key task identifier
  - `session_id: Column[String]` - Foreign key to sessions table with CASCADE delete (indexed)
  - `user_id: Column[String]` - User identifier (indexed)
  - `user_message: Column[Text]` - Optional user message content
  - `message_bubbles: Column[Text]` - Required message bubbles data
  - `task_metadata: Column[Text]` - Optional task metadata
  - `created_time: Column[BigInteger]` - Creation timestamp in epoch milliseconds (indexed)
  - `updated_time: Column[BigInteger]` - Optional update timestamp
  - `session: relationship` - SQLAlchemy relationship to SessionModel

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.models.chat_task_model import ChatTaskModel
from sqlalchemy.orm import sessionmaker

# Create a chat task
chat_task = ChatTaskModel(
    id="task_123",
    session_id="session_456",
    user_id="user_789",
    user_message="Hello, how can you help me?",
    message_bubbles='[{"type": "user", "content": "Hello"}]',
    task_metadata='{"priority": "high"}',
    created_time=1640995200000,
    updated_time=1640995260000
)

# Add to database
Session = sessionmaker(bind=engine)
db_session = Session()
db_session.add(chat_task)
db_session.commit()

# Access related session
session = chat_task.session
```

### feedback_model.py
**Purpose:** SQLAlchemy model for storing user feedback on tasks
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.models.feedback_model import FeedbackModel`

**Classes:**
- `FeedbackModel(Base)` - SQLAlchemy model for user feedback
  - `id: Column[String]` - Primary key feedback identifier
  - `session_id: Column[String]` - Session identifier
  - `task_id: Column[String]` - Task identifier (indexed)
  - `user_id: Column[String]` - User identifier (indexed)
  - `rating: Column[String]` - Feedback rating (e.g., 'up', 'down')
  - `comment: Column[Text]` - Optional feedback comment
  - `created_time: Column[BigInteger]` - Creation timestamp in epoch milliseconds

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.models.feedback_model import FeedbackModel
from sqlalchemy.orm import sessionmaker

# Create feedback
feedback = FeedbackModel(
    id="feedback_123",
    session_id="session_456",
    task_id="task_789",
    user_id="user_123",
    rating="up",
    comment="Great response!",
    created_time=1640995200000
)

# Add to database
Session = sessionmaker(bind=engine)
db_session = Session()
db_session.add(feedback)
db_session.commit()
```

### session_model.py
**Purpose:** SQLAlchemy model and Pydantic schemas for managing chat sessions with chat task relationships
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.models.session_model import SessionModel, CreateSessionModel, UpdateSessionModel`

**Classes:**
- `SessionModel(Base)` - SQLAlchemy model for chat sessions
  - `id: Column[String]` - Primary key session identifier
  - `name: Column[String]` - Optional session name
  - `user_id: Column[String]` - Required user identifier
  - `agent_id: Column[String]` - Optional agent identifier
  - `created_time: Column[BigInteger]` - Creation timestamp (auto-generated)
  - `updated_time: Column[BigInteger]` - Last update timestamp (auto-updated)
  - `chat_tasks: relationship` - SQLAlchemy relationship to ChatTaskModel with cascade delete

- `CreateSessionModel(BaseModel)` - Pydantic model for creating sessions
  - `id: str` - Session identifier
  - `name: str | None` - Optional session name
  - `user_id: str` - User identifier
  - `agent_id: str | None` - Optional agent identifier
  - `created_time: int` - Creation timestamp
  - `updated_time: int` - Update timestamp

- `UpdateSessionModel(BaseModel)` - Pydantic model for updating sessions
  - `name: str | None` - Optional updated session name
  - `agent_id: str | None` - Optional updated agent identifier
  - `updated_time: int` - Update timestamp

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.models.session_model import SessionModel, CreateSessionModel
from sqlalchemy.orm import sessionmaker

# Create using SQLAlchemy model
session = SessionModel(
    id="session_123",
    name="My Chat Session",
    user_id="user_456",
    agent_id="agent_789"
)

# Create using Pydantic model
create_data = CreateSessionModel(
    id="session_124",
    name="Another Session",
    user_id="user_456",
    agent_id="agent_789",
    created_time=1640995200000,
    updated_time=1640995200000
)

# Access related chat tasks
chat_tasks = session.chat_tasks  # Returns list of ChatTaskModel instances
```

### task_event_model.py
**Purpose:** SQLAlchemy model for storing A2A task events with task relationships
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.models.task_event_model import TaskEventModel`

**Classes:**
- `TaskEventModel(Base)` - SQLAlchemy model for A2A task events
  - `id: Column[String]` - Primary key event identifier
  - `task_id: Column[String]` - Foreign key to tasks table with CASCADE delete (indexed)
  - `user_id: Column[String]` - Optional user identifier (indexed)
  - `created_time: Column[BigInteger]` - Creation timestamp in epoch milliseconds
  - `topic: Column[Text]` - Event topic
  - `direction: Column[String]` - Event direction (max 50 chars)
  - `payload: Column[JSON]` - Event payload as JSON
  - `task: relationship` - SQLAlchemy relationship to TaskModel

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.models.task_event_model import TaskEventModel
from sqlalchemy.orm import sessionmaker

# Create a task event
event = TaskEventModel(
    id="event_123",
    task_id="task_456",
    user_id="user_789",
    created_time=1640995200000,
    topic="agent/response",
    direction="inbound",
    payload={"message": "Task completed", "status": "success"}
)

# Add to database
Session = sessionmaker(bind=engine)
db_session = Session()
db_session.add(event)
db_session.commit()
```

### task_model.py
**Purpose:** SQLAlchemy model for managing tasks with event relationships and token usage tracking
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.models.task_model import TaskModel`

**Classes:**
- `TaskModel(Base)` - SQLAlchemy model for tasks
  - `id: Column[String]` - Primary key task identifier
  - `user_id: Column[String]` - User identifier (indexed)
  - `start_time: Column[BigInteger]` - Task start timestamp in epoch milliseconds
  - `end_time: Column[BigInteger]` - Optional task end timestamp
  - `status: Column[String]` - Optional task status
  - `initial_request_text: Column[Text]` - Optional initial request text (indexed)
  - `total_input_tokens: Column[Integer]` - Optional total input tokens used
  - `total_output_tokens: Column[Integer]` - Optional total output tokens used
  - `total_cached_input_tokens: Column[Integer]` - Optional total cached input tokens
  - `token_usage_details: Column[JSON]` - Optional detailed token usage information
  - `events: relationship` - SQLAlchemy relationship to TaskEventModel with cascade delete

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.models.task_model import TaskModel
from sqlalchemy.orm import sessionmaker

# Create a new task with token tracking
task = TaskModel(
    id="task_123",
    user_id="user_456",
    start_time=1640995200000,
    status="in_progress",
    initial_request_text="Please help me with this task",
    total_input_tokens=150,
    total_output_tokens=300,
    total_cached_input_tokens=50,
    token_usage_details={"model": "gpt-4", "breakdown": {"reasoning": 200, "response": 100}}
)

# Add to database
Session = sessionmaker(bind=engine)
db_session = Session()
db_session.add(task)
db_session.commit()

# Access related events
events = task.events  # Returns list of TaskEventModel instances
```

================================================================================

## Section 34: solace_agent_mesh/gateway/http_sse/repository/repository_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/repository/repository_llm.txt`

# DEVELOPER GUIDE: repository

## Quick Summary

The repository directory implements the data access layer for the HTTP SSE gateway using the Repository pattern with SQLAlchemy ORM. It provides a clean separation between domain entities (business logic) and database persistence through abstract interfaces and concrete implementations. The architecture consists of repository interfaces defining contracts, SQLAlchemy implementations, domain entities with validation, and ORM models for database schema. The entities/ subdirectory contains business objects while models/ contains database persistence logic, working together to provide comprehensive data management for chat sessions, tasks, feedback, and events.

## Files and Subdirectories Overview

**Direct files:**
- `__init__.py` - Main package exports for repository interfaces, implementations, entities, and models
- `interfaces.py` - Abstract repository interfaces defining data access contracts
- `session_repository.py` - SQLAlchemy implementation of session data access operations
- `chat_task_repository.py` - SQLAlchemy implementation of chat task data access operations  
- `feedback_repository.py` - SQLAlchemy implementation of feedback data access operations
- `task_repository.py` - SQLAlchemy implementation of task data access operations

**Subdirectories:**
- `entities/` - Domain entities with business logic for sessions, tasks, feedback, and events
- `models/` - SQLAlchemy ORM models for database persistence and schema definition

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Central package exports for all repository components
**Import:** `from solace_agent_mesh.gateway.http_sse.repository import ISessionRepository, SessionRepository, Session, Base, SessionModel`

**Exports:**
- `ISessionRepository` - Session repository interface
- `SessionRepository` - Session repository implementation
- `Session` - Session domain entity
- `Base` - SQLAlchemy declarative base
- `SessionModel` - SQLAlchemy session model

#### interfaces.py
**Purpose:** Defines abstract repository interfaces for data access contracts
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.interfaces import ISessionRepository, ITaskRepository, IFeedbackRepository, IChatTaskRepository`

**Classes:**
- `ISessionRepository(ABC)` - Abstract interface for session data operations
  - `find_by_user(session: DBSession, user_id: UserId, pagination: PaginationParams | None = None) -> list[Session]` - Find all sessions for a user
  - `count_by_user(session: DBSession, user_id: UserId) -> int` - Count total sessions for a user
  - `find_user_session(session: DBSession, session_id: SessionId, user_id: UserId) -> Session | None` - Find specific user session
  - `save(session: DBSession, session_obj: Session) -> Session` - Save or update a session
  - `delete(session: DBSession, session_id: SessionId, user_id: UserId) -> bool` - Delete user session

- `ITaskRepository(ABC)` - Abstract interface for task data operations
  - `save_task(session: DBSession, task: Task) -> Task` - Create or update a task
  - `save_event(session: DBSession, event: TaskEvent) -> TaskEvent` - Save a task event
  - `find_by_id(session: DBSession, task_id: str) -> Task | None` - Find a task by its ID
  - `find_by_id_with_events(session: DBSession, task_id: str) -> tuple[Task, list[TaskEvent]] | None` - Find a task with all its events
  - `search(session: DBSession, user_id: UserId, start_date: int | None = None, end_date: int | None = None, search_query: str | None = None, pagination: PaginationParams | None = None) -> list[Task]` - Search for tasks with filters
  - `delete_tasks_older_than(session: DBSession, cutoff_time_ms: int, batch_size: int) -> int` - Delete tasks older than cutoff time

- `IFeedbackRepository(ABC)` - Abstract interface for feedback data operations
  - `save(session: DBSession, feedback: Feedback) -> Feedback` - Save feedback
  - `delete_feedback_older_than(session: DBSession, cutoff_time_ms: int, batch_size: int) -> int` - Delete feedback older than cutoff time

- `IChatTaskRepository(ABC)` - Abstract interface for chat task data operations
  - `save(session: DBSession, task: ChatTask) -> ChatTask` - Save or update a chat task (upsert)
  - `find_by_session(session: DBSession, session_id: SessionId, user_id: UserId) -> list[ChatTask]` - Find all tasks for a session
  - `find_by_id(session: DBSession, task_id: str, user_id: UserId) -> Optional[ChatTask]` - Find a specific task
  - `delete_by_session(session: DBSession, session_id: SessionId) -> bool` - Delete all tasks for a session

#### session_repository.py
**Purpose:** SQLAlchemy implementation of session repository interface
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.session_repository import SessionRepository`

**Classes:**
- `SessionRepository(PaginatedRepository[SessionModel, Session], ISessionRepository)` - SQLAlchemy session repository implementation
  - `find_by_user(session: DBSession, user_id: UserId, pagination: PaginationParams | None = None) -> list[Session]` - Find user sessions with pagination
  - `count_by_user(session: DBSession, user_id: UserId) -> int` - Count total sessions for a user
  - `find_user_session(session: DBSession, session_id: SessionId, user_id: UserId) -> Session | None` - Find specific user session
  - `save(db_session: DBSession, session: Session) -> Session` - Save or update session in database
  - `delete(db_session: DBSession, session_id: SessionId, user_id: UserId) -> bool` - Delete user session

#### chat_task_repository.py
**Purpose:** SQLAlchemy implementation of chat task repository interface
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.chat_task_repository import ChatTaskRepository`

**Classes:**
- `ChatTaskRepository(IChatTaskRepository)` - SQLAlchemy chat task repository implementation
  - `save(session: DBSession, task: ChatTask) -> ChatTask` - Save or update a chat task (upsert)
  - `find_by_session(session: DBSession, session_id: SessionId, user_id: UserId) -> List[ChatTask]` - Find all tasks for a session
  - `find_by_id(session: DBSession, task_id: str, user_id: UserId) -> Optional[ChatTask]` - Find a specific task
  - `delete_by_session(session: DBSession, session_id: SessionId) -> bool` - Delete all tasks for a session
  - `_model_to_entity(model: ChatTaskModel) -> ChatTask` - Convert SQLAlchemy model to domain entity

#### feedback_repository.py
**Purpose:** SQLAlchemy implementation of feedback repository interface
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.feedback_repository import FeedbackRepository`

**Classes:**
- `FeedbackRepository(IFeedbackRepository)` - SQLAlchemy feedback repository implementation
  - `save(session: DBSession, feedback: Feedback) -> Feedback` - Save feedback to database
  - `delete_feedback_older_than(session: DBSession, cutoff_time_ms: int, batch_size: int) -> int` - Delete feedback older than cutoff time using batch deletion
  - `_model_to_entity(model: FeedbackModel) -> Feedback` - Convert SQLAlchemy model to domain entity

#### task_repository.py
**Purpose:** SQLAlchemy implementation of task repository interface
**Import:** `from solace_agent_mesh.gateway.http_sse.repository.task_repository import TaskRepository`

**Classes:**
- `TaskRepository(ITaskRepository)` - SQLAlchemy task repository implementation
  - `save_task(session: DBSession, task: Task) -> Task` - Create or update a task
  - `save_event(session: DBSession, event: TaskEvent) -> TaskEvent` - Save a task event
  - `find_by_id(session: DBSession, task_id: str) -> Task | None` - Find a task by its ID
  - `find_by_id_with_events(session: DBSession, task_id: str) -> tuple[Task, list[TaskEvent]] | None` - Find a task with all its events
  - `search(session: DBSession, user_id: UserId, start_date: int | None = None, end_date: int | None = None, pagination: PaginationParams | None = None) -> list[Task]` - Search for tasks with filters
  - `delete_tasks_older_than(session: DBSession, cutoff_time_ms: int, batch_size: int) -> int` - Delete tasks older than cutoff time using batch deletion
  - `_task_model_to_entity(model: TaskModel) -> Task` - Convert SQLAlchemy task model to domain entity
  - `_event_model_to_entity(model: TaskEventModel) -> TaskEvent` - Convert SQLAlchemy event model to domain entity

### Subdirectory APIs

#### entities/
**Purpose:** Provides domain entities with business logic for sessions, tasks, feedback, and events
**Key Exports:** ChatTask, Feedback, Session, Task, TaskEvent
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.entities import ChatTask, Feedback, Session, Task, TaskEvent
```

#### models/
**Purpose:** Provides SQLAlchemy ORM models for database persistence and schema definition
**Key Exports:** Base, ChatTaskModel, FeedbackModel, SessionModel, TaskModel, TaskEventModel, CreateSessionModel, UpdateSessionModel
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.repository.models import Base, SessionModel, ChatTaskModel, TaskModel, FeedbackModel
```

## Complete Usage Guide

### 1. Setting Up the Repository Layer

```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from solace_agent_mesh.gateway.http_sse.repository import (
    Base, SessionRepository, ChatTaskRepository, TaskRepository, FeedbackRepository
)

# Create database engine and session
engine = create_engine("sqlite:///chat.db")
Base.metadata.create_all(engine)
SessionMaker = sessionmaker(bind=engine)
db_session = SessionMaker()

# Initialize repositories
session_repo = SessionRepository()
chat_task_repo = ChatTaskRepository()
task_repo = TaskRepository()
feedback_repo = FeedbackRepository()
```

### 2. Working with Sessions

```python
from solace_agent_mesh.gateway.http_sse.repository.entities import Session
from solace_agent_mesh.gateway.http_sse.shared.pagination import PaginationParams
import time

# Create a new session
session = Session(
    id="session_123",
    user_id="user_456",
    name="Customer Support Chat",
    agent_id="agent_789",
    created_time=int(time.time() * 1000)
)

# Save session
saved_session = session_repo.save(db_session, session)

# Find user sessions with pagination
pagination = PaginationParams(page=1, page_size=10)
user_sessions = session_repo.find_by_user(db_session, "user_456", pagination)

# Count total sessions for user
total_sessions = session_repo.count_by_user(db_session, "user_456")

# Find specific session
found_session = session_repo.find_user_session(db_session, "session_123", "user_456")

# Update session
if found_session:
    found_session.update_name("Updated Chat Name")
    session_repo.save(db_session, found_session)

# Delete session
deleted = session_repo.delete(db_session, "session_123", "user_456")
db_session.commit()
```

### 3. Working with Chat Tasks

```python
from solace_agent_mesh.gateway.http_sse.repository.entities import ChatTask
import json

# Create a chat task with message bubbles
message_bubbles = json.dumps([
    {"type": "user", "content": "Hello, I need help"},
    {"type": "agent", "content": "Hi! How can I assist you today?"}
])

chat_task = ChatTask(
    id="chat_task_123",
    session_id="session_123",
    user_id="user_456",
    user_message="Hello, I need help",
    message_bubbles=message_bubbles,
    created_time=int(time.time() * 1000)
)

# Save chat task
saved_task = chat_task_repo.save(db_session, chat_task)

# Find all tasks for a session
session_tasks = chat_task_repo.find_by_session(db_session, "session_123", "user_456")

# Find specific task
found_task = chat_task_repo.find_by_id(db_session, "chat_task_123", "user_456")

# Add feedback to task
if found_task:
    found_task.add_feedback("positive", "Great response!")
    chat_task_repo.save(db_session, found_task)

# Delete all tasks for a session
deleted = chat_task_repo.delete_by_session(db_session, "session_123")
db_session.commit()
```

### 4. Working with Tasks and Events

```python
from solace_agent_mesh.gateway.http_sse.repository.entities import Task, TaskEvent

# Create a new task
task = Task(
    id="task_123",
    user_id="user_456",
    start_time=int(time.time() * 1000),
    status="in_progress",
    initial_request_text="Help me with my order",
    total_input_tokens=150,
    total_output_tokens=300
)

# Save task
saved_task = task_repo.save_task(db_session, task)

# Create task event
event = TaskEvent(
    id="event_123",
    task_id="task_123",
    user_id="user_456",
    created_time=int(time.time() * 1000),
    topic="task.status.changed",
    direction="outbound",
    payload={"status": "completed", "result": "success"}
)

# Save event
saved_event = task_repo.save_event(db_session, event)

# Find task with events
result = task_repo.find_by_id_with_events(db_session, "task_123")
if result:
    task, events = result
    print(f"Task {task.id} has {len(events)} events")

# Search tasks with filters
from solace_agent_mesh.gateway.http_sse.shared.pagination import PaginationParams
pagination_params = PaginationParams(page=1, page_size=10)
start_date = int((time.time() - 86400) * 1000)  # 24 hours ago
end_date = int(time.time() * 1000)

tasks = task_repo.search(
    db_session,
    user_id="user_456",
    start_date=start_date,
    end_date=end_date,
    pagination=pagination_params
)

# Batch delete old tasks
cutoff_time = int((time.time() - 7 * 86400) * 1000)  # 7 days ago
deleted_count = task_repo.delete_tasks_older_than(db_session, cutoff_time, batch_size=100)
print(f"Deleted {deleted_count} old tasks")
```

### 5. Working with Feedback

```python
from solace_agent_mesh.gateway.http_sse.repository.entities import Feedback

# Create feedback
feedback = Feedback(
    id="feedback_123",
    session_id="session_123",
    task_id="task_123",
    user_id="user_456",
    rating="up",

================================================================================

## Section 35: solace_agent_mesh/gateway/http_sse/routers/dto/dto_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/routers/dto/dto_llm.txt`

# DEVELOPER GUIDE: dto

## Quick Summary
The `dto` directory contains Data Transfer Objects (DTOs) for API contract definition and validation in the HTTP SSE gateway. It's organized into two main subdirectories: `requests` for incoming API request validation using Pydantic models, and `responses` for structured API response formatting with automatic timestamp conversion. The DTOs primarily focus on session management and task operations, providing type-safe interfaces for API endpoints with field aliasing and validation.

## Files and Subdirectories Overview
- **Direct files:** 
  - `__init__.py` - Main module exports for requests and responses submodules
- **Subdirectories:**
  - `requests/` - Request DTOs for API endpoint validation (session and task CRUD operations)
  - `responses/` - Response DTOs with automatic timestamp serialization and field aliasing

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Main entry point that exports the requests and responses submodules
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.dto import requests, responses`

**Exports:**
- `requests` - Module containing all request DTOs
- `responses` - Module containing all response DTOs

### Subdirectory APIs

#### requests/
**Purpose:** Provides Pydantic models for validating incoming API requests for session management and task operations
**Key Exports:** GetSessionRequest, UpdateSessionRequest, SaveTaskRequest
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.routers.dto.requests import (
    GetSessionRequest,
    UpdateSessionRequest,
    SaveTaskRequest
)
```

#### responses/
**Purpose:** Provides structured response DTOs with automatic timestamp conversion and field aliasing for API consistency
**Key Exports:** SessionResponse, SessionListResponse, TaskResponse, TaskListResponse, BaseTimestampResponse
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.routers.dto.responses import (
    SessionResponse,
    SessionListResponse,
    TaskResponse,
    TaskListResponse
)
```

## Complete Usage Guide

### 1. Basic Imports and Setup

```python
# Import the main dto modules
from solace_agent_mesh.gateway.http_sse.routers.dto import requests, responses

# Or import specific DTOs directly
from solace_agent_mesh.gateway.http_sse.routers.dto.requests import (
    GetSessionRequest,
    UpdateSessionRequest,
    SaveTaskRequest
)
from solace_agent_mesh.gateway.http_sse.routers.dto.responses import (
    SessionResponse,
    SessionListResponse,
    TaskResponse,
    TaskListResponse
)
```

### 2. Working with Session Request DTOs

```python
from solace_agent_mesh.gateway.http_sse.routers.dto.requests import (
    GetSessionRequest,
    UpdateSessionRequest
)
from pydantic import ValidationError

# Create a request to get a specific session
def get_session(session_id: str, user_id: str):
    try:
        request = GetSessionRequest(
            session_id=session_id,
            user_id=user_id
        )
        return request
    except ValidationError as e:
        print(f"Invalid request parameters: {e}")
        return None

# Create a request to update session name
def update_session_name(session_id: str, user_id: str, new_name: str):
    try:
        request = UpdateSessionRequest(
            session_id=session_id,
            user_id=user_id,
            name=new_name  # Automatically validated (1-255 characters)
        )
        return request
    except ValidationError as e:
        print(f"Validation failed: {e}")
        return None
```

### 3. Working with Task Request DTOs

```python
from solace_agent_mesh.gateway.http_sse.routers.dto.requests import SaveTaskRequest
from pydantic import ValidationError
import json

# Create a save task request with camelCase field names (API style)
def save_task_with_validation(task_id: str, message_bubbles: list, user_message: str = None, metadata: dict = None):
    try:
        # Convert data to JSON strings as required
        bubbles_json = json.dumps(message_bubbles)
        metadata_json = json.dumps(metadata) if metadata else None
        
        request = SaveTaskRequest(
            task_id=task_id,
            user_message=user_message,
            message_bubbles=bubbles_json,
            task_metadata=metadata_json
        )
        return request
    except ValidationError as e:
        print(f"Task validation failed: {e}")
        return None

# Example usage
task_request = save_task_with_validation(
    task_id="task_123",
    message_bubbles=[
        {"type": "user", "content": "Hello"},
        {"type": "assistant", "content": "Hi there!"}
    ],
    user_message="Please analyze this data",
    metadata={"priority": "high", "category": "analysis"}
)
```

### 4. Working with Session Response DTOs

```python
from solace_agent_mesh.gateway.http_sse.routers.dto.responses import (
    SessionResponse,
    SessionListResponse
)
import time

# Create session responses
def create_session_response(session_data: dict) -> SessionResponse:
    return SessionResponse(
        id=session_data["id"],
        user_id=session_data["user_id"],
        name=session_data.get("name"),
        agent_id=session_data.get("agent_id"),
        created_time=int(time.time() * 1000),  # Current time in epoch ms
        updated_time=session_data.get("updated_time")
    )

# Create paginated session list responses
def create_session_list_response(sessions: list, total: int) -> SessionListResponse:
    session_responses = [create_session_response(session) for session in sessions]
    return SessionListResponse(
        sessions=session_responses,
        pagination={"page": 1, "size": len(sessions), "total_pages": 1},
        total_count=total
    )
```

### 5. Working with Task Response DTOs

```python
from solace_agent_mesh.gateway.http_sse.routers.dto.responses import (
    TaskResponse,
    TaskListResponse
)
import json
import time

# Create task responses
def create_task_response(task_data: dict) -> TaskResponse:
    return TaskResponse(
        task_id=task_data["task_id"],
        session_id=task_data["session_id"],
        user_message=task_data.get("user_message"),
        message_bubbles=json.dumps(task_data["message_bubbles"]),
        task_metadata=json.dumps(task_data["metadata"]) if task_data.get("metadata") else None,
        created_time=int(time.time() * 1000),
        updated_time=task_data.get("updated_time")
    )

# Create task list responses
def create_task_list_response(tasks: list) -> TaskListResponse:
    task_responses = [create_task_response(task) for task in tasks]
    return TaskListResponse(tasks=task_responses)
```

### 6. Complete API Endpoint Examples

```python
from fastapi import APIRouter, HTTPException
from solace_agent_mesh.gateway.http_sse.routers.dto.requests import (
    GetSessionRequest,
    UpdateSessionRequest,
    SaveTaskRequest
)
from solace_agent_mesh.gateway.http_sse.routers.dto.responses import (
    SessionResponse,
    SessionListResponse,
    TaskResponse
)

router = APIRouter()

@router.get("/sessions/{session_id}")
async def get_session(session_id: str, user_id: str) -> SessionResponse:
    """Get a specific session"""
    
    # Create and validate request DTO
    request = GetSessionRequest(
        session_id=session_id,
        user_id=user_id
    )
    
    # Fetch data (mock implementation)
    session_data = fetch_session(request)
    
    # Return structured response with automatic timestamp conversion
    return SessionResponse(
        id=session_data["id"],
        user_id=session_data["user_id"],
        name=session_data["name"],
        created_time=session_data["created_time"]
    )

@router.put("/sessions/{session_id}")
async def update_session(
    session_id: str,
    user_id: str,
    name: str
) -> SessionResponse:
    """Update session name"""
    
    # Validate request using DTO
    try:
        request = UpdateSessionRequest(
            session_id=session_id,
            user_id=user_id,
            name=name
        )
    except ValidationError as e:
        raise HTTPException(status_code=400, detail=str(e))
    
    # Update session (mock implementation)
    updated_session = update_session_in_db(request)
    
    # Return response DTO with automatic field aliasing
    return SessionResponse(
        id=updated_session["id"],
        user_id=updated_session["user_id"],
        name=updated_session["name"],
        created_time=updated_session["created_time"],
        updated_time=updated_session["updated_time"]
    )

@router.post("/tasks")
async def save_task(
    task_id: str,
    message_bubbles: str,
    user_message: str = None,
    task_metadata: str = None
) -> TaskResponse:
    """Save a new task"""
    
    # Validate request using DTO
    try:
        request = SaveTaskRequest(
            task_id=task_id,
            user_message=user_message,
            message_bubbles=message_bubbles,
            task_metadata=task_metadata
        )
    except ValidationError as e:
        raise HTTPException(status_code=400, detail=str(e))
    
    # Save task (mock implementation)
    saved_task = save_task_to_db(request)
    
    # Return response DTO
    return TaskResponse(
        task_id=saved_task["task_id"],
        session_id=saved_task["session_id"],
        user_message=saved_task["user_message"],
        message_bubbles=saved_task["message_bubbles"],
        task_metadata=saved_task["task_metadata"],
        created_time=saved_task["created_time"]
    )
```

### 7. JSON Serialization with Automatic Timestamp Conversion

```python
from solace_agent_mesh.gateway.http_sse.routers.dto.responses import SessionResponse, TaskResponse
import json

# Create a session response
session = SessionResponse(
    id="sess_123",
    user_id="user_456",
    name="My Session",
    created_time=1640995200000,  # Epoch milliseconds
    updated_time=1640995260000
)

# Automatic conversion to ISO strings in JSON output
json_output = session.model_dump_json()
print(json_output)
# Output: {
#   "id": "sess_123",
#   "userId": "user_456",  # Note the camelCase aliasing
#   "name": "My Session",
#   "createdTime": "2022-01-01T00:00:00Z",  # Converted to ISO string
#   "updatedTime": "2022-01-01T00:01:00Z"
# }

# Create a task response with field aliasing
task = TaskResponse(
    task_id="task_789",
    session_id="sess_123",
    user_message="Process this data",
    message_bubbles='[{"type": "text", "content": "Processing..."}]',
    task_metadata='{"priority": "high"}',
    created_time=1640995200000
)

# Get dict with converted timestamps and aliased fields
dict_output = task.model_dump()
print(dict_output["taskId"])  # "task_789" (camelCase alias)
print(dict_output["sessionId"])  # "sess_123" (camelCase alias)
print(dict_output["createdTime"])  # "2022-01-01T00:00:00Z" (converted timestamp)
```

### 8. Custom Response Classes Using Base

```python
from solace_agent_mesh.gateway.http_sse.routers.dto.responses.base_responses import BaseTimestampResponse

class CustomResponse(BaseTimestampResponse):
    """Custom response with automatic timestamp handling"""
    name: str
    status: str
    created_time: int
    last_accessed: int | None = None
    
    class Config:
        # Add field aliases if needed
        alias_generator = lambda field_name: ''.join(
            word.capitalize() if i > 0 else word 
            for i, word in enumerate(field_name.split('_'))
        )

# Usage
custom_response = CustomResponse(
    name="Test Item",
    status="active",
    created_time=1640995200000,
    last_accessed=1640995300000
)

# Automatic timestamp conversion in JSON
json_data = custom_response.model_dump_json()
# Fields like created_time become ISO strings automatically
```

### 9. Working with Both Requests and Responses Together

```python
from solace_agent_mesh.gateway.http_sse.routers.dto.requests import UpdateSessionRequest, SaveTaskRequest
from solace_agent_mesh.gateway.http_sse.routers.dto.responses import SessionResponse, TaskResponse
from pydantic import ValidationError
import json

async def complete_session_workflow():
    """Example showing complete request/response workflow"""
    
    # 1. Validate incoming request data
    try:
        update_request = UpdateSessionRequest(
            session_id="sess_123",
            user_id="user_456",
            name="Updated Session Name"
        )
    except ValidationError as e:
        return {"error": f"Invalid session update request: {e}"}
    
    # 2. Process the request (mock database operation)
    updated_session_data = {
        "id": update_request.session_id,
        "user_id": update_request.user_id,
        "name": update_request.name,
        "created_time": 1640995200000,
        "updated_time": 1640995260000
    }
    
    # 3. Create structured response
    session_response = SessionResponse(**updated_session_data)
    
    # 4. Save a related task
    try:
        task_request = SaveTaskRequest(
            task_id="task_456",
            user_message="Session updated successfully",
            message_bubbles=json.dumps([
                {"type": "system", "content": "Session name updated"}
            ]),
            task_metadata=json.dumps({"action": "session_update"})
        )
    except ValidationError as e:
        return {"error": f"Invalid task request: {e}"}
    
    # 5. Create task response
    task_response = TaskResponse(
        task_id=task_request.task_id,
        session_id=update_request.session_id,
        user_message=task_request.user_message,
        message_bubbles=task_request.message_bubbles,
        task_metadata=task_request.task_metadata,
        created_time=1640995300000
    )
    
    # 6. Return both responses with automatic field aliasing and timestamp conversion
    return {
        "session": session_response.model_dump(),
        "task": task_response.model_dump()
    }

# Usage
result = await complete_session_workflow()
print(json.dumps(result, indent=2))
```

This comprehensive guide shows how the `dto` directory provides a complete type-safe API contract system with automatic validation for requests and structured responses with timestamp conversion and field aliasing for both session management and task operations in the HTTP SSE gateway.

================================================================================

## Section 36: solace_agent_mesh/gateway/http_sse/routers/dto/requests/requests_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/routers/dto/requests/requests_llm.txt`

# DEVELOPER GUIDE: requests

## Quick Summary
This directory contains request Data Transfer Objects (DTOs) for API endpoints, providing Pydantic models for session management and task operations. These DTOs handle request validation, field transformation, and type safety for incoming API requests.

## Files Overview
- `__init__.py` - Exports all request DTOs for centralized importing
- `session_requests.py` - Defines request DTOs for session operations (get, update)
- `task_requests.py` - Defines request DTOs for task operations (save)

## Developer API Reference

### __init__.py
**Purpose:** Provides centralized imports for all request DTOs
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.dto.requests import GetSessionRequest, UpdateSessionRequest, SaveTaskRequest`

**Usage Examples:**
```python
# Import all request DTOs
from solace_agent_mesh.gateway.http_sse.routers.dto.requests import (
    GetSessionRequest,
    UpdateSessionRequest,
    SaveTaskRequest
)
```

### session_requests.py
**Purpose:** Defines Pydantic models for session-related API request validation
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.dto.requests.session_requests import GetSessionRequest, UpdateSessionRequest`

**Classes:**
- `GetSessionRequest(session_id: SessionId, user_id: UserId)` - Request DTO for retrieving a specific session by ID
- `UpdateSessionRequest(session_id: SessionId, user_id: UserId, name: str)` - Request DTO for updating session details with validation (name must be 1-255 characters)

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.routers.dto.requests.session_requests import (
    GetSessionRequest,
    UpdateSessionRequest
)
from pydantic import ValidationError

# Create a request to get a specific session
get_session_req = GetSessionRequest(
    session_id="session456",
    user_id="user123"
)

# Create a request to update a session name
update_req = UpdateSessionRequest(
    session_id="session456",
    user_id="user123",
    name="My Updated Session"
)

# Validate request data from dictionary
request_data = {
    "session_id": "session789",
    "user_id": "user456",
    "name": "New Session Name"
}

try:
    validated_request = UpdateSessionRequest(**request_data)
    print(f"Valid request: {validated_request}")
except ValidationError as e:
    print(f"Validation failed: {e}")

# Access validated fields
print(f"Session ID: {update_req.session_id}")
print(f"User ID: {update_req.user_id}")
print(f"New name: {update_req.name}")
```

### task_requests.py
**Purpose:** Defines Pydantic models for task-related API request validation with JSON field handling
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.dto.requests.task_requests import SaveTaskRequest`

**Classes:**
- `SaveTaskRequest(task_id: str, user_message: Optional[str], message_bubbles: str, task_metadata: Optional[str])` - Request DTO for saving tasks with JSON validation
  - `validate_task_id(v: str) -> str` - Validates task_id is non-empty and strips whitespace
  - `validate_message_bubbles(v: str) -> str` - Validates message_bubbles is valid non-empty JSON array
  - `validate_task_metadata(v: Optional[str]) -> Optional[str]` - Validates task_metadata is valid JSON if provided

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.routers.dto.requests.task_requests import SaveTaskRequest
from pydantic import ValidationError
import json

# Create a save task request with camelCase field names (API style)
task_data = {
    "taskId": "task_123",
    "userMessage": "Please analyze this data",
    "messageBubbles": json.dumps([
        {"type": "user", "content": "Hello"},
        {"type": "assistant", "content": "Hi there!"}
    ]),
    "taskMetadata": json.dumps({"priority": "high", "category": "analysis"})
}

try:
    save_task_req = SaveTaskRequest(**task_data)
    print(f"Task ID: {save_task_req.task_id}")
    print(f"User Message: {save_task_req.user_message}")
    print(f"Message Bubbles: {save_task_req.message_bubbles}")
    print(f"Task Metadata: {save_task_req.task_metadata}")
except ValidationError as e:
    print(f"Validation failed: {e}")

# Create with snake_case field names (internal style)
task_data_snake = {
    "task_id": "task_456",
    "user_message": "Process this request",
    "message_bubbles": json.dumps([{"type": "system", "content": "Processing..."}]),
    "task_metadata": None  # Optional field
}

save_task_req2 = SaveTaskRequest(**task_data_snake)

# Handle validation errors
invalid_data = {
    "taskId": "",  # Empty task_id will fail validation
    "messageBubbles": "invalid json"  # Invalid JSON will fail
}

try:
    SaveTaskRequest(**invalid_data)
except ValidationError as e:
    print(f"Expected validation error: {e}")
```

================================================================================

## Section 37: solace_agent_mesh/gateway/http_sse/routers/dto/responses/responses_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/routers/dto/responses/responses_llm.txt`

# DEVELOPER GUIDE: responses

## Quick Summary
The `responses` directory contains Pydantic response DTOs (Data Transfer Objects) for API endpoints. It provides structured response models with automatic timestamp conversion from epoch milliseconds to ISO 8601 strings for JSON serialization, covering sessions, tasks, and messages.

## Files Overview
- `__init__.py` - Exports all response DTOs for easy importing
- `base_responses.py` - Base response class with automatic timestamp serialization
- `session_responses.py` - Session-related response DTOs with field aliasing
- `task_responses.py` - Task-related response DTOs with field aliasing

## Developer API Reference

### __init__.py
**Purpose:** Central import point for all response DTOs
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.dto.responses import SessionResponse, SessionListResponse, TaskResponse, TaskListResponse`

### base_responses.py
**Purpose:** Provides base response class with automatic timestamp field conversion
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.dto.responses.base_responses import BaseTimestampResponse`

**Classes:**
- `BaseTimestampResponse(BaseModel)` - Base class for responses with timestamp fields that auto-converts epoch ms to ISO strings
  - `model_dump(**kwargs) -> dict[str, Any]` - Converts timestamp fields to ISO strings in output
  - `model_dump_json(**kwargs) -> str` - Serializes to JSON with timestamp conversion

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.routers.dto.responses.base_responses import BaseTimestampResponse

class MyResponse(BaseTimestampResponse):
    name: str
    created_time: int  # Will be auto-converted to ISO string in JSON output
    updated_time: int | None = None

# Usage
response = MyResponse(name="test", created_time=1640995200000)
json_data = response.model_dump()  # created_time becomes ISO string
```

### session_responses.py
**Purpose:** Session response DTOs with field aliasing for API consistency
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.dto.responses import SessionResponse, SessionListResponse`

**Classes:**
- `SessionResponse(BaseTimestampResponse)` - Response DTO for chat sessions
  - `id: SessionId` - Unique session identifier
  - `user_id: UserId` - User who owns the session (aliased as "userId")
  - `name: str | None` - Optional session name
  - `agent_id: str | None` - Optional agent identifier (aliased as "agentId")
  - `created_time: int` - Creation timestamp in epoch ms (aliased as "createdTime")
  - `updated_time: int | None` - Update timestamp in epoch ms (aliased as "updatedTime")

- `SessionListResponse(BaseModel)` - Response DTO for paginated session lists
  - `sessions: list[SessionResponse]` - List of session objects
  - `pagination: PaginationMeta | None` - Pagination metadata
  - `total_count: int` - Total number of sessions (aliased as "totalCount")

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.routers.dto.responses import SessionResponse, SessionListResponse

# Create a session response
session = SessionResponse(
    id="sess_456",
    user_id="user_789",
    name="My Chat Session",
    agent_id="agent_001",
    created_time=1640995200000
)

# Create a session list response
session_list = SessionListResponse(
    sessions=[session],
    total_count=1
)

# Serialize to JSON (timestamps auto-converted to ISO strings)
json_output = session.model_dump_json()
```

### task_responses.py
**Purpose:** Task response DTOs with field aliasing for API consistency
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.dto.responses import TaskResponse, TaskListResponse`

**Classes:**
- `TaskResponse(BaseTimestampResponse)` - Response DTO for a single task
  - `task_id: str` - Unique task identifier (aliased as "taskId")
  - `session_id: str` - Session this task belongs to (aliased as "sessionId")
  - `user_message: str | None` - Optional user message (aliased as "userMessage")
  - `message_bubbles: str` - JSON string containing message bubbles (aliased as "messageBubbles")
  - `task_metadata: str | None` - Optional JSON string with task metadata (aliased as "taskMetadata")
  - `created_time: int` - Creation timestamp in epoch ms (aliased as "createdTime")
  - `updated_time: int | None` - Update timestamp in epoch ms (aliased as "updatedTime")

- `TaskListResponse(BaseModel)` - Response DTO for a list of tasks
  - `tasks: list[TaskResponse]` - List of task objects

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.routers.dto.responses import TaskResponse, TaskListResponse

# Create a task response
task = TaskResponse(
    task_id="task_123",
    session_id="sess_456",
    user_message="Process this data",
    message_bubbles='{"bubbles": [{"type": "text", "content": "Processing..."}]}',
    task_metadata='{"priority": "high"}',
    created_time=1640995200000,
    updated_time=1640995260000
)

# Create a task list response
task_list = TaskListResponse(
    tasks=[task]
)

# Serialize to JSON (timestamps auto-converted to ISO strings)
json_output = task.model_dump_json()
```

================================================================================

## Section 38: solace_agent_mesh/gateway/http_sse/routers/routers_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/routers/routers_llm.txt`

# DEVELOPER GUIDE for the routers directory

## Quick Summary
The `routers` directory contains FastAPI router modules that define the REST API endpoints for the HTTP SSE Gateway. Each router groups endpoints by functional domain (agent discovery, artifact management, authentication, sessions, etc.) and provides the primary interface for frontend applications and other clients to interact with the gateway. The routers work together to provide a complete web API with real-time capabilities through Server-Sent Events (SSE), along with comprehensive session management, artifact handling, and A2A message visualization.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py` - Package initialization for router modules
  - `agent_cards.py` - Agent discovery endpoints
  - `artifacts.py` - Artifact management (upload, download, versioning)
  - `auth.py` - Authentication flow endpoints (login, callback, refresh)
  - `config.py` - Frontend configuration endpoint
  - `feedback.py` - User feedback collection endpoints
  - `people.py` - User search for autocomplete features
  - `sessions.py` - Session management (CRUD operations)
  - `sse.py` - Server-Sent Events streaming endpoint
  - `tasks.py` - Task submission and management endpoints
  - `users.py` - Current user information endpoint
  - `visualization.py` - A2A message visualization streaming
- **Subdirectories:**
  - `dto/` - Data Transfer Objects for request/response validation

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Package initialization for the routers module
**Import:** `from solace_agent_mesh.gateway.http_sse.routers import *`

#### agent_cards.py
**Purpose:** Provides REST endpoints for agent discovery
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.agent_cards import router`

**Functions:**
- `get_discovered_agent_cards() -> List[AgentCard]` - Retrieves all currently discovered A2A agents

#### artifacts.py
**Purpose:** Manages session-specific artifacts via REST endpoints with versioning and metadata support
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.artifacts import router, ArtifactUploadResponse`

**Classes:**
- `ArtifactUploadResponse(BaseModel)` - Response model for artifact uploads with camelCase fields

**Functions:**
- `upload_artifact_with_session(upload_file: UploadFile, sessionId: str, filename: str, metadata_json: str) -> ArtifactUploadResponse` - Uploads artifact with session management
- `list_artifact_versions(session_id: str, filename: str) -> List[int]` - Lists available versions for an artifact
- `list_artifacts(session_id: str) -> List[ArtifactInfo]` - Lists all artifacts in a session with metadata
- `get_latest_artifact(session_id: str, filename: str) -> StreamingResponse` - Downloads latest artifact version with embed resolution
- `get_specific_artifact_version(session_id: str, filename: str, version: Union[int, str]) -> StreamingResponse` - Downloads specific version
- `get_artifact_by_uri(uri: str) -> StreamingResponse` - Downloads artifact by formal artifact:// URI
- `delete_artifact(session_id: str, filename: str) -> Response` - Deletes artifact and all versions

#### auth.py
**Purpose:** Handles OAuth-based user authentication flow with external authorization service
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.auth import router`

**Functions:**
- `initiate_login(request: FastAPIRequest) -> RedirectResponse` - Starts OAuth login flow with external service
- `get_csrf_token(response: Response) -> Dict[str, str]` - Generates and sets CSRF token
- `auth_callback(request: FastAPIRequest) -> RedirectResponse` - Handles OAuth callback and token exchange
- `refresh_token(request: FastAPIRequest) -> Dict[str, str]` - Refreshes access token using refresh token

#### config.py
**Purpose:** Provides frontend configuration settings including feature flags
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.config import router`

**Functions:**
- `get_app_config() -> Dict[str, Any]` - Returns frontend configuration including auth URLs, feature flags, and persistence settings

#### feedback.py
**Purpose:** Receives and processes user feedback on chat messages
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.feedback import router, FeedbackPayload`

**Classes:**
- `FeedbackPayload(BaseModel)` - Data model for feedback submission
  - `task_id: str` - ID of the task being rated
  - `session_id: str` - Session containing the task
  - `feedback_type: Literal["up", "down"]` - Type of feedback
  - `feedback_text: Optional[str]` - Optional text feedback

**Functions:**
- `submit_feedback(payload: FeedbackPayload, user_id: str) -> Dict[str, str]` - Processes user feedback asynchronously

#### people.py
**Purpose:** Provides user search functionality for autocomplete features
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.people import router`

**Functions:**
- `search_people(q: str, limit: int = 10) -> List[Dict[str, Any]]` - Searches for users for @mention autocomplete

#### sessions.py
**Purpose:** Manages user sessions including CRUD operations with persistence
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.sessions import router`

**Functions:**
- `get_all_sessions(page_number: int, page_size: int, user: dict) -> PaginatedResponse[SessionResponse]` - Lists user's sessions with pagination
- `get_session(session_id: str, user: dict) -> DataResponse[SessionResponse]` - Gets session details with authorization
- `get_session_history(session_id: str, user: dict) -> List[MessageResponse]` - Gets session message history
- `update_session_name(session_id: str, name: str, user: dict) -> SessionResponse` - Updates session name with validation
- `delete_session(session_id: str, user: dict) -> None` - Deletes session with cascade notifications
- `save_task(session_id: str, request: SaveTaskRequest, user: dict) -> TaskResponse` - Saves complete task interaction (upsert)
- `get_session_tasks(session_id: str, user: dict) -> TaskListResponse` - Gets all tasks for a session

#### sse.py
**Purpose:** Provides Server-Sent Events endpoint for real-time streaming
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.sse import router`

**Functions:**
- `subscribe_to_task_events(task_id: str, request: FastAPIRequest) -> EventSourceResponse` - Establishes SSE connection for task updates with automatic cleanup

#### tasks.py
**Purpose:** Handles task submission, management, and historical search
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.tasks import router`

**Functions:**
- `search_tasks(start_date: Optional[str], end_date: Optional[str], search: Optional[str], page: int, page_size: int, query_user_id: Optional[str]) -> List[Task]` - Searches historical tasks with admin capabilities
- `get_task_as_stim_file(task_id: str) -> Response` - Downloads complete task history as .stim file
- `send_task_to_agent(request: FastAPIRequest, payload: SendMessageRequest) -> SendMessageSuccessResponse` - Submits non-streaming task
- `subscribe_task_from_agent(request: FastAPIRequest, payload: SendStreamingMessageRequest) -> SendStreamingMessageSuccessResponse` - Submits streaming task
- `cancel_agent_task(request: FastAPIRequest, taskId: str, payload: CancelTaskRequest) -> Dict[str, str]` - Cancels active task

#### users.py
**Purpose:** Provides current user information with authentication status
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.users import router`

**Functions:**
- `get_current_user_endpoint(user: dict) -> Dict[str, Any]` - Returns current user information with auth status

#### visualization.py
**Purpose:** Manages A2A message visualization streams for real-time monitoring
**Import:** `from solace_agent_mesh.gateway.http_sse.routers.visualization import router, SubscriptionTarget, VisualizationSubscribeRequest`

**Classes:**
- `SubscriptionTarget(BaseModel)` - Defines visualization target
  - `type: str` - Target type (e.g., "current_namespace_a2a_messages", "agent_a2a_messages")
  - `identifier: Optional[str]` - Target identifier (namespace or agent name)
- `VisualizationSubscribeRequest(BaseModel)` - Subscription request
  - `subscription_targets: Optional[List[SubscriptionTarget]]` - Targets to monitor
  - `client_stream_id: Optional[str]` - Client-generated stream ID for idempotency
- `VisualizationSubscribeResponse(BaseModel)` - Subscription response with SSE URL
- `VisualizationConfigUpdateRequest(BaseModel)` - Configuration update request
- `VisualizationConfigUpdateResponse(BaseModel)` - Configuration update response

**Functions:**
- `subscribe_to_visualization_stream(request_data: VisualizationSubscribeRequest) -> VisualizationSubscribeResponse` - Starts visualization stream with authorization
- `get_visualization_stream_events(stream_id: str) -> EventSourceResponse` - SSE endpoint for visualization events
- `update_visualization_stream_config(stream_id: str, update_request: VisualizationConfigUpdateRequest) -> VisualizationConfigUpdateResponse` - Updates stream configuration
- `unsubscribe_from_visualization_stream(stream_id: str) -> Response` - Terminates visualization stream

### Subdirectory APIs

#### dto/
**Purpose:** Provides Data Transfer Objects for request/response validation and serialization with automatic timestamp conversion
**Key Exports:** Request and response DTOs for session management with field validation and camelCase aliasing
**Import Examples:**
```python
from solace_agent_mesh.gateway.http_sse.routers.dto.requests import GetSessionsRequest, UpdateSessionRequest
from solace_agent_mesh.gateway.http_sse.routers.dto.responses import SessionResponse, MessageResponse
```

## Complete Usage Guide

### 1. Setting Up Routers in FastAPI Application

```python
from fastapi import FastAPI
from solace_agent_mesh.gateway.http_sse.routers import (
    agent_cards,
    artifacts,
    auth,
    config,
    feedback,
    people,
    sessions,
    sse,
    tasks,
    users,
    visualization
)

app = FastAPI()

# Include all routers with appropriate prefixes
app.include_router(agent_cards.router, prefix="/api/v1", tags=["agents"])
app.include_router(artifacts.router, prefix="/api/v1/artifacts", tags=["artifacts"])
app.include_router(auth.router, prefix="/api/v1", tags=["auth"])
app.include_router(config.router, prefix="/api/v1", tags=["config"])
app.include_router(feedback.router, prefix="/api/v1", tags=["feedback"])
app.include_router(people.router, prefix="/api/v1", tags=["people"])
app.include_router(sessions.router, prefix="/api/v1", tags=["sessions"])
app.include_router(sse.router, prefix="/api/v1/sse", tags=["sse"])
app.include_router(tasks.router, prefix="/api/v1/tasks", tags=["tasks"])
app.include_router(users.router, prefix="/api/v1/users", tags=["users"])
app.include_router(visualization.router, prefix="/api/v1/visualization", tags=["visualization"])
```

### 2. Agent Discovery and Task Submission

```python
import httpx
from a2a.types import SendStreamingMessageRequest, Message, MessagePart

# Discover available agents
async def get_available_agents():
    async with httpx.AsyncClient() as client:
        response = await client.get("http://localhost:8000/api/v1/agentCards")
        return response.json()

# Submit a streaming task to an agent
async def submit_streaming_task(agent_name: str, message_text: str, session_id: str):
    # Create message parts
    parts = [MessagePart(text=message_text)]
    
    # Create message with metadata
    message = Message(
        parts=parts,
        context_id=session_id,
        metadata={"agent_name": agent_name}
    )
    
    # Create request payload
    payload = SendStreamingMessageRequest(
        method="message:stream",
        params={"message": message},
        id="req_123"
    )
    
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/api/v1/tasks/message:stream",
            json=payload.model_dump()
        )
        return response.json()

# Search historical tasks (admin users can query all users)
async def search_historical_tasks(start_date: str = None, query_user_id: str = None):
    params = {}
    if start_date:
        params["start_date"] = start_date
    if query_user_id:
        params["query_user_id"] = query_user_id
    
    async with httpx.AsyncClient() as client:
        response = await client.get(
            "http://localhost:8000/api/v1/tasks",
            params=params
        )
        return response.json()
```

### 3. Real-time Event Streaming with SSE

```python
import asyncio
import httpx
import json

# Client-side SSE connection for task events
async def listen_to_task_events(task_id: str):
    async with httpx.AsyncClient() as client:
        async with client.stream(
            "GET", 
            f"http://localhost:8000/api/v1/sse/subscribe/{task_id}",
            headers={"Accept": "text/event-stream"}
        ) as response:
            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    event_data = line[6:]  # Remove "data: " prefix
                    try:
                        parsed_data = json.loads(event_data)
                        print(f"Received event: {parsed_data}")
                    except json.JSONDecodeError:
                        print(f"Received raw data: {event_data}")

# Client-side SSE connection for visualization
async def listen_to_visualization_events(stream_id: str):
    async with httpx.AsyncClient() as client:
        async with client.stream(
            "GET",
            f"http://localhost:8000/api/v1/visualization/{stream_id}/events",
            headers={"Accept": "text/event-stream"}
        ) as response:
            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    event_data = line[6:]
                    print(f"Visualization event: {event_data}")
```

### 4. Comprehensive Artifact Management

```python
import httpx
import json
from pathlib import Path

# Upload an artifact with metadata and automatic session creation
async def upload_artifact_with_metadata(session_id: str, filename: str, file_path: Path, metadata: dict = None):
    files = {"upload_file": (filename, file_path.open("rb"))}
    data = {
        "sessionId": session_id,  # Can be null/empty to create new session
        "filename": filename
    }
    
    if metadata:
        data["metadata_json"] = json.dumps(metadata)
    
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:

================================================================================

## Section 39: solace_agent_mesh/gateway/http_sse/services/services_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/services/services_llm.txt`

# DEVELOPER GUIDE: services

## Quick Summary
The `services` directory contains the business logic layer for the HTTP SSE Gateway. It provides high-level services for agent management (discovering and retrieving A2A agents), user feedback processing with database persistence and event publishing, user search via identity services, session management with database persistence, task logging to database, data retention/cleanup, and A2A task operations like cancellation.

## Files Overview
- `__init__.py` - Package initialization file marking the directory as a Python package
- `agent_card_service.py` - Service for retrieving information about discovered A2A agents from the registry
- `data_retention_service.py` - Service for automatic cleanup of old tasks and feedback based on retention policies
- `feedback_service.py` - Service for processing and storing user feedback on chat messages with database and event publishing
- `people_service.py` - Service for searching users via configured identity services
- `session_service.py` - Service for managing chat sessions and messages with database persistence
- `task_logger_service.py` - Service for logging A2A tasks and events to the database
- `task_service.py` - Service for handling A2A task operations like cancellation

## Developer API Reference

### __init__.py
**Purpose:** Marks the services directory as a Python package
**Import:** N/A - No public interfaces

### agent_card_service.py
**Purpose:** Provides methods for accessing information about discovered A2A agents from the shared AgentRegistry
**Import:** `from solace_agent_mesh.gateway.http_sse.services.agent_card_service import AgentCardService`

**Classes:**
- `AgentCardService(agent_registry: AgentRegistry)` - Service for accessing discovered A2A agent information
  - `get_all_agent_cards() -> List[AgentCard]` - Retrieves all currently discovered and registered agent cards
  - `get_agent_card_by_name(agent_name: str) -> Optional[AgentCard]` - Retrieves a specific agent card by name, returns None if not found

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.services.agent_card_service import AgentCardService
from solace_agent_mesh.common.agent_registry import AgentRegistry

# Initialize with shared agent registry
agent_registry = AgentRegistry()  # Usually injected as shared instance
agent_service = AgentCardService(agent_registry=agent_registry)

# Get all available agents
all_agents = agent_service.get_all_agent_cards()
print(f"Found {len(all_agents)} agents")

# Get specific agent by name
agent = agent_service.get_agent_card_by_name("data-processor")
if agent:
    print(f"Found agent: {agent.name}")
else:
    print("Agent not found")
```

### data_retention_service.py
**Purpose:** Service for automatically cleaning up old tasks, task events, and feedback based on configurable retention policies
**Import:** `from solace_agent_mesh.gateway.http_sse.services.data_retention_service import DataRetentionService`

**Classes:**
- `DataRetentionService(session_factory: Callable[[], DBSession] | None, config: Dict[str, Any])` - Service for automatic data cleanup based on retention policies
  - `cleanup_old_data() -> None` - Main orchestration method for cleaning up old data, calls cleanup methods for tasks and feedback

**Constants/Variables:**
- `MIN_RETENTION_DAYS: int` - Minimum retention period (1 day)
- `MIN_CLEANUP_INTERVAL_HOURS: int` - Minimum cleanup interval (1 hour)
- `MIN_BATCH_SIZE: int` - Minimum batch size for deletion (1)
- `MAX_BATCH_SIZE: int` - Maximum batch size for deletion (10000)

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.services.data_retention_service import DataRetentionService
from sqlalchemy.orm import sessionmaker

# Initialize with database session factory and config
session_factory = sessionmaker(bind=your_engine)
config = {
    "enabled": True,
    "task_retention_days": 90,
    "feedback_retention_days": 90,
    "cleanup_interval_hours": 24,
    "batch_size": 1000
}

retention_service = DataRetentionService(
    session_factory=session_factory,
    config=config
)

# Run cleanup (typically called by scheduler)
retention_service.cleanup_old_data()
```

### feedback_service.py
**Purpose:** Handles the business logic for processing and storing user feedback with database persistence and event publishing
**Import:** `from solace_agent_mesh.gateway.http_sse.services.feedback_service import FeedbackService`

**Classes:**
- `FeedbackService(session_factory: Callable[[], DBSession] | None, component: WebUIBackendComponent, task_repo: ITaskRepository)` - Service for processing user feedback with database persistence and event publishing
  - `process_feedback(payload: FeedbackPayload, user_id: str) -> None` - Asynchronously processes and stores feedback, publishes events if configured

**Usage Examples:**
```python
import asyncio
from solace_agent_mesh.gateway.http_sse.services.feedback_service import FeedbackService
from sqlalchemy.orm import sessionmaker

# Initialize with database session factory
session_factory = sessionmaker(bind=your_engine)
component = YourWebUIBackendComponent()  # Your component instance
task_repo = YourTaskRepository()  # Your task repository

feedback_service = FeedbackService(
    session_factory=session_factory,
    component=component,
    task_repo=task_repo
)

# Process feedback (requires FeedbackPayload from router)
async def process_user_feedback():
    # payload would be a FeedbackPayload instance from the router
    await feedback_service.process_feedback(payload, user_id="user123")

asyncio.run(process_user_feedback())
```

### people_service.py
**Purpose:** Provides user search functionality via configured identity services
**Import:** `from solace_agent_mesh.gateway.http_sse.services.people_service import PeopleService`

**Classes:**
- `PeopleService(identity_service: Optional[BaseIdentityService])` - Service for searching and retrieving user information
  - `search_for_users(query: str, limit: int = 10) -> List[Dict[str, Any]]` - Asynchronously searches for users, returns empty list if no identity service configured or query too short

**Usage Examples:**
```python
import asyncio
from solace_agent_mesh.gateway.http_sse.services.people_service import PeopleService
from solace_agent_mesh.common.services.identity_service import BaseIdentityService

# Initialize with identity service
identity_service = SomeIdentityService()  # Your identity service implementation
people_service = PeopleService(identity_service=identity_service)

async def search_users():
    # Search for users
    users = await people_service.search_for_users("john", limit=5)
    for user in users:
        print(f"User: {user.get('name')} - {user.get('email')}")

# Initialize without identity service (graceful degradation)
people_service_no_id = PeopleService(identity_service=None)
# search_for_users will return empty list

asyncio.run(search_users())
```

### session_service.py
**Purpose:** Manages chat sessions and messages with database persistence support
**Import:** `from solace_agent_mesh.gateway.http_sse.services.session_service import SessionService`

**Classes:**
- `SessionService(component: WebUIBackendComponent = None)` - Service for managing chat sessions and messages
  - `is_persistence_enabled() -> bool` - Checks if the service is configured with a persistent backend
  - `get_user_sessions(db: DbSession, user_id: UserId, pagination: PaginationParams | None = None) -> PaginatedResponse[Session]` - Retrieves paginated sessions for a user
  - `get_session_details(db: DbSession, session_id: SessionId, user_id: UserId) -> Session | None` - Gets session details for a specific session
  - `create_session(db: DbSession, user_id: UserId, name: str | None = None, agent_id: str | None = None, session_id: str | None = None) -> Optional[Session]` - Creates a new session
  - `update_session_name(db: DbSession, session_id: SessionId, user_id: UserId, name: str) -> Session | None` - Updates session name
  - `delete_session_with_notifications(db: DbSession, session_id: SessionId, user_id: UserId) -> bool` - Deletes session and notifies agents
  - `save_task(db: DbSession, task_id: str, session_id: str, user_id: str, user_message: Optional[str], message_bubbles: str, task_metadata: Optional[str] = None) -> ChatTask` - Saves a complete task interaction
  - `get_session_tasks(db: DbSession, session_id: str, user_id: str) -> List[ChatTask]` - Gets all tasks for a session
  - `get_session_messages_from_tasks(db: DbSession, session_id: str, user_id: str) -> List[Dict[str, Any]]` - Gets session messages by flattening task message_bubbles for backward compatibility

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.services.session_service import SessionService
from sqlalchemy.orm import Session as DbSession

# Initialize with component
component = YourWebUIBackendComponent()  # Your component
session_service = SessionService(component=component)

# Use with database session
with your_session_factory() as db:
    # Create a new session
    session = session_service.create_session(
        db=db,
        user_id="user123",
        name="My Chat Session",
        agent_id="assistant-agent"
    )

    # Save a task with message bubbles
    import json
    message_bubbles = json.dumps([
        {"type": "user", "text": "Hello", "id": "msg1"},
        {"type": "agent", "text": "Hi there!", "id": "msg2"}
    ])
    
    task = session_service.save_task(
        db=db,
        task_id="task-123",
        session_id=session.id,
        user_id="user123",
        user_message="Hello",
        message_bubbles=message_bubbles
    )

    # Get user's sessions with pagination
    paginated_sessions = session_service.get_user_sessions(db, "user123")
    
    db.commit()
```

### task_logger_service.py
**Purpose:** Service for logging A2A tasks and events to the database with configurable filtering and sanitization
**Import:** `from solace_agent_mesh.gateway.http_sse.services.task_logger_service import TaskLoggerService`

**Classes:**
- `TaskLoggerService(session_factory: Callable[[], DBSession] | None, config: Dict[str, Any])` - Service for logging A2A tasks and events to database
  - `log_event(event_data: Dict[str, Any]) -> None` - Parses a raw A2A message and logs it as a task event, creates or updates master task record

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.services.task_logger_service import TaskLoggerService
from sqlalchemy.orm import sessionmaker

# Initialize with database session factory and config
session_factory = sessionmaker(bind=your_engine)
config = {
    "enabled": True,
    "log_status_updates": True,
    "log_artifact_events": False,
    "log_file_parts": True,
    "max_file_part_size_bytes": 102400
}

task_logger = TaskLoggerService(
    session_factory=session_factory,
    config=config
)

# Log an A2A event
event_data = {
    "topic": "sam/agents/my-agent/request",
    "payload": {"id": "task-123", "method": "sendMessage"},
    "user_properties": {"userId": "user@example.com"}
}

task_logger.log_event(event_data)
```

### task_service.py
**Purpose:** Handles A2A task operations, specifically task cancellation using CoreA2AService and message publishing
**Import:** `from solace_agent_mesh.gateway.http_sse.services.task_service import TaskService, PublishFunc`

**Type Aliases:**
- `PublishFunc: Callable[[str, Dict, Optional[Dict]], None]` - Function type for publishing messages (topic, payload, user_properties)

**Classes:**
- `TaskService(core_a2a_service: CoreA2AService, publish_func: PublishFunc, namespace: str, gateway_id: str, sse_manager: SSEManager, task_context_map: Dict[str, Dict], task_context_lock: threading.Lock, app_name: str)` - Service for managing A2A task operations
  - `cancel_task(agent_name: str, task_id: str, client_id: str, user_id: str = "web_user") -> None` - Asynchronously cancels a task by publishing A2A CancelTaskRequest message

**Usage Examples:**
```python
import asyncio
import threading
from solace_agent_mesh.gateway.http_sse.services.task_service import TaskService, PublishFunc
from solace_agent_mesh.core_a2a.service import CoreA2AService
from solace_agent_mesh.gateway.http_sse.sse_manager import SSEManager

# Define publish function
def my_publish_func(topic: str, payload: dict, user_properties: dict = None):
    print(f"Publishing to {topic}: {payload}")
    # Your actual message publishing logic here

# Initialize dependencies
core_a2a_service = CoreA2AService()  # Your core A2A service
sse_manager = SSEManager()
task_context_map = {}
task_context_lock = threading.Lock()

# Create task service
task_service = TaskService(
    core_a2a_service=core_a2a_service,
    publish_func=my_publish_func,
    namespace="my-namespace",
    gateway_id="gateway-01",
    sse_manager=sse_manager,
    task_context_map=task_context_map,
    task_context_lock=task_context_lock,
    app_name="my-app"
)

async def cancel_task_example():
    # Cancel a task
    await task_service.cancel_task(
        agent_name="data-processor",
        task_id="task-123",
        client_id="client-456",
        user_id="user@example.com"
    )

asyncio.run(cancel_task_example())
```

================================================================================

## Section 40: solace_agent_mesh/gateway/http_sse/shared/shared_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/shared/shared_llm.txt`

# DEVELOPER GUIDE: shared

## Quick Summary
The `shared` directory contains common utilities, constants, enums, types, and exception handling used across all layers of the HTTP SSE gateway. It provides authentication helpers, timestamp utilities, standardized exception handling, database utilities, pagination support, and response formatting for consistent API behavior.

## Files Overview
- `__init__.py` - Central exports for all shared utilities and components
- `auth_utils.py` - Authentication utilities for FastAPI applications
- `timestamp_utils.py` - Epoch timestamp utilities matching Java backend patterns
- `exceptions.py` - Generic web exceptions for HTTP/REST APIs
- `error_dto.py` - Standardized error response DTOs
- `exception_handlers.py` - FastAPI exception handlers for consistent HTTP error responses
- `base_repository.py` - Base repository classes with proper transaction management
- `pagination.py` - Pagination utilities for API responses
- `database_exceptions.py` - Database exception handling and conversion
- `database_helpers.py` - Database utility functions and custom types
- `response_utils.py` - Standardized response formatting utilities
- `enums.py` - Enumerations for message types, task status, and validation errors
- `types.py` - Custom types and type aliases for better type safety
- `utils.py` - Generic utility functions

## Developer API Reference

### auth_utils.py
**Purpose:** Provides authentication utilities for FastAPI controllers
**Import:** `from solace_agent_mesh.gateway.http_sse.shared import get_current_user`

**Functions:**
- `get_current_user(request: FastAPIRequest) -> dict` - Extracts authenticated user from request state, returns user info or anonymous default

**Usage Examples:**
```python
from fastapi import Depends
from solace_agent_mesh.gateway.http_sse.shared import get_current_user

@app.get("/protected")
async def protected_endpoint(user: dict = Depends(get_current_user)):
    return {"user_id": user["id"], "name": user["name"]}
```

### timestamp_utils.py
**Purpose:** Provides epoch timestamp utilities for database portability and timezone handling
**Import:** `from solace_agent_mesh.gateway.http_sse.shared import now_epoch_ms, epoch_ms_to_iso8601, iso8601_to_epoch_ms`

**Functions:**
- `now_epoch_ms() -> int` - Get current time as milliseconds since epoch
- `epoch_ms_to_iso8601(epoch_ms: int) -> str` - Convert epoch milliseconds to ISO 8601 string
- `iso8601_to_epoch_ms(iso8601_string: str) -> int` - Convert ISO 8601 string to epoch milliseconds
- `datetime_to_epoch_ms(dt: datetime) -> int` - Convert datetime object to epoch milliseconds
- `epoch_ms_to_datetime(epoch_ms: int) -> datetime` - Convert epoch milliseconds to datetime object
- `validate_epoch_ms(epoch_ms: int | None) -> bool` - Validate that an epoch milliseconds value is reasonable

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.shared import (
    now_epoch_ms, epoch_ms_to_iso8601, iso8601_to_epoch_ms
)

# Get current timestamp for database storage
created_time = now_epoch_ms()

# Convert for API response
iso_string = epoch_ms_to_iso8601(created_time)

# Parse from API request
timestamp = iso8601_to_epoch_ms("2024-01-01T00:00:00Z")
```

### exceptions.py
**Purpose:** Generic web exceptions for HTTP/REST APIs
**Import:** `from solace_agent_mesh.gateway.http_sse.shared import ValidationError, EntityNotFoundError, EntityAlreadyExistsError`

**Classes:**
- `WebUIBackendException(message: str, details: Optional[Dict[str, Any]] = None)` - Base exception for all web UI backend errors
- `ValidationError(message: str, validation_details: Optional[Dict[str, List[str]]] = None, entity_type: Optional[str] = None, entity_identifier: Optional[str] = None)` - Exception for validation errors with field-level details
- `EntityNotFoundError(entity_type: str, entity_id: str)` - Generic exception for when an entity is not found
- `EntityAlreadyExistsError(entity_type: str, identifier: str, value: Any = None)` - Exception for when an entity already exists
- `BusinessRuleViolationError(rule: str, message: str)` - Exception for business rule violations
- `ConfigurationError(component: str, message: str)` - Exception for configuration-related errors
- `DataIntegrityError(constraint: str, message: str)` - Exception for data integrity violations
- `ExternalServiceError(service: str, message: str, status_code: Optional[int] = None)` - Exception for external service communication errors
- `ValidationErrorBuilder()` - Builder for constructing ValidationError instances with fluent API

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.shared import (
    ValidationError, EntityNotFoundError, ValidationErrorBuilder
)

# Simple validation error
raise ValidationError("Invalid input data")

# Entity not found
raise EntityNotFoundError("User", "123")

# Complex validation with builder
error = ValidationError.builder() \
    .message("Invalid user data") \
    .validation_detail("email", ["Invalid email format"]) \
    .entity_type("User") \
    .build()
```

### error_dto.py
**Purpose:** Standardized error response DTOs for HTTP APIs
**Import:** `from solace_agent_mesh.gateway.http_sse.shared import EventErrorDTO`

**Classes:**
- `EventErrorDTO(message: str, validationDetails: Optional[Dict[str, List[str]]] = None)` - Simplified and standardized error response format
  - `create(message: str, validation_details: Optional[Dict[str, List[str]]] = None) -> EventErrorDTO` - Create a new EventErrorDTO
  - `not_found(entity_type: str, entity_id: str) -> EventErrorDTO` - Create a 404 Not Found error
  - `validation_error(message: str, validation_details: Dict[str, List[str]]) -> EventErrorDTO` - Create a validation error

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.shared import EventErrorDTO

# Simple error
error = EventErrorDTO.create("Something went wrong")

# Not found error
error = EventErrorDTO.not_found("User", "123")

# Validation error
error = EventErrorDTO.validation_error(
    "Invalid data",
    {"email": ["Invalid format"], "age": ["Must be positive"]}
)
```

### exception_handlers.py
**Purpose:** FastAPI exception handlers for consistent HTTP error responses
**Import:** `from solace_agent_mesh.gateway.http_sse.shared import register_exception_handlers`

**Functions:**
- `register_exception_handlers(app)` - Register all exception handlers with a FastAPI app
- `create_error_response(status_code: int, message: str, validation_details: dict = None) -> JSONResponse` - Create standardized error response

**Usage Examples:**
```python
from fastapi import FastAPI
from solace_agent_mesh.gateway.http_sse.shared import register_exception_handlers

app = FastAPI()
register_exception_handlers(app)
```

### base_repository.py
**Purpose:** Base repository classes with proper transaction management
**Import:** `from solace_agent_mesh.gateway.http_sse.shared import BaseRepository, PaginatedRepository, ValidationMixin`

**Classes:**
- `BaseRepository(model_class: Type[ModelType], entity_class: Type[EntityType])` - Abstract base class for repositories
  - `create(session: Session, create_data: Dict[str, Any]) -> EntityType` - Create a new entity
  - `get_by_id(session: Session, entity_id: Any) -> EntityType` - Get entity by ID
  - `get_all(session: Session, limit: Optional[int] = None, offset: Optional[int] = None) -> List[EntityType]` - Get all entities
  - `update(session: Session, entity_id: Any, update_data: Dict[str, Any]) -> EntityType` - Update an entity
  - `delete(session: Session, entity_id: Any) -> None` - Delete an entity
- `PaginatedRepository(model_class: Type[ModelType], entity_class: Type[EntityType])` - Base repository with enhanced pagination support
- `ValidationMixin` - Mixin for repositories that need validation logic

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.shared import BaseRepository
from sqlalchemy.orm import Session

class UserRepository(BaseRepository[UserModel, UserEntity]):
    @property
    def entity_name(self) -> str:
        return "User"

# Usage
repo = UserRepository(UserModel, UserEntity)
user = repo.create(session, {"name": "John", "email": "john@example.com"})
```

### pagination.py
**Purpose:** Pagination utilities for API responses
**Import:** `from solace_agent_mesh.gateway.http_sse.shared import PaginationParams, PaginatedResponse, DataResponse`

**Classes:**
- `PaginationParams(page_number: int = 1, page_size: int = 20)` - Request parameters for pagination
  - `offset: int` - Calculate the offset for database queries
- `PaginatedResponse[T](data: list[T], meta: Meta)` - Generic paginated response with data and metadata
  - `create(data: list[T], total_count: int, pagination: PaginationParams) -> PaginatedResponse[T]` - Create paginated response
- `DataResponse[T](data: T)` - Simple data response wrapper
  - `create(data: T) -> DataResponse[T]` - Create data response

**Constants/Variables:**
- `DEFAULT_PAGE_NUMBER: int` - Default page number (1)
- `DEFAULT_PAGE_SIZE: int` - Default page size (20)
- `MAX_PAGE_SIZE: int` - Maximum allowed page size (100)

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.shared import PaginationParams, PaginatedResponse

# Create pagination params
pagination = PaginationParams(page_number=1, page_size=20)

# Create paginated response
response = PaginatedResponse.create(users, total_count=100, pagination=pagination)
```

### response_utils.py
**Purpose:** Standardized response formatting utilities
**Import:** `from solace_agent_mesh.gateway.http_sse.shared import create_data_response, create_paginated_response, StandardResponseMixin`

**Functions:**
- `create_data_response(data: T) -> DataResponse[T]` - Create a standardized data response
- `create_paginated_response(data: List[T], total_count: int, pagination_params: PaginationParams) -> PaginatedResponse[T]` - Create a standardized paginated response
- `create_success_response(message: str = "Success") -> DataResponse[Dict[str, str]]` - Create a standardized success response
- `create_list_response(items: List[T]) -> DataResponse[List[T]]` - Create a standardized list response

**Classes:**
- `StandardResponseMixin` - Mixin class to add standard response methods to services or controllers

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.shared import create_data_response, create_paginated_response

# Simple data response
response = create_data_response({"id": 1, "name": "test"})

# Paginated response
response = create_paginated_response(users, 100, pagination_params)
```

### database_exceptions.py
**Purpose:** Database exception handling and conversion
**Import:** `from solace_agent_mesh.gateway.http_sse.shared import DatabaseExceptionHandler, handle_database_errors`

**Classes:**
- `DatabaseExceptionHandler` - Centralized handler for converting SQLAlchemy exceptions to domain exceptions
  - `handle_integrity_error(e: IntegrityError, entity_type: str = "Resource") -> ValidationError` - Convert integrity constraint violations
  - `handle_operational_error(e: OperationalError, entity_type: str = "Resource") -> DataIntegrityError` - Handle operational errors
  - `handle_database_error(e: DatabaseError, entity_type: str = "Resource") -> DataIntegrityError` - Handle general database errors
  - `handle_sqlalchemy_error(e: SQLAlchemyError, entity_type: str = "Resource") -> DataIntegrityError` - Handle any other SQLAlchemy errors

**Functions:**
- `handle_database_errors(entity_type: str = "Resource")` - Convenience decorator for database exception handling

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.shared import handle_database_errors

class UserRepository:
    @handle_database_errors("User")
    def create_user(self, session, data):
        # Repository method implementation
        pass
```

### database_helpers.py
**Purpose:** Database utility functions and custom types
**Import:** `from solace_agent_mesh.gateway.http_sse.shared import SimpleJSON`

**Classes:**
- `SimpleJSON(TypeDecorator)` - Simple JSON type using Text storage for all databases
  - `process_bind_param(value, dialect)` - Convert Python object to JSON string for storage
  - `process_result_value(value, dialect)` - Convert JSON string back to Python object

**Usage Examples:**
```python
from sqlalchemy import Column, String
from solace_agent_mesh.gateway.http_sse.shared import SimpleJSON

class MyModel(Base):
    id = Column(String, primary_key=True)
    metadata = Column(SimpleJSON)  # Stores JSON as text
```

### enums.py
**Purpose:** Enumerations used throughout the application
**Import:** `from solace_agent_mesh.gateway.http_sse.shared.enums import SenderType, TaskStatus, MessageType`

**Classes:**
- `SenderType(str, Enum)` - Types of message senders (USER, AGENT, SYSTEM)
- `TaskStatus(str, Enum)` - Task execution status (PENDING, RUNNING, COMPLETED, FAILED, CANCELLED)
- `MessageType(str, Enum)` - Types of messages (TEXT, FILE, IMAGE, DOCUMENT)
- `ValidationErrorType(str, Enum)` - Types of validation errors (REQUIRED_FIELD, INVALID_FORMAT, etc.)

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.shared.enums import SenderType, TaskStatus

# Use in message handling
if sender_type == SenderType.USER:
    process_user_message()

# Use in task management
task.status = TaskStatus.RUNNING
```

### types.py
**Purpose:** Custom types and type aliases for better type safety
**Import:** `from solace_agent_mesh.gateway.http_sse.shared.types import UserId, JsonDict, Timestamp`

**Type Aliases:**
- `UserId: str` - User identifier type
- `SessionId: str` - Session identifier type
- `MessageId: str` - Message identifier type
- `TaskId: str` - Task identifier type
- `AgentId: str` - Agent identifier type
- `JsonDict: dict[str, Any]` - JSON dictionary type
- `Headers: dict[str, str]` - HTTP headers type
- `QueryParams: dict[str, str | list[str]]` - Query parameters type

**Classes:**
- `Timestamp(BaseModel)` - Standardized timestamp representation using epoch milliseconds
  - `created_time: int` - Creation time in epoch milliseconds
  - `updated_time: int | None` - Update time in epoch milliseconds
- `SortInfo(BaseModel)` - Sorting information for list requests
  - `field: str` - Field to sort by
  - `direction: str` - Sort direction (asc or desc)
- `FilterInfo(BaseModel)` - Filtering information for list requests
  - `field: str` - Field to filter

================================================================================

## Section 41: solace_agent_mesh/gateway/http_sse/utils/utils_llm.txt

**Source file:** `solace_agent_mesh/gateway/http_sse/utils/utils_llm.txt`

## Quick Summary
The `utils` directory provides utility functions for the HTTP SSE Gateway, specifically for creating .stim file structures from task and event data.

## Files Overview
- `__init__.py` - Package initialization file for HTTP SSE Gateway utilities
- `stim_utils.py` - Utility functions for formatting task data into .stim file structures

## Developer API Reference

### __init__.py
**Purpose:** Package initialization for HTTP SSE Gateway utilities
**Import:** `from solace_agent_mesh.gateway.http_sse.utils import *`

This file serves as the package entry point and contains no public interfaces.

### stim_utils.py
**Purpose:** Provides utility functions for creating .stim file structures from task and event data
**Import:** `from solace_agent_mesh.gateway.http_sse.utils.stim_utils import create_stim_from_task_data`

**Functions:**
- `create_stim_from_task_data(task: Task, events: List[TaskEvent]) -> dict` - Formats a task and its events into the .stim file structure with version 2.0 format for gateway-generated logs

**Usage Examples:**
```python
from solace_agent_mesh.gateway.http_sse.utils.stim_utils import create_stim_from_task_data
from solace_agent_mesh.gateway.http_sse.repository.entities import Task, TaskEvent

# Create a .stim file structure from task and events
task = Task(
    id="task_123",
    user_id="user_456", 
    start_time="2024-01-01T10:00:00Z",
    end_time="2024-01-01T10:05:00Z",
    status="completed",
    initial_request_text="Process this data"
)

events = [
    TaskEvent(event_type="start", timestamp="2024-01-01T10:00:00Z"),
    TaskEvent(event_type="complete", timestamp="2024-01-01T10:05:00Z")
]

stim_data = create_stim_from_task_data(task, events)
# Returns a dictionary with 'invocation_details' and 'invocation_flow' keys
```

================================================================================

## Section 42: solace_agent_mesh/solace_agent_mesh_llm.txt

**Source file:** `solace_agent_mesh/solace_agent_mesh_llm.txt`

# DEVELOPER GUIDE: solace_agent_mesh

## Quick Summary
The `solace_agent_mesh` directory contains the core implementation of a distributed AI agent communication system built on the Solace event mesh. It provides a complete framework for hosting Google ADK (Agent Development Kit) agents with Agent-to-Agent (A2A) protocol support, enabling real-time communication, task delegation, and multi-platform integration.

The architecture consists of four main subsystems: `agent/` for hosting ADK agents with comprehensive tool libraries, `common/` for foundational A2A protocol infrastructure, `core_a2a/` for reusable service layers, and `gateway/` for external platform integration. These components work together to create a distributed AI agent ecosystem with capabilities for data analysis, multimedia processing, web integration, and inter-agent collaboration.

## Files and Subdirectories Overview
- **Direct files:**
  - `__init__.py`: Empty package initialization file
  - `llm.txt`: Comprehensive developer guide documentation
  - `llm_detail.txt`: Detailed concatenated documentation from all subdirectories
- **Subdirectories:**
  - `agent/`: Complete ADK agent hosting framework with A2A protocol integration and comprehensive tool library
  - `common/`: Foundational A2A protocol infrastructure, type systems, and client/server implementations
  - `core_a2a/`: Reusable service layer for core A2A interactions and agent registry operations
  - `gateway/`: Gateway framework with HTTP/SSE, Slack, and Webhook implementations for external platform integration

## Developer API Reference

### Direct Files

#### __init__.py
**Purpose:** Standard Python package initializer that allows the `solace_agent_mesh` directory to be treated as a package
**Import:** `import solace_agent_mesh`

**Classes/Functions/Constants:** [None - empty file]

#### llm.txt
**Purpose:** Contains comprehensive developer guide documentation for the entire system
**Import:** Not applicable - documentation file

**Classes/Functions/Constants:** [None - documentation file]

#### llm_detail.txt
**Purpose:** Contains detailed concatenated documentation from all subdirectories
**Import:** Not applicable - documentation file

**Classes/Functions/Constants:** [None - documentation file]

### Subdirectory APIs

#### agent/
**Purpose:** Provides a complete framework for hosting Google ADK agents with A2A protocol support and a comprehensive, extensible tool library
**Key Exports:** `SamAgentApp`, `SamAgentComponent`, `AppLlmAgent`, and a wide array of built-in tools for data analysis, web requests, multimedia processing, and inter-agent communication
**Import Examples:**
```python
from solace_agent_mesh.agent.sac.app import SamAgentApp
from solace_agent_mesh.agent.sac.component import SamAgentComponent
from solace_agent_mesh.agent.adk.app_llm_agent import AppLlmAgent
from solace_agent_mesh.agent.tools.builtin_data_analysis_tools import query_data_with_sql
from solace_agent_mesh.agent.tools.peer_agent_tool import PeerAgentTool
from solace_agent_mesh.agent.tools.web_tools import web_request
from solace_agent_mesh.agent.tools.image_tools import create_image_from_description
```

#### common/
**Purpose:** Provides the foundational infrastructure for Agent-to-Agent (A2A) communication, including the core protocol, data types, message translation, and client/server implementations
**Key Exports:** A2A protocol functions, Pydantic type definitions (`Message`, `Task`, `AgentCard`), `A2AClient` for interacting with agents, `A2AServer` for building agents, and various utilities
**Import Examples:**
```python
from solace_agent_mesh.common.a2a_protocol import get_agent_request_topic
from solace_agent_mesh.common.types import Message, Task, AgentCard, TextPart
from solace_agent_mesh.common.client import A2AClient, A2ACardResolver
from solace_agent_mesh.common.server import A2AServer, InMemoryTaskManager
from solace_agent_mesh.common.agent_registry import AgentRegistry
from solace_agent_mesh.common.utils.embeds import resolve_embeds_recursively_in_string
```

#### core_a2a/
**Purpose:** Provides a reusable, decoupled service layer for core A2A interactions, handling task submission, cancellation, and agent discovery
**Key Exports:** `CoreA2AService` for managing A2A protocol logic without being tied to a specific gateway or messaging implementation
**Import Examples:**
```python
from solace_agent_mesh.core_a2a.service import CoreA2AService
```

#### gateway/
**Purpose:** Provides a framework and multiple implementations for building gateways that bridge external platforms (like web UIs, Slack, or webhooks) with the A2A messaging system
**Key Exports:** `BaseGatewayApp` and `BaseGatewayComponent` for creating custom gateways, and concrete implementations like `WebUIBackendApp`, `SlackGatewayApp`, and `WebhookGatewayApp`
**Import Examples:**
```python
from solace_agent_mesh.gateway.base.app import BaseGatewayApp
from solace_agent_mesh.gateway.http_sse.app import WebUIBackendApp
from solace_agent_mesh.gateway.slack.app import SlackGatewayApp
from solace_agent_mesh.gateway.webhook.app import WebhookGatewayApp
```

## Complete Usage Guide

### 1. Setting Up a Complete AI Agent System

This example demonstrates how to create a comprehensive AI agent system with multiple components working together.

```python
# Step 1: Create an ADK-powered agent
from solace_agent_mesh.agent.sac.app import SamAgentApp

# Configure the agent with comprehensive capabilities
agent_config = {
    "name": "data-analyst-agent",
    "app_config": {
        "namespace": "myorg/ai-agents",
        "agent_name": "data_analyst",
        "model": "gemini-1.5-pro",
        "instruction": "You are a data analysis expert with access to SQL, charting, web tools, and peer collaboration.",
        "tools": [
            {"tool_type": "builtin", "tool_name": "query_data_with_sql"},
            {"tool_type": "builtin", "tool_name": "create_chart"},
            {"tool_type": "builtin", "tool_name": "web_request"},
            {"tool_type": "builtin", "tool_name": "peer_agent_tool"}
        ],
        "agent_card": {
            "description": "AI agent for comprehensive data analysis and reporting",
            "capabilities": ["data_analysis", "web_research", "chart_generation", "peer_collaboration"]
        },
        "agent_card_publishing": {"interval_seconds": 30},
        "agent_discovery": {"enabled": True},
        "inter_agent_communication": {"allow_list": ["*"]}
    }
}

# Create the agent app
agent_app = SamAgentApp(agent_config)

# Step 2: Set up A2A protocol infrastructure
from solace_agent_mesh.common.agent_registry import AgentRegistry
from solace_agent_mesh.common.types import AgentCard, AgentCapabilities, AgentSkill
from solace_agent_mesh.core_a2a.service import CoreA2AService

# Initialize shared agent registry
agent_registry = AgentRegistry()

# Create core A2A service
namespace = "myorg/ai-agents"
a2a_service = CoreA2AService(agent_registry, namespace)

# Register agent capabilities
data_analyst_card = AgentCard(
    name="data_analyst",
    display_name="Data Analyst",
    description="AI agent for data analysis",
    url=f"a2a://{namespace}/data_analyst",
    version="1.0.0",
    capabilities=AgentCapabilities(streaming=True, pushNotifications=True),
    skills=[AgentSkill(id="sql_analysis", name="SQL Data Analysis")]
)
a2a_service.process_discovery_message(data_analyst_card)

# Step 3: Create gateway integrations
from solace_agent_mesh.gateway.http_sse.app import WebUIBackendApp
from solace_agent_mesh.gateway.slack.app import SlackGatewayApp

# Web UI Gateway for browser-based interactions
webui_config = {
    "name": "web-gateway",
    "app_config": {
        "namespace": "myorg/ai-agents",
        "gateway_id": "web-ui-gateway",
        "session_secret_key": "a-very-secret-key",
        "fastapi_host": "0.0.0.0",
        "fastapi_port": 8080,
        "artifact_service": {"type": "local_file", "base_path": "./artifacts"}
    }
}
webui_app = WebUIBackendApp(webui_config)

# Slack Gateway for team collaboration
slack_config = {
    "name": "slack-gateway",
    "app_config": {
        "namespace": "myorg/ai-agents",
        "gateway_id": "slack-gateway",
        "slack_bot_token": "${SLACK_BOT_TOKEN}",
        "slack_app_token": "${SLACK_APP_TOKEN}",
        "default_agent_name": "data_analyst"
    }
}
slack_app = SlackGatewayApp(slack_config)
```

### 2. Inter-Agent Communication Pattern

```python
# This code would run within an agent's tool execution context
from solace_agent_mesh.agent.tools.peer_agent_tool import PeerAgentTool

async def analyze_and_delegate_report(component, tool_context):
    # Step 1: Perform local analysis using built-in tools
    from solace_agent_mesh.agent.tools.builtin_data_analysis_tools import query_data_with_sql
    
    analysis_result = await query_data_with_sql(
        sql_query="SELECT * FROM sales_data WHERE date >= '2024-01-01'",
        tool_context=tool_context
    )

    # Step 2: Delegate report generation to a specialist agent
    peer_tool = PeerAgentTool(
        target_agent_name="report_generator",
        host_component=component
    )
    
    report_result = await peer_tool.run_async(
        args={
            "task_description": "Generate a professional PDF report from this analysis",
            "analysis_data": "artifact://analysis_result.json",
            "report_format": "PDF"
        },
        tool_context=tool_context
    )
    
    return report_result
```

### 3. Building Custom Tools

```python
from solace_agent_mesh.agent.tools.registry import tool_registry
from solace_agent_mesh.agent.tools.tool_definition import BuiltinTool
from google.adk.tools import ToolContext

async def custom_database_query(
    query: str,
    database_name: str = "default",
    tool_context: ToolContext = None,
    tool_config: dict = None
) -> dict:
    """Execute a custom database query with enhanced features."""
    
    # Access the host component for shared resources
    host_component = tool_context._invocation_context.agent.host_component
    
    # Get database connection from agent state
    db_connection = host_component.get_agent_specific_state('db_connection')
    
    # Execute query with error handling
    try:
        result = await execute_query(db_connection, query, database_name)
        
        # Save results as an artifact
        from solace_agent_mesh.agent.utils.artifact_helpers import save_artifact_with_metadata
        import json
        from datetime import datetime, timezone
        
        artifact_result = await save_artifact_with_metadata(
            artifact_service=host_component.get_shared_artifact_service(),
            app_name=host_component.get_config()["app_name"],
            user_id=tool_context.user_id,
            session_id=tool_context.session_id,
            filename=f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            content_bytes=json.dumps(result).encode(),
            mime_type="application/json",
            metadata_dict={
                "query": query,
                "database": database_name,
                "tool": "custom_database_query"
            },
            timestamp=datetime.now(timezone.utc)
        )
        
        return {
            "status": "success",
            "rows_returned": len(result),
            "artifact_filename": artifact_result["filename"],
            "preview": result[:5] if len(result) > 5 else result
        }
        
    except Exception as e:
        return {
            "status": "error",
            "error_message": str(e)
        }

# Register the custom tool
custom_tool = BuiltinTool(
    name="custom_database_query",
    description="Execute custom database queries with enhanced features",
    function=custom_database_query,
    category="data_analysis"
)
tool_registry.register(custom_tool)
```

### 4. Working with Multimedia Tools

```python
from solace_agent_mesh.agent.tools.audio_tools import text_to_speech, multi_speaker_text_to_speech
from solace_agent_mesh.agent.tools.image_tools import create_image_from_description, describe_image

async def multimedia_workflow(tool_context):
    # Generate speech from text
    tts_result = await text_to_speech(
        text="Welcome to our AI-powered presentation system!",
        output_filename="intro.mp3",
        gender="female",
        tone="professional",
        language="en-US",
        tool_context=tool_context
    )
    
    # Create a multi-speaker dialogue
    conversation_result = await multi_speaker_text_to_speech(
        conversation_text="""
        Presenter: Today we'll discuss our quarterly results.
        Analyst: The data shows significant growth in Q4.
        Presenter: Let's dive into the details.
        """,
        speaker_configs=[
            {"name": "Presenter", "gender": "female", "tone": "professional"},
            {"name": "Analyst", "gender": "male", "tone": "analytical"}
        ],
        output_filename="dialogue.mp3",
        tool_context=tool_context
    )
    
    # Generate supporting visuals
    chart_image = await create_image_from_description(
        image_description="A professional bar chart showing quarterly growth with blue and green colors",
        output_filename="quarterly_chart.png",
        tool_context=tool_context
    )
    
    return {
        "intro_audio": tts_result,
        "dialogue_audio": conversation_result,
        "chart_image": chart_image
    }
```

### 5. Client-Side Integration

```python
import asyncio
from solace_agent_mesh.common.client import A2AClient, A2ACardResolver
from solace_agent_mesh.common.types import Message, TextPart

async def client_integration_example():
    # Discover available agents
    resolver = A2ACardResolver("https://agents.myorg.com")
    agent_card = resolver.get_agent_card()
    
    # Create client for agent interaction
    client = A2AClient(agent_card=agent_card)
    
    # Submit a complex task with file upload
    task_payload = {
        "message": {
            "role": "user",
            "parts": [
                {"type": "text", "text": "Please analyze this sales data and create a report"},
                {"type": "file", "file": {"name": "sales_data.csv", "uri": "file://./sales_data.csv"}}
            ]
        }
    }
    
    # Stream the response
    print("Submitting task and streaming response...")
    async for response in client.send_task_streaming(task_payload):
        if hasattr(response.result, 'text_delta'):
            print(response.result.text_delta,

================================================================================


# A2A ADK Orchestrator Component Configurations
#
# This file demonstrates how to configure the A2A_ADK_HostComponent as an orchestrator.

log:
  stdout_log_level: INFO
  log_file_level: DEBUG # Changed from INFO to DEBUG to capture ADK INFO logs
  log_file: a2a_orchestrator_example.log

# Shared SAM config
!include shared_config.yaml

apps:
  # Example 1: Custom OpenAI-Compatible LLM Agent
  - name: custom_llm_agent_app
    app_base_path: .
    app_module: src.solace_agent_mesh.agent.sac.app # Use the custom App class in its new location
    broker:
      <<: *broker_connection

    # App Level Config
    app_config:
      namespace: ${NAMESPACE} # Your A2A topic namespace
      supports_streaming: true # Host capability flag
      agent_name: "AgentBob"
      display_name: "AgentBob"

      model: *planning_model
      #model: *multimodal_model

      instruction: | 
            Complete the task using the tools available to you.
      session_service:
        type: "memory"
        default_behavior: "PERSISTENT" # Or "RUN_BASED"
      artifact_service:
        type: "filesystem"
        base_path: "/tmp/samv2"
        artifact_scope: namespace # Default scope, shares artifacts within the NAMESPACE
      artifact_handling_mode: "reference" # Embed artifacts created by *this* agent
      enable_embed_resolution: true # Enable embed feature and instruction injection
      enable_artifact_content_instruction: true # Enable instruction for late-stage embed
      tools:
        - tool_type: builtin-group
          group_name: "artifact_management"
        - tool_type: builtin-group
          group_name: "data_analysis"
      stream_batching_threshold_bytes: 50
      inject_system_purpose: true
      inject_response_format: true
      max_llm_calls_per_task: 25 # Limit the number of LLM calls per task to prevent excessive usage

      # Agent Card Definition (Simplified)
      agent_card:
        description: "AgentBob"
        defaultInputModes: ["text"] # Optional, Defaults to ["text"] if omitted
        defaultOutputModes: ["text", "file"] # Indicate potential file output
        skills: [] # Keep, but now optional (defaults to empty list)
        # documentationUrl: Optional
        # provider: Optional
      # Discovery & Communication
      agent_card_publishing: { interval_seconds: 10 }
      agent_discovery: { enabled: true } # Enable discovery and peer delegation instruction injection
      inter_agent_communication:
        allow_list: ["AgentPhil", "AgentJudy"]
        request_timeout_seconds: 2000